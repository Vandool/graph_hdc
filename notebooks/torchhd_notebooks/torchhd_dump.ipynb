{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T08:15:57.111410Z",
     "start_time": "2025-05-28T08:15:57.106741Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a=MAPTensor([-1.,  1., -1.,  1.,  1.,  1.,  1., -1.])\n",
      "b=MAPTensor([ 1.,  1., -1., -1., -1.,  1.,  1., -1.])\n",
      "a_b=MAPTensor([[-1.,  1., -1.,  1.,  1.,  1.,  1., -1.],\n",
      "           [ 1.,  1., -1., -1., -1.,  1.,  1., -1.]])\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "from notebooks.rewrite import edge_index\n",
    "from src.encoding.types import VSAModel\n",
    "import torch\n",
    "import torchhd\n",
    "\n",
    "from tests_new.test_torchhd_utils import cartesian_bind_tensor\n",
    "\n",
    "l = list(tuple(VSAModel))\n",
    "\n",
    "vsa = VSAModel.MAP\n",
    "a, b = torchhd.random(2, 8, vsa=vsa.value)\n",
    "print(f\"{a=}\")\n",
    "print(f\"{b=}\")\n",
    "\n",
    "a_b = torch.stack([a, b]).squeeze()\n",
    "print(f\"{a_b=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0074fe42e8aac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{torchhd.bind(a, b)=}\")\n",
    "print(f\"{torchhd.multibind(a_b)=}\")\n",
    "print(f\"{torch.equal(torchhd.bind(a, b), torchhd.multibind(a_b))=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4beff1813c251a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{torchhd.bundle(a, b)=}\")\n",
    "print(f\"{torchhd.multibundle(a_b)=}\")\n",
    "print(f\"{torch.equal(torchhd.bundle(a, b), torchhd.multibundle(a_b))=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79b981cdb3dc206",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{a_b.shape=}\")\n",
    "a_b = torch.unsqueeze(a_b, dim=0)\n",
    "print(f\"{a_b.shape=}\")\n",
    "a_b_x_2 = torch.cat([a_b, a_b], dim=0)\n",
    "print(f\"{a_b_x_2.shape=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6f01671ec4499",
   "metadata": {},
   "outputs": [],
   "source": [
    "multibundle = torchhd.multibundle(a_b_x_2)\n",
    "print(f\"{ multibundle=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc162519a3f559c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchhd\n",
    "\n",
    "R = torchhd.random(5, 10)\n",
    "print(f\"{R.shape=}\")\n",
    "G = torchhd.random(5, 10)\n",
    "print(f\"{G.shape=}\")\n",
    "\n",
    "RG = torch.stack([R, G], dim=0)  # [2, 5, 10]\n",
    "print(f\"{RG.shape}\")\n",
    "\n",
    "## We want to multibind on the 0th dimension\n",
    "RGT = RG.transpose(0, 1)\n",
    "print(f\"{RGT.shape=}\")\n",
    "\n",
    "y = torchhd.multibind(RGT)\n",
    "print(f\"{y.shape=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b224b50724782529",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchhd\n",
    "from torchhd import functional as F, HRRTensor  # or just use torchhd.bind\n",
    "\n",
    "# your random hypervectors\n",
    "R = torchhd.random(5, 10)\n",
    "G = torchhd.random(5, 10)\n",
    "B = torchhd.random(5, 10)\n",
    "\n",
    "# stack & multibind via transpose (what you already did)\n",
    "RG = torch.stack([R, G, B], dim=0)  # [2, 5, 10]\n",
    "y = torchhd.multibind(RG.transpose(0, 1))  # → [5, 10]\n",
    "\n",
    "# manual two-way bind along N\n",
    "# torchhd.bind (alias for the MAP-model binding op) does elementwise bind of two HVs\n",
    "y2 = torchhd.bind(R, G).bind(\n",
    "    B\n",
    ")  # → [5, 10]  [oai_citation:0‡Torchhd](https://torchhd.readthedocs.io/en/stable/torchhd.html)\n",
    "\n",
    "# check they’re identical\n",
    "print(\"shapes:\", y.shape, y2.shape)\n",
    "print(\"equal?:\", torch.equal(y, y2))  # → True\n",
    "\n",
    "l = [R, G, B]\n",
    "# start from the first element...\n",
    "y3 = l[0]\n",
    "# ...then iteratively bind in the rest\n",
    "for hv in l[1:]:\n",
    "    y3 = torchhd.bind(y3, hv)\n",
    "\n",
    "print(\"shapes:\", y.shape, y3.shape)  # both torch.Size([5, 10])\n",
    "print(\"equal?:\", torch.equal(y, y3))  # → True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88cdf98851707a1f",
   "metadata": {},
   "source": "## True False Hyper vectors"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c03f6a74006d768",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchhd\n",
    "from torchhd import functional as F\n",
    "\n",
    "D = 10\n",
    "true_hv = torchhd.random(1, D)[0]  # e.g. shape [D]\n",
    "false_hv = F.inverse(true_hv)  # inverse for binding\n",
    "\n",
    "# check: binding true⊗false → identity\n",
    "I = torchhd.identity(1, D)[0]\n",
    "print(torch.equal(torchhd.bind(true_hv, false_hv), I))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3120262c0d405e3f",
   "metadata": {},
   "source": "## Create Torchhd BSC Tensor Manually - Bundle vs. Multibundle Problem"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108854aa56199b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchhd import BSCTensor\n",
    "\n",
    "# 1) as a plain Boolean torch.Tensor\n",
    "a = torch.tensor([True, True], dtype=torch.bool)\n",
    "a_hv = BSCTensor(a)\n",
    "z = a_hv.new_zeros(size=a_hv.size())\n",
    "b = torch.tensor([False, False], dtype=torch.bool)\n",
    "b_hv = BSCTensor(b)\n",
    "\n",
    "## This is a strange behaviour, the majority voting tie-break of multi bundle and bundle do not result in the same vector\n",
    "res1 = a_hv.bundle(b_hv)  # False, False\n",
    "res2 = torchhd.multibundle(torch.stack([a_hv, b_hv]))  # True, False\n",
    "print(f\"{torch.equal(res1, res2)=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d203bf66d1ec8b5f",
   "metadata": {},
   "source": "## Create Torchhd MAP Tensor Manually - Bundle vs. Multibundle Problem"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ebe1c5af55d0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchhd\n",
    "from torchhd.tensors.map import MAPTensor\n",
    "\n",
    "# Fix a small dimension for demo\n",
    "D = 2\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# Create two random MAP hypervectors of shape [2]\n",
    "a_hv = MAPTensor.random(1, D).squeeze(0)\n",
    "b_hv = MAPTensor.random(1, D).squeeze(0)\n",
    "\n",
    "# 1) Two-way bundle (elementwise sum)\n",
    "res1 = torchhd.bundle(a_hv, b_hv)\n",
    "\n",
    "# 2) Multibundle (sum across the first dim)\n",
    "res2 = torchhd.multibundle(torch.stack([a_hv, b_hv], dim=0))\n",
    "\n",
    "print(\"a_hv:\", a_hv)\n",
    "print(\"b_hv:\", b_hv)\n",
    "print(\"res1 (bundle):   \", res1)\n",
    "print(\"res2 (multibundle):\", res2)\n",
    "print(\"Equal?:\", torch.equal(res1, res2))  # → True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565f8eedd9e2b522",
   "metadata": {},
   "source": "## Multibind, Mulitbundle"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99a22676714f475f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T13:51:22.276765Z",
     "start_time": "2025-06-06T13:51:16.921411Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: HRRTensor([ 0.5222, -0.0994, -0.7384,  0.1926, -0.3675])\n",
      "a_bind: HRRTensor([ 0.5222, -0.2335, -0.2729, -0.2729, -0.2335])\n",
      "Equal?: False\n",
      "a_bind_b HRRTensor([ 0.0613,  0.4760, -0.9029,  0.4831,  0.1230])\n",
      "a_bundle: HRRTensor([ 0.5222, -0.0994, -0.7384,  0.1926, -0.3675])\n",
      "Equal?: False\n",
      "a_bundle_b HRRTensor([ 1.0445, -0.1989, -1.4767,  0.3853, -0.7351])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arvandkaveh/Projects/kit/graph_hdc/.venv/lib/python3.13/site-packages/torch/_tensor.py:1668: UserWarning: Casting complex values to real discards the imaginary part (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/Copy.cpp:307.)\n",
      "  ret = func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchhd\n",
    "from torchhd.tensors.hrr import HRRTensor\n",
    "\n",
    "# Fix a small dimension for demo\n",
    "D = 5\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# Create two random MAP hypervectors of shape [2]\n",
    "a = HRRTensor.random(1, D).squeeze(0)\n",
    "a_bind = torchhd.multibind(torch.stack([a]))\n",
    "a_bind_b = torchhd.bind(a, a)\n",
    "a_bundle = torchhd.multibundle(torch.stack([a]))\n",
    "a_bundle_b = torchhd.bundle(a, a)\n",
    "\n",
    "print(\"a:\", a)\n",
    "print(\"a_bind:\", a_bind)\n",
    "print(\"Equal?:\", torch.equal(a, a_bind))  # → True\n",
    "print(\"a_bind_b\", a_bind_b)\n",
    "\n",
    "print(\"a_bundle:\", a_bundle)\n",
    "print(\"Equal?:\", torch.equal(a, a_bind))  # → False\n",
    "print(\"a_bundle_b\", a_bundle_b)\n",
    "\n",
    "# Important: the multibind and multibundle apply a self-bundle/bind if on a single input. So you should always check the dimensions, and not apply the function if the dim(-2) is one. But it seems like bind(a, a) is not equal multibind(a). Whatos going on?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fbfd18cdff26712c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T16:08:07.026999Z",
     "start_time": "2025-06-06T16:08:06.964715Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_b: HRRTensor([ 0.4415, -0.2786,  0.6536, -0.3927, -0.5884])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got -2)",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mIndexError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[35]\u001B[39m\u001B[32m, line 25\u001B[39m\n\u001B[32m     23\u001B[39m spectra = torch.fft.fft(a, dim=-\u001B[32m1\u001B[39m)\n\u001B[32m     24\u001B[39m \u001B[38;5;66;03m# Multiply spectra across vectors (no dtype cast to float!)\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m25\u001B[39m prod_spectra = \u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43mprod\u001B[49m\u001B[43m(\u001B[49m\u001B[43mspectra\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdim\u001B[49m\u001B[43m=\u001B[49m\u001B[43m-\u001B[49m\u001B[32;43m2\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m     26\u001B[39m \u001B[38;5;66;03m# Inverse FFT to get convolution result\u001B[39;00m\n\u001B[32m     27\u001B[39m result = torch.fft.ifft(prod_spectra, dim=-\u001B[32m1\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/kit/graph_hdc/.venv/lib/python3.13/site-packages/torch/_tensor.py:1668\u001B[39m, in \u001B[36mTensor.__torch_function__\u001B[39m\u001B[34m(cls, func, types, args, kwargs)\u001B[39m\n\u001B[32m   1665\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mNotImplemented\u001B[39m\n\u001B[32m   1667\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m _C.DisableTorchFunctionSubclass():\n\u001B[32m-> \u001B[39m\u001B[32m1668\u001B[39m     ret = \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1669\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m func \u001B[38;5;129;01min\u001B[39;00m get_default_nowrap_functions():\n\u001B[32m   1670\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m ret\n",
      "\u001B[31mIndexError\u001B[39m: Dimension out of range (expected to be in range of [-1, 0], but got -2)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchhd\n",
    "\n",
    "\n",
    "# Fix a small dimension for demo\n",
    "D = 5\n",
    "torch.manual_seed(0)\n",
    "\n",
    "\n",
    "a = torchhd.random(1, D, vsa=\"HRR\")\n",
    "b = torchhd.random(1, D, vsa=\"HRR\")\n",
    "\n",
    "a = a.squeeze(0)\n",
    "b = b.squeeze(0)\n",
    "\n",
    "# normal binds\n",
    "a_b = torchhd.bind(a, a).bind(b)\n",
    "print(\"a_b:\", a_b)\n",
    "\n",
    "# multibind\n",
    "s = torch.stack([a, b], dim=0)\n",
    "a_b_m = torchhd.multibind(s)\n",
    "print(\"a_b_m:\", a_b_m)\n",
    "\n",
    "assert torch.allclose(a_b, a_b_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2510c7a7aa51949e",
   "metadata": {},
   "source": "## Test multiset multisetity"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d9a5e07a14f6a0d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-31T12:14:23.116507Z",
     "start_time": "2025-05-31T12:14:23.102460Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###############<VSAModel.HRR: 'HRR'>\n",
      "HRRTensor([2., 0., 0., -0., 0., -0., 0., -0., -0., 0., 0., -0., 0., 0., -0., 0.])\n",
      "HRRTensor([1., -0., 0., -0., -0., 0., -0., 0., 0., 0.])\n",
      "Index is Correct: (f ==f_idx)=True\n",
      "Count is correct: simf[f_idx]=HRRTensor(2.), (simf[f_idx]==5)=HRRTensor(False)\n",
      "Index is Correct: (b ==b_idx)=True\n",
      "Count is correct: simb[b_idx]=HRRTensor(1.), (simb[b_idx]==3)=HRRTensor(False)\n",
      "\n",
      "--------------------------------\n",
      "\n",
      "###############<VSAModel.FHRR: 'FHRR'>\n",
      "FHRRTensor([2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.int32)\n",
      "FHRRTensor([1., 0., -0., -0., 0., -0., -0., -0., 0., -0.])\n",
      "Index is Correct: (f ==f_idx)=True\n",
      "Count is correct: simf[f_idx]=FHRRTensor(2, dtype=torch.int32), (simf[f_idx]==5)=FHRRTensor(False)\n",
      "Index is Correct: (b ==b_idx)=True\n",
      "Count is correct: simb[b_idx]=FHRRTensor(1.), (simb[b_idx]==3)=FHRRTensor(False)\n",
      "\n",
      "--------------------------------\n",
      "\n",
      "###############<VSAModel.MAP: 'MAP'>\n",
      "MAPTensor([2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.int32)\n",
      "MAPTensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.int32)\n",
      "Index is Correct: (f ==f_idx)=True\n",
      "Count is correct: simf[f_idx]=MAPTensor(2, dtype=torch.int32), (simf[f_idx]==5)=MAPTensor(False)\n",
      "Index is Correct: (b ==b_idx)=True\n",
      "Count is correct: simb[b_idx]=MAPTensor(1, dtype=torch.int32), (simb[b_idx]==3)=MAPTensor(False)\n",
      "\n",
      "--------------------------------\n",
      "\n",
      "###############<VSAModel.VTB: 'VTB'>\n",
      "VTBTensor([2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.int32)\n",
      "VTBTensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.int32)\n",
      "Index is Correct: (f ==f_idx)=True\n",
      "Count is correct: simf[f_idx]=VTBTensor(2, dtype=torch.int32), (simf[f_idx]==5)=VTBTensor(False)\n",
      "Index is Correct: (b ==b_idx)=True\n",
      "Count is correct: simb[b_idx]=VTBTensor(1, dtype=torch.int32), (simb[b_idx]==3)=VTBTensor(False)\n",
      "\n",
      "--------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchhd\n",
    "from src.encoding.configs_and_constants import VSAModel\n",
    "\n",
    "#### HRR\n",
    "# Fix a small dimension for demo\n",
    "D = 256\n",
    "vsa = VSAModel.HRR\n",
    "# Create two random MAP hypervectors of shape [2]\n",
    "fruits = torchhd.random(16, D, vsa=vsa.value)\n",
    "books = torchhd.random(10, D, vsa=vsa.value)\n",
    "\n",
    "f = 0\n",
    "b = 0\n",
    "bundle = torchhd.multibundle(\n",
    "    torch.stack(\n",
    "        [\n",
    "            fruits[f],\n",
    "            fruits[f],\n",
    "            # fruits[f],\n",
    "            # fruits[f],\n",
    "            # fruits[f],\n",
    "            books[b],\n",
    "            # books[b],\n",
    "            # books[b],\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "simf = torch.round(torchhd.dot(bundle, fruits)).clamp(min=0)\n",
    "simb = torch.round(torchhd.dot(bundle, books)).clamp(min=0)\n",
    "\n",
    "print(f\"###############{repr(vsa)}\")\n",
    "print(simf)\n",
    "print(simb)\n",
    "f_idx = simf.argmax().item()\n",
    "print(f\"Index is Correct: {(f ==f_idx)=}\")\n",
    "print(f\"Count is correct: {simf[f_idx]=}, {(simf[f_idx]==5)=}\")\n",
    "b_idx = simb.argmax().item()\n",
    "print(f\"Index is Correct: {(b ==b_idx)=}\")\n",
    "print(f\"Count is correct: {simb[b_idx]=}, {(simb[b_idx]==3)=}\")\n",
    "print(\"\\n--------------------------------\\n\")\n",
    "\n",
    "\n",
    "#### FHRR\n",
    "# Fix a small dimension for demo\n",
    "vsa = VSAModel.FHRR\n",
    "# Create two random MAP hypervectors of shape [2]\n",
    "fruits = torchhd.random(16, D, vsa=vsa.value)\n",
    "books = torchhd.random(10, D, vsa=vsa.value)\n",
    "\n",
    "bundle = torchhd.multibundle(\n",
    "    torch.stack(\n",
    "        [\n",
    "            fruits[f],\n",
    "            fruits[f],\n",
    "            # fruits[f],\n",
    "            # fruits[f],\n",
    "            # fruits[f],\n",
    "            books[b],\n",
    "            # books[b],\n",
    "            # books[b],\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "simf = (torchhd.dot(bundle, fruits) / D).round().int().clamp(min=0)\n",
    "simb = torch.round(torchhd.dot(bundle, books) / D).clamp(min=0)\n",
    "\n",
    "print(f\"###############{repr(vsa)}\")\n",
    "print(simf)\n",
    "print(simb)\n",
    "f_idx = simf.argmax().item()\n",
    "print(f\"Index is Correct: {(f ==f_idx)=}\")\n",
    "print(f\"Count is correct: {simf[f_idx]=}, {(simf[f_idx]==5)=}\")\n",
    "b_idx = simb.argmax().item()\n",
    "print(f\"Index is Correct: {(b ==b_idx)=}\")\n",
    "print(f\"Count is correct: {simb[b_idx]=}, {(simb[b_idx]==3)=}\")\n",
    "print(\"\\n--------------------------------\\n\")\n",
    "\n",
    "#### FHRR\n",
    "# Fix a small dimension for demo\n",
    "vsa = VSAModel.MAP\n",
    "# Create two random MAP hypervectors of shape [2]\n",
    "fruits = torchhd.random(16, D, vsa=vsa.value)\n",
    "books = torchhd.random(10, D, vsa=vsa.value)\n",
    "\n",
    "bundle = torchhd.multibundle(\n",
    "    torch.stack(\n",
    "        [\n",
    "            fruits[f],\n",
    "            fruits[f],\n",
    "            # fruits[f],\n",
    "            # fruits[f],\n",
    "            # fruits[f],\n",
    "            books[b],\n",
    "            # books[b],\n",
    "            # books[b],\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "simf = (torchhd.dot(bundle, fruits) / D).round().int().clamp(min=0)\n",
    "simb = (torchhd.dot(bundle, books) / D).round().int().clamp(min=0)\n",
    "\n",
    "print(f\"###############{repr(vsa)}\")\n",
    "print(simf)\n",
    "print(simb)\n",
    "f_idx = simf.argmax().item()\n",
    "print(f\"Index is Correct: {(f ==f_idx)=}\")\n",
    "print(f\"Count is correct: {simf[f_idx]=}, {(simf[f_idx]==5)=}\")\n",
    "b_idx = simb.argmax().item()\n",
    "print(f\"Index is Correct: {(b ==b_idx)=}\")\n",
    "print(f\"Count is correct: {simb[b_idx]=}, {(simb[b_idx]==3)=}\")\n",
    "print(\"\\n--------------------------------\\n\")\n",
    "\n",
    "\n",
    "#### VTB\n",
    "# Fix a small dimension for demo\n",
    "vsa = VSAModel.VTB\n",
    "# Create two random MAP hypervectors of shape [2]\n",
    "fruits = torchhd.random(16, D, vsa=vsa.value)\n",
    "books = torchhd.random(10, D, vsa=vsa.value)\n",
    "\n",
    "bundle = torchhd.multibundle(\n",
    "    torch.stack(\n",
    "        [\n",
    "            fruits[f],\n",
    "            fruits[f],\n",
    "            # fruits[f],\n",
    "            # fruits[f],\n",
    "            # fruits[f],\n",
    "            books[b],\n",
    "            # books[b],\n",
    "            # books[b],\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "simf = (torchhd.dot(bundle, fruits)).round().int().clamp(min=0)\n",
    "simb = (torchhd.dot(bundle, books)).round().int().clamp(min=0)\n",
    "\n",
    "print(f\"###############{repr(vsa)}\")\n",
    "print(simf)\n",
    "print(simb)\n",
    "f_idx = simf.argmax().item()\n",
    "print(f\"Index is Correct: {(f ==f_idx)=}\")\n",
    "print(f\"Count is correct: {simf[f_idx]=}, {(simf[f_idx]==5)=}\")\n",
    "b_idx = simb.argmax().item()\n",
    "print(f\"Index is Correct: {(b ==b_idx)=}\")\n",
    "print(f\"Count is correct: {simb[b_idx]=}, {(simb[b_idx]==3)=}\")\n",
    "print(\"\\n--------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a92f54bcac4c7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "881cbe24cbdb0b7a",
   "metadata": {},
   "source": "## Dtypes"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f3491bb036b4dd7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T08:32:18.449373Z",
     "start_time": "2025-06-06T08:32:18.446647Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vsa:MAP, t.dtype:torch.float32\n",
      "vsa:HRR, t.dtype:torch.float32\n",
      "vsa:FHRR, t.dtype:torch.complex64\n",
      "vsa:VTB, t.dtype:torch.float32\n"
     ]
    }
   ],
   "source": [
    "from src.encoding.configs_and_constants import VSAModel\n",
    "import torchhd\n",
    "\n",
    "for vsa in VSAModel:\n",
    "    t = torchhd.random(1, 1, vsa=vsa.value)\n",
    "    print(f\"vsa:{vsa.value}, t.dtype:{t.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829fec0bcbcdb32",
   "metadata": {},
   "source": "## Multiple Node Feature Decoding"
  },
  {
   "cell_type": "code",
   "id": "a86e960b64549949",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T19:22:44.932163Z",
     "start_time": "2025-06-06T19:22:44.896718Z"
    }
   },
   "source": [
    "import torch\n",
    "import torchhd\n",
    "from src.encoding.configs_and_constants import VSAModel\n",
    "from src.utils.utils import cartesian_bind_tensor\n",
    "from collections import defaultdict\n",
    "\n",
    "vsa = VSAModel.HRR\n",
    "D = 1000\n",
    "fruits = torchhd.random(10, D, vsa=vsa.value)\n",
    "veggies = torchhd.random(6, D, vsa=vsa.value)\n",
    "\n",
    "nodes = [\n",
    "    torchhd.bind(fruits[0], veggies[0]),\n",
    "    torchhd.bind(fruits[0], veggies[0]),\n",
    "    torchhd.bind(fruits[0], veggies[0]),\n",
    "    torchhd.bind(fruits[0], veggies[2]),\n",
    "    torchhd.bind(fruits[0], veggies[4]),\n",
    "    torchhd.bind(fruits[1], veggies[0]),\n",
    "    torchhd.bind(fruits[1], veggies[0]),\n",
    "    torchhd.bind(fruits[1], veggies[0]),\n",
    "    torchhd.bind(fruits[1], veggies[2]),\n",
    "    torchhd.bind(fruits[1], veggies[4]),\n",
    "    torchhd.bind(fruits[2], veggies[0]),\n",
    "    torchhd.bind(fruits[2], veggies[0]),\n",
    "    torchhd.bind(fruits[2], veggies[0]),\n",
    "    torchhd.bind(fruits[2], veggies[2]),\n",
    "    torchhd.bind(fruits[2], veggies[4]),\n",
    "    torchhd.bind(fruits[3], veggies[0]),\n",
    "    torchhd.bind(fruits[3], veggies[0]),\n",
    "    torchhd.bind(fruits[3], veggies[0]),\n",
    "    torchhd.bind(fruits[3], veggies[2]),\n",
    "    torchhd.bind(fruits[3], veggies[4]),\n",
    "]\n",
    "embedding_0 = torchhd.multiset(torch.stack(nodes, dim=0))\n",
    "\n",
    "node_codebook = cartesian_bind_tensor([fruits, veggies])\n",
    "\n",
    "sim_node = torchhd.dot(embedding_0, node_codebook).round().int().clamp(min=0)\n",
    "## This should print 3, 0, 1, 0, 1, 0, 3, .... so many time as there items.\n",
    "## And it does, so it should work\n",
    "print(sim_node)\n",
    "\n",
    "\n",
    "## Now level 1\n",
    "edge_idx = list(zip(range(len(nodes)), range(len(nodes))))\n",
    "\n",
    "edge_dict = defaultdict(list)\n",
    "for src, dst in edge_idx:\n",
    "    edge_dict[src].append(dst)\n",
    "print(edge_dict)\n",
    "\n",
    "edge_term_bindings = [torchhd.bind(nodes[src], torchhd.multiset(torch.stack([nodes[dst] for dst in dsts], dim=0))) for src, dsts in edge_dict.items()]\n",
    "edge_terms = torchhd.multiset(torch.stack(edge_term_bindings, dim=0))\n",
    "embedding_1 = torchhd.multiset(torch.stack([embedding_0, edge_terms], dim=0))\n",
    "\n",
    "edge_codebook = cartesian_bind_tensor([node_codebook, node_codebook])\n",
    "\n",
    "sim_edge = torchhd.dot(embedding_1, edge_terms).round().int().clamp(min=0)\n",
    "## This should print 3, 0, 1, 0, 1, 0, 3, .... so many time as there items.\n",
    "## And it does, so it should work\n",
    "print(sim_edge)\n",
    "print(sim_edge.sum().item())\n",
    "print(len(nodes)*2)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HRRTensor([3, 0, 1, 0, 1, 0, 4, 0, 2, 0, 1, 0, 3, 0, 1, 0, 1, 0, 3, 0, 1, 0, 1,\n",
      "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.int32)\n",
      "defaultdict(<class 'list'>, {0: [0], 1: [1], 2: [2], 3: [3], 4: [4], 5: [5], 6: [6], 7: [7], 8: [8], 9: [9], 10: [10], 11: [11], 12: [12], 13: [13], 14: [14], 15: [15], 16: [16], 17: [17], 18: [18], 19: [19]})\n",
      "HRRTensor(167, dtype=torch.int32)\n",
      "167\n",
      "40\n"
     ]
    }
   ],
   "execution_count": 61
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
