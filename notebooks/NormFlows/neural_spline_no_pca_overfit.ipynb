{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-14T14:04:00.490091Z",
     "start_time": "2025-07-14T13:56:48.616700Z"
    }
   },
   "source": [
    "import datetime\n",
    "import random\n",
    "import shutil\n",
    "import string\n",
    "import time\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from torch.utils.data import Dataset\n",
    "from torch_geometric.data import Batch\n",
    "from torch_geometric.datasets import ZINC\n",
    "\n",
    "from src.datasets import AddNodeDegree\n",
    "from src.encoding.configs_and_constants import SupportedDataset\n",
    "from src.encoding.graph_encoders import HyperNet\n",
    "from src.encoding.the_types import VSAModel\n",
    "from src.normalizing_flow.models import NeuralSplineLightning\n",
    "\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import Callback, LearningRateMonitor, ModelCheckpoint\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "from sklearn.decomposition import PCA\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data import Subset\n",
    "from torch_geometric.datasets import ZINC\n",
    "\n",
    "from graph_hdc.utils import AbstractEncoder\n",
    "from src.datasets import AddNodeDegree\n",
    "from src.encoding.configs_and_constants import DSHDCConfig, SupportedDataset\n",
    "from src.encoding.graph_encoders import HyperNet\n",
    "from src.encoding.the_types import VSAModel\n",
    "from src.normalizing_flow.config import FlowConfig\n",
    "from src.normalizing_flow.models import NeuralSplineLightning\n",
    "\n",
    "\n",
    "def setup_exp(ds_value: str) -> dict:\n",
    "    \"\"\"\n",
    "    Sets up experiment directories based on the current script location.\n",
    "\n",
    "    Args:\n",
    "        ds_value (str): Dataset name to use for global_dataset_dir.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary containing paths to various directories.\n",
    "    \"\"\"\n",
    "    # Resolve script location\n",
    "    script_path = Path(\"/Users/arvandkaveh/Projects/kit/graph_hdc/notebooks/NormFlows/real_nvp.ipynb\")\n",
    "    experiments_path = script_path.parent\n",
    "    script_stem = script_path.stem  # without .py\n",
    "\n",
    "    # Resolve base and project directories\n",
    "    base_dir = experiments_path / \"results\" / script_stem\n",
    "    base_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    project_dir = script_path.parents[2]  # adjust as needed\n",
    "\n",
    "    print(f\"Setting up experiment in {base_dir}\")\n",
    "    now = f\"{datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}_{''.join(random.choices(string.ascii_lowercase, k=4))}\"\n",
    "    exp_dir = base_dir / now\n",
    "    exp_dir.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"Experiment directory created: {exp_dir}\")\n",
    "\n",
    "    dirs = {\n",
    "        \"exp_dir\": exp_dir,\n",
    "        \"models_dir\": exp_dir / \"models\",\n",
    "        \"evals_dir\": exp_dir / \"evaluations\",\n",
    "        \"artefacts_dir\": exp_dir / \"artefacts\",\n",
    "        \"global_model_dir\": project_dir / \"_models\",\n",
    "        \"global_dataset_dir\": project_dir / \"_datasets\" / ds_value,\n",
    "    }\n",
    "\n",
    "    for d in dirs.values():\n",
    "        d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Save a copy of the script\n",
    "    try:\n",
    "        shutil.copy(script_path, exp_dir / script_path.name)\n",
    "        print(f\"Saved a copy of the script to {exp_dir / script_path.name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Failed to save script copy: {e}\")\n",
    "\n",
    "    return dirs\n",
    "\n",
    "\n",
    "def plot_train_val_loss(df, artefacts_dir):\n",
    "    train = df[df[\"train_loss_epoch\"].notna()]\n",
    "    val = df[df[\"val_loss\"].notna()]\n",
    "\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(train[\"epoch\"], train[\"train_loss_epoch\"], label=\"Train Loss\")\n",
    "    plt.plot(val[\"epoch\"], val[\"val_loss\"], label=\"Validation Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Train vs. Validation Loss\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "\n",
    "    artefacts_dir.mkdir(exist_ok=True)\n",
    "    plt.savefig(artefacts_dir / \"train_val_loss.png\")\n",
    "    plt.close()\n",
    "    print(f\"Saved train/val loss plot to {artefacts_dir / 'train_val_loss.png'}\")\n",
    "\n",
    "\n",
    "def pca_encode(x: torch.Tensor, pca: PCA, norm: bool = False) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Encode data using a fitted PCA, with optional normalization.\n",
    "\n",
    "    :param x: Input tensor of shape (..., features).\n",
    "    :type x: torch.Tensor\n",
    "    :param pca: Fitted PCA instance with attributes `mean_` and `std_`.\n",
    "    :type pca: PCA\n",
    "    :param norm: Whether to normalize input by mean and std before PCA.\n",
    "    :type norm: bool\n",
    "    :returns: Tensor of reduced dimensions, same dtype as input.\n",
    "    :rtype: torch.Tensor\n",
    "\n",
    "    The input is flattened over all but the last dimension, optionally normalized,\n",
    "    transformed with the PCA, then returned as a tensor.\n",
    "    \"\"\"\n",
    "    flat = x.view(-1, x.shape[-1]).cpu().numpy()\n",
    "    if norm:\n",
    "        flat = (flat - pca.mean_) / pca.std_\n",
    "    reduced = pca.transform(flat)\n",
    "    return torch.tensor(reduced, dtype=x.dtype)\n",
    "\n",
    "\n",
    "def load_or_fit_pca(\n",
    "        train_dataset: Dataset, encoder: AbstractEncoder, pca_path: Path | None = None, n_components: float = 0.99999,\n",
    "        n_fit: int = 20000\n",
    ") -> PCA:\n",
    "    \"\"\"\n",
    "    Load an existing PCA from disk or fit a new one and save it.\n",
    "\n",
    "    :param train_dataset: Dataset for fitting PCA.\n",
    "    :type train_dataset: Dataset\n",
    "    :param encoder: Model or function returning a dict with keys \\\"node_terms\\\", \\\"edge_terms\\\", and \\\"graph_embedding\\\".\n",
    "    :param pca_path: Path to load/save the PCA object.\n",
    "    :type pca_path: Path\n",
    "    :param n_components: Number of components or variance ratio for PCA.\n",
    "    :type n_components: float\n",
    "    :param n_fit: Maximum number of samples to fit PCA on.\n",
    "    :type n_fit: int\n",
    "    :returns: Fitted PCA instance with `mean_` and `std_` attributes.\n",
    "    :rtype: PCA\n",
    "\n",
    "    If a PCA exists at `pca_path`, it is loaded. Otherwise, embeddings\n",
    "    are collected by applying `encoder` to dataset entries until `n_fit`\n",
    "    samples, flattened, and used to fit a new PCA. The mean and std of the\n",
    "    fit data are stored on the PCA for later normalization.\n",
    "    \"\"\"\n",
    "    if pca_path is not None and pca_path.exists():\n",
    "        print(f\"Loading existing PCA from {pca_path}\")\n",
    "        pca = joblib.load(pca_path)\n",
    "        print(f\"Loaded PCA with {pca.n_components_} components\")\n",
    "        return pca\n",
    "\n",
    "    print(\"Fitting PCA on training data...\")\n",
    "    n_fit = min(n_fit, len(train_dataset))\n",
    "    X_fit = []\n",
    "    for i in range(n_fit):\n",
    "        data = train_dataset[i]\n",
    "        batch_data = Batch.from_data_list([data])\n",
    "        res = encoder.forward(data=batch_data)\n",
    "        x = torch.stack(\n",
    "            [res[\"node_terms\"].squeeze(0), res[\"edge_terms\"].squeeze(0), res[\"graph_embedding\"].squeeze(0)], dim=0\n",
    "        )  # [3, D]\n",
    "        X_fit.append(x.cpu().numpy())\n",
    "    X_fit = np.stack(X_fit)\n",
    "    X_fit_flat = X_fit.reshape(-1, X_fit.shape[-1])\n",
    "\n",
    "    # Compute mean and std for normalization\n",
    "    mu = np.mean(X_fit_flat, axis=0)\n",
    "    sigma = np.std(X_fit_flat, axis=0)\n",
    "\n",
    "    # Fit PCA\n",
    "    pca = PCA(n_components=n_components, svd_solver=\"full\")\n",
    "    pca.fit(X_fit_flat)\n",
    "\n",
    "    # Attach normalization stats\n",
    "    pca.mean_ = mu\n",
    "    pca.std_ = sigma\n",
    "\n",
    "    print(f\"PCA reduced dimension: {pca.n_components_} from {X_fit.shape[-1]}\")\n",
    "    joblib.dump(pca, pca_path)\n",
    "    print(f\"Saved new PCA to {pca_path}\")\n",
    "    return pca\n",
    "\n",
    "\n",
    "def load_or_create_hypernet(path: Path, ds: SupportedDataset, depth: int) -> HyperNet:\n",
    "    ds_name = ds.name\n",
    "    if ds.default_cfg.nha_depth:\n",
    "        ds_name = f\"{ds_name}-nha-d{ds.default_cfg.nha_depth}\"\n",
    "    if ds.default_cfg.nha_bins:\n",
    "        ds_name = f\"{ds_name}-nha-b{ds.default_cfg.nha_bins}\"\n",
    "    path = path / f\"hypernet_ds{ds.name}_{ds.default_cfg.vsa.value}_d{cfg.hv_dim}_s{cfg.seed}_dpth{depth}.pt\"\n",
    "    if path.exists():\n",
    "        print(f\"Loading existing HyperNet from {path}\")\n",
    "        encoder = HyperNet(config=ds.default_cfg, depth=depth)\n",
    "        encoder.load(path)\n",
    "    else:\n",
    "        print(\"Creating new HyperNet instance.\")\n",
    "        encoder = HyperNet(config=ds.default_cfg, depth=depth)\n",
    "        encoder.populate_codebooks()\n",
    "        encoder.save_to_path(path)\n",
    "        print(f\"Saved new HyperNet to {path}\")\n",
    "    return encoder\n",
    "\n",
    "\n",
    "class EncodedPCADataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, base_dataset, encoder: AbstractEncoder, pca: PCA | None = None, *, use_norm_pca: bool = False):\n",
    "        self.base_dataset = base_dataset\n",
    "        self.encoder = encoder\n",
    "        self.pca = pca\n",
    "        self.use_norm = use_norm_pca  # Whether to normalize the PCA\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.base_dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = self.base_dataset[idx]\n",
    "        batch_data = Batch.from_data_list([data])\n",
    "        res = self.encoder.forward(data=batch_data)\n",
    "        x = torch.stack(\n",
    "            [res[\"node_terms\"].squeeze(0), res[\"edge_terms\"].squeeze(0), res[\"graph_embedding\"].squeeze(0)], dim=0\n",
    "        )\n",
    "        if self.pca is not None:\n",
    "            return pca_encode(x, self.pca, self.use_norm)\n",
    "        return x\n",
    "\n",
    "\n",
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        count = torch.cuda.device_count()\n",
    "        print(f\"CUDA is available. Detected {count} GPU device{'s' if count != 1 else ''}.\")\n",
    "        return torch.device(\"cuda\")\n",
    "    print(\"CUDA is not available.\")\n",
    "    return torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "class TimeLoggingCallback(Callback):\n",
    "    def setup(self, trainer, pl_module, stage=None):\n",
    "        self.start_time = time.time()\n",
    "\n",
    "    def on_train_epoch_end(self, trainer, pl_module):\n",
    "        elapsed = time.time() - self.start_time\n",
    "        trainer.logger.log_metrics({\"elapsed_time_sec\": elapsed}, step=trainer.current_epoch)\n",
    "\n",
    "\n",
    "class DebugMetricsCallback(Callback):\n",
    "    def on_train_epoch_end(self, trainer, pl_module):\n",
    "        print(\"\\n==> callback_metrics:\")\n",
    "        for k, v in trainer.callback_metrics.items():\n",
    "            print(f\"   {k:20s} → {type(v)}\")\n",
    "        print()\n",
    "\n",
    "\n",
    "class SamplingEveryNEpoch(Callback):\n",
    "    def __init__(self, encoder, n_samples: int = 10, every_n_epochs: int = 10):\n",
    "        \"\"\"\n",
    "        :param encoder: your graph‐reconstruction encoder, with `.decode_order_zero_counter()`\n",
    "        :param n_samples: how many samples to draw\n",
    "        :param every_n_epochs: interval at which to run the sampling\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.n_samples = n_samples\n",
    "        self.every_n = every_n_epochs\n",
    "\n",
    "    def on_train_epoch_start(self, trainer, pl_module):\n",
    "        epoch = trainer.current_epoch\n",
    "        if epoch % self.every_n != 0:\n",
    "            return\n",
    "\n",
    "        device = pl_module.device\n",
    "        print(f\"{device=}\")\n",
    "        self.encoder.to(device)\n",
    "\n",
    "        pl_module.eval()\n",
    "        with torch.no_grad():\n",
    "            print(f\"\\n=== Sampling callback at epoch {epoch} ===\")\n",
    "            # ---- Sampling example ----\n",
    "            z, logs = pl_module.sample(self.n_samples)\n",
    "            print(f\"\\n=== Finished sampling ===\")\n",
    "            z = z.to(device)\n",
    "\n",
    "            # if you had a PCA decode step:\n",
    "            # z = pca_decode(z, pca)\n",
    "\n",
    "            # unpack into (batch, 3, D)\n",
    "            node_terms_s, _, _ = z.unbind(dim=1)\n",
    "\n",
    "            # Cast to HRRTensor\n",
    "            node_terms_hrr = node_terms_s.as_subclass(HRRTensor)\n",
    "\n",
    "            for b in range(self.n_samples):\n",
    "                print(f\"-- SAMPLE #{b} --\")\n",
    "                node_counter = self.encoder.decode_order_zero_counter(node_terms_hrr[b])\n",
    "                print(f\"node_counter[0] = {node_counter[0]}\")\n",
    "                print(f\"  total = {node_counter[0].total()}\")\n",
    "        pl_module.train()\n",
    "\n",
    "\n",
    "hv_dim = 60 * 60\n",
    "batch_size = 2\n",
    "cfg = FlowConfig(\n",
    "    project_dir=\"/Users/arvandkaveh/Projects/kit/graph_hdc\",\n",
    "    seed=42,\n",
    "    epochs=500,\n",
    "    batch_size=batch_size,\n",
    "    vsa=VSAModel.HRR,\n",
    "    hv_dim=hv_dim,\n",
    "    dataset=SupportedDataset.ZINC_NODE_DEGREE_COMB,\n",
    "    num_input_channels=3 * hv_dim,\n",
    "    num_flows=16,\n",
    "    num_hidden_channels=128,\n",
    "    input_shape=(3, hv_dim),\n",
    "    lr=0.00003,\n",
    "    weight_decay=0.0001,\n",
    ")\n",
    "\n",
    "print(\"Running experiment\")\n",
    "pprint(cfg.__dict__, indent=2)\n",
    "\n",
    "dirs = setup_exp(cfg.dataset.value)\n",
    "exp_dir = dirs[\"exp_dir\"]\n",
    "models_dir = dirs[\"models_dir\"]\n",
    "evals_dir = dirs[\"evals_dir\"]\n",
    "artefacts_dir = dirs[\"artefacts_dir\"]\n",
    "global_model_dir = dirs[\"global_model_dir\"]\n",
    "global_dataset_dir = dirs[\"global_dataset_dir\"]\n",
    "\n",
    "# W&B Logging — use existing run (from sweep or manual init)\n",
    "# run = wandb.run or wandb.init(project=\"realnvp-hdc\", config=cfg.__dict__, name=f\"run_{cfg.hv_dim}_{cfg.seed}\", reinit=True)\n",
    "# run.tags = [f\"hv_dim={cfg.hv_dim}\", f\"vsa={cfg.vsa.value}\", f\"dataset={cfg.dataset.value}\"]\n",
    "\n",
    "# wandb_logger = WandbLogger(log_model=True, experiment=run)\n",
    "\n",
    "train_data = ZINC(root=str(global_dataset_dir), pre_transform=AddNodeDegree(), split=\"train\", subset=True)[:1]\n",
    "# make a length-4 dataset by selecting index 0 four times\n",
    "train_dataset = Subset(train_data, indices=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
    "print(f\"Train length = {len(train_dataset)}\")  # → 4\n",
    "print(train_dataset[0])\n",
    "validation_data = ZINC(root=str(global_dataset_dir), pre_transform=AddNodeDegree(), split=\"val\", subset=True)[:1]\n",
    "validation_dataset = Subset(validation_data, indices=[0, 0, 0, 0])\n",
    "print(f\"{len(validation_dataset)=}\")\n",
    "print(validation_dataset[0])\n",
    "\n",
    "device = get_device()\n",
    "ds = cfg.dataset\n",
    "ds.default_cfg.vsa = cfg.vsa\n",
    "ds.default_cfg.hv_dim = cfg.hv_dim\n",
    "ds.default_cfg.device = device\n",
    "ds.default_cfg.seed = cfg.seed\n",
    "ds.default_cfg.edge_feature_configs = {}\n",
    "ds.default_cfg.graph_feature_configs = {}\n",
    "\n",
    "encoder = load_or_create_hypernet(path=global_model_dir, cfg=ds.default_cfg, depth=3)\n",
    "\n",
    "n_components = 0.998\n",
    "pca_path = global_model_dir / f\"hypervec_pca_{cfg.vsa.value}_d{cfg.hv_dim}_s{cfg.seed}_c{str(n_components)[2:]}.joblib\"\n",
    "# pca = load_or_fit_pca(\n",
    "#     train_dataset=ZINC(root=str(global_dataset_dir), pre_transform=AddNodeDegree(), split=\"train\", subset=True),\n",
    "#     encoder=encoder,\n",
    "#     pca_path=pca_path,\n",
    "#     n_components=n_components,\n",
    "#     n_fit=20_000,\n",
    "# )\n",
    "\n",
    "# reduced_dim = int(pca.n_components_)\n",
    "cfg.num_input_channels = 3 * hv_dim\n",
    "cfg.input_shape = (3, hv_dim)\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    EncodedPCADataset(train_dataset, encoder),\n",
    "    batch_size=cfg.batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    pin_memory=torch.cuda.is_available(),\n",
    "    drop_last=True,\n",
    ")\n",
    "validation_dataloader = DataLoader(\n",
    "    EncodedPCADataset(validation_dataset, encoder),\n",
    "    batch_size=cfg.batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=torch.cuda.is_available(),\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "model = NeuralSplineLightning(cfg)\n",
    "\n",
    "csv_logger = CSVLogger(save_dir=str(evals_dir), name=\"logs\")\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor=\"val_loss\",\n",
    "    save_top_k=2,\n",
    "    mode=\"min\",\n",
    "    dirpath=str(models_dir),\n",
    "    filename=\"epoch{epoch:02d}-val{val_loss:.2f}\",\n",
    "    save_last=True,\n",
    ")\n",
    "lr_monitor = LearningRateMonitor(logging_interval=\"epoch\")\n",
    "time_logger = TimeLoggingCallback()\n",
    "# debug_callback = DebugMetricsCallback()\n",
    "sampling_cb = SamplingEveryNEpoch(encoder=encoder, n_samples=1, every_n_epochs=10)\n",
    "\n",
    "trainer = Trainer(\n",
    "    max_epochs=cfg.epochs,\n",
    "    logger=[csv_logger,\n",
    "            # wandb_logger\n",
    "            ],\n",
    "    callbacks=[checkpoint_callback, lr_monitor, time_logger,\n",
    "               # debug_callback,\n",
    "               # sampling_cb\n",
    "               ],\n",
    "    default_root_dir=str(exp_dir),\n",
    "    accelerator=\"auto\",\n",
    "    log_every_n_steps=4,\n",
    "    enable_progress_bar=True,\n",
    "    # detect_anomaly=True,\n",
    ")\n",
    "\n",
    "trainer.fit(model, train_dataloaders=train_dataloader,\n",
    "            val_dataloaders=validation_dataloader\n",
    "            )\n",
    "\n",
    "torch.save(model.state_dict(), models_dir / \"final_model.pt\")\n",
    "\n",
    "metrics_path = Path(csv_logger.log_dir) / \"metrics.csv\"\n",
    "if metrics_path.exists():\n",
    "    df = pd.read_csv(metrics_path)\n",
    "    df.to_parquet(evals_dir / \"metrics.parquet\")\n",
    "    plot_train_val_loss(df, artefacts_dir)\n",
    "\n",
    "print(\"==== The Experiment is done! ====\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment\n",
      "{ 'activation': <class 'torch.nn.modules.activation.ReLU'>,\n",
      "  'batch_size': 2,\n",
      "  'dataset': <SupportedDataset.ZINC_NODE_DEGREE_COMB: 'ZINC_ND_COMB'>,\n",
      "  'device': 'cpu',\n",
      "  'dropout_probability': 0.0,\n",
      "  'epochs': 500,\n",
      "  'exp_dir': None,\n",
      "  'flow_type': <class 'normflows.flows.neural_spline.wrapper.AutoregressiveRationalQuadraticSpline'>,\n",
      "  'hv_dim': 3600,\n",
      "  'init_identity': True,\n",
      "  'input_shape': (3, 3600),\n",
      "  'lr': 3e-05,\n",
      "  'num_bins': 8,\n",
      "  'num_blocks': 2,\n",
      "  'num_context_channels': None,\n",
      "  'num_flows': 16,\n",
      "  'num_hidden_channels': 128,\n",
      "  'num_input_channels': 10800,\n",
      "  'permute': False,\n",
      "  'project_dir': PosixPath('/Users/arvandkaveh/Projects/kit/graph_hdc'),\n",
      "  'seed': 42,\n",
      "  'tail_bound': 3,\n",
      "  'vsa': <VSAModel.HRR: 'HRR'>,\n",
      "  'weight_decay': 0.0001}\n",
      "Setting up experiment in /Users/arvandkaveh/Projects/kit/graph_hdc/notebooks/NormFlows/results/real_nvp\n",
      "Experiment directory created: /Users/arvandkaveh/Projects/kit/graph_hdc/notebooks/NormFlows/results/real_nvp/2025-07-14_15-56-53_wtvj\n",
      "Saved a copy of the script to /Users/arvandkaveh/Projects/kit/graph_hdc/notebooks/NormFlows/results/real_nvp/2025-07-14_15-56-53_wtvj/real_nvp.ipynb\n",
      "Train length = 16\n",
      "Data(x=[29, 2], edge_index=[2, 64], edge_attr=[64], y=[1])\n",
      "len(validation_dataset)=4\n",
      "Data(x=[35, 2], edge_index=[2, 78], edge_attr=[78], y=[1])\n",
      "CUDA is not available.\n",
      "Loading existing HyperNet from /Users/arvandkaveh/Projects/kit/graph_hdc/_models/hypernet_HRR_d3600_s42_dpth3.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name | Type            | Params | Mode \n",
      "-------------------------------------------------\n",
      "0 | flow | NormalizingFlow | 535 M  | train\n",
      "-------------------------------------------------\n",
      "535 M     Trainable params\n",
      "0         Non-trainable params\n",
      "535 M     Total params\n",
      "2,143.499 Total estimated model params size (MB)\n",
      "307       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arvandkaveh/Projects/kit/graph_hdc/.pixi/envs/default/lib/python3.13/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arvandkaveh/Projects/kit/graph_hdc/.pixi/envs/default/lib/python3.13/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 8/8 [00:07<00:00,  1.10it/s, v_num=0, train_loss_step=2.05e+9]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001B[A\n",
      "Validation:   0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:  50%|█████     | 1/2 [00:00<00:00,  4.47it/s]\u001B[A\n",
      "Validation DataLoader 0: 100%|██████████| 2/2 [00:00<00:00,  4.53it/s]\u001B[A\n",
      "Epoch 1: 100%|██████████| 8/8 [00:07<00:00,  1.13it/s, v_num=0, train_loss_step=2.05e+9, val_loss=1.84e+9, lr=3e-5, train_loss_epoch=2.05e+9]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001B[A\n",
      "Validation:   0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:  50%|█████     | 1/2 [00:00<00:00,  4.49it/s]\u001B[A\n",
      "Validation DataLoader 0: 100%|██████████| 2/2 [00:00<00:00,  4.60it/s]\u001B[A\n",
      "Epoch 2: 100%|██████████| 8/8 [00:07<00:00,  1.12it/s, v_num=0, train_loss_step=2.05e+9, val_loss=1.84e+9, lr=3e-5, train_loss_epoch=2.05e+9]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001B[A\n",
      "Validation:   0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:  50%|█████     | 1/2 [00:00<00:00,  4.70it/s]\u001B[A\n",
      "Validation DataLoader 0: 100%|██████████| 2/2 [00:00<00:00,  4.62it/s]\u001B[A\n",
      "Epoch 3: 100%|██████████| 8/8 [00:07<00:00,  1.05it/s, v_num=0, train_loss_step=2.05e+9, val_loss=1.84e+9, lr=3e-5, train_loss_epoch=2.05e+9]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001B[A\n",
      "Validation:   0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:  50%|█████     | 1/2 [00:00<00:00,  4.47it/s]\u001B[A\n",
      "Validation DataLoader 0: 100%|██████████| 2/2 [00:00<00:00,  4.43it/s]\u001B[A\n",
      "Epoch 4: 100%|██████████| 8/8 [00:07<00:00,  1.04it/s, v_num=0, train_loss_step=2.05e+9, val_loss=1.84e+9, lr=3e-5, train_loss_epoch=2.05e+9]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001B[A\n",
      "Validation:   0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:  50%|█████     | 1/2 [00:00<00:00,  4.87it/s]\u001B[A\n",
      "Validation DataLoader 0: 100%|██████████| 2/2 [00:00<00:00,  4.63it/s]\u001B[A\n",
      "Epoch 5: 100%|██████████| 8/8 [00:07<00:00,  1.02it/s, v_num=0, train_loss_step=2.05e+9, val_loss=1.84e+9, lr=3e-5, train_loss_epoch=2.05e+9]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001B[A\n",
      "Validation:   0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:  50%|█████     | 1/2 [00:00<00:00,  4.96it/s]\u001B[A\n",
      "Validation DataLoader 0: 100%|██████████| 2/2 [00:00<00:00,  4.87it/s]\u001B[A\n",
      "Epoch 6: 100%|██████████| 8/8 [00:08<00:00,  0.98it/s, v_num=0, train_loss_step=2.05e+9, val_loss=1.84e+9, lr=3e-5, train_loss_epoch=2.05e+9]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001B[A\n",
      "Validation:   0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:  50%|█████     | 1/2 [00:00<00:00,  4.58it/s]\u001B[A\n",
      "Validation DataLoader 0: 100%|██████████| 2/2 [00:00<00:00,  4.34it/s]\u001B[A\n",
      "Epoch 7: 100%|██████████| 8/8 [00:07<00:00,  1.04it/s, v_num=0, train_loss_step=2.05e+9, val_loss=1.84e+9, lr=3e-5, train_loss_epoch=2.05e+9]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001B[A\n",
      "Validation:   0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:  50%|█████     | 1/2 [00:00<00:00,  4.90it/s]\u001B[A\n",
      "Validation DataLoader 0: 100%|██████████| 2/2 [00:00<00:00,  4.77it/s]\u001B[A\n",
      "Epoch 8: 100%|██████████| 8/8 [00:08<00:00,  0.90it/s, v_num=0, train_loss_step=2.05e+9, val_loss=1.84e+9, lr=3e-5, train_loss_epoch=2.05e+9]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001B[A\n",
      "Validation:   0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:  50%|█████     | 1/2 [00:00<00:00,  3.77it/s]\u001B[A\n",
      "Validation DataLoader 0: 100%|██████████| 2/2 [00:00<00:00,  3.80it/s]\u001B[A\n",
      "Epoch 9: 100%|██████████| 8/8 [00:07<00:00,  1.05it/s, v_num=0, train_loss_step=2.05e+9, val_loss=1.84e+9, lr=3e-5, train_loss_epoch=2.05e+9]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001B[A\n",
      "Validation:   0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:  50%|█████     | 1/2 [00:00<00:00,  4.78it/s]\u001B[A\n",
      "Validation DataLoader 0: 100%|██████████| 2/2 [00:00<00:00,  4.53it/s]\u001B[A\n",
      "Epoch 10: 100%|██████████| 8/8 [00:07<00:00,  1.00it/s, v_num=0, train_loss_step=2.05e+9, val_loss=1.84e+9, lr=3e-5, train_loss_epoch=2.05e+9]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001B[A\n",
      "Validation:   0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:  50%|█████     | 1/2 [00:00<00:00,  5.01it/s]\u001B[A\n",
      "Validation DataLoader 0: 100%|██████████| 2/2 [00:00<00:00,  4.88it/s]\u001B[A\n",
      "Epoch 11: 100%|██████████| 8/8 [00:08<00:00,  1.00it/s, v_num=0, train_loss_step=2.05e+9, val_loss=1.84e+9, lr=3e-5, train_loss_epoch=2.05e+9]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001B[A\n",
      "Validation:   0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:  50%|█████     | 1/2 [00:00<00:00,  4.96it/s]\u001B[A\n",
      "Validation DataLoader 0: 100%|██████████| 2/2 [00:00<00:00,  4.87it/s]\u001B[A\n",
      "Epoch 11: 100%|██████████| 8/8 [00:08<00:00,  0.94it/s, v_num=0, train_loss_step=2.05e+9, val_loss=1.84e+9, lr=3e-5, train_loss_epoch=2.05e+9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'exit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/kit/graph_hdc/.pixi/envs/default/lib/python3.13/site-packages/pytorch_lightning/trainer/call.py:47\u001B[39m, in \u001B[36m_call_and_handle_interrupt\u001B[39m\u001B[34m(trainer, trainer_fn, *args, **kwargs)\u001B[39m\n\u001B[32m     46\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)\n\u001B[32m---> \u001B[39m\u001B[32m47\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtrainer_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     49\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m _TunerExitException:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/kit/graph_hdc/.pixi/envs/default/lib/python3.13/site-packages/pytorch_lightning/trainer/trainer.py:574\u001B[39m, in \u001B[36mTrainer._fit_impl\u001B[39m\u001B[34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001B[39m\n\u001B[32m    568\u001B[39m ckpt_path = \u001B[38;5;28mself\u001B[39m._checkpoint_connector._select_ckpt_path(\n\u001B[32m    569\u001B[39m     \u001B[38;5;28mself\u001B[39m.state.fn,\n\u001B[32m    570\u001B[39m     ckpt_path,\n\u001B[32m    571\u001B[39m     model_provided=\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[32m    572\u001B[39m     model_connected=\u001B[38;5;28mself\u001B[39m.lightning_module \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[32m    573\u001B[39m )\n\u001B[32m--> \u001B[39m\u001B[32m574\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_run\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mckpt_path\u001B[49m\u001B[43m=\u001B[49m\u001B[43mckpt_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    576\u001B[39m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m.state.stopped\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/kit/graph_hdc/.pixi/envs/default/lib/python3.13/site-packages/pytorch_lightning/trainer/trainer.py:981\u001B[39m, in \u001B[36mTrainer._run\u001B[39m\u001B[34m(self, model, ckpt_path)\u001B[39m\n\u001B[32m    978\u001B[39m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n\u001B[32m    979\u001B[39m \u001B[38;5;66;03m# RUN THE TRAINER\u001B[39;00m\n\u001B[32m    980\u001B[39m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m981\u001B[39m results = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_run_stage\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    983\u001B[39m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n\u001B[32m    984\u001B[39m \u001B[38;5;66;03m# POST-Training CLEAN UP\u001B[39;00m\n\u001B[32m    985\u001B[39m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/kit/graph_hdc/.pixi/envs/default/lib/python3.13/site-packages/pytorch_lightning/trainer/trainer.py:1025\u001B[39m, in \u001B[36mTrainer._run_stage\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m   1024\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m torch.autograd.set_detect_anomaly(\u001B[38;5;28mself\u001B[39m._detect_anomaly):\n\u001B[32m-> \u001B[39m\u001B[32m1025\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mfit_loop\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1026\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/kit/graph_hdc/.pixi/envs/default/lib/python3.13/site-packages/pytorch_lightning/loops/fit_loop.py:206\u001B[39m, in \u001B[36m_FitLoop.run\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    205\u001B[39m \u001B[38;5;28mself\u001B[39m.advance()\n\u001B[32m--> \u001B[39m\u001B[32m206\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mon_advance_end\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    207\u001B[39m \u001B[38;5;28mself\u001B[39m._restarting = \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/kit/graph_hdc/.pixi/envs/default/lib/python3.13/site-packages/pytorch_lightning/loops/fit_loop.py:378\u001B[39m, in \u001B[36m_FitLoop.on_advance_end\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    377\u001B[39m call._call_lightning_module_hook(trainer, \u001B[33m\"\u001B[39m\u001B[33mon_train_epoch_end\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m--> \u001B[39m\u001B[32m378\u001B[39m \u001B[43mcall\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_call_callback_hooks\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrainer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mon_train_epoch_end\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmonitoring_callbacks\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[32m    380\u001B[39m trainer._logger_connector.on_epoch_end()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/kit/graph_hdc/.pixi/envs/default/lib/python3.13/site-packages/pytorch_lightning/trainer/call.py:218\u001B[39m, in \u001B[36m_call_callback_hooks\u001B[39m\u001B[34m(trainer, hook_name, monitoring_callbacks, *args, **kwargs)\u001B[39m\n\u001B[32m    217\u001B[39m         \u001B[38;5;28;01mwith\u001B[39;00m trainer.profiler.profile(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33m[Callback]\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcallback.state_key\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mhook_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m):\n\u001B[32m--> \u001B[39m\u001B[32m218\u001B[39m             \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrainer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrainer\u001B[49m\u001B[43m.\u001B[49m\u001B[43mlightning_module\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    220\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m pl_module:\n\u001B[32m    221\u001B[39m     \u001B[38;5;66;03m# restore current_fx when nested context\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/kit/graph_hdc/.pixi/envs/default/lib/python3.13/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:325\u001B[39m, in \u001B[36mModelCheckpoint.on_train_epoch_end\u001B[39m\u001B[34m(self, trainer, pl_module)\u001B[39m\n\u001B[32m    324\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._every_n_epochs >= \u001B[32m1\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m (trainer.current_epoch + \u001B[32m1\u001B[39m) % \u001B[38;5;28mself\u001B[39m._every_n_epochs == \u001B[32m0\u001B[39m:\n\u001B[32m--> \u001B[39m\u001B[32m325\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_save_topk_checkpoint\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrainer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmonitor_candidates\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    326\u001B[39m \u001B[38;5;28mself\u001B[39m._save_last_checkpoint(trainer, monitor_candidates)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/kit/graph_hdc/.pixi/envs/default/lib/python3.13/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:385\u001B[39m, in \u001B[36mModelCheckpoint._save_topk_checkpoint\u001B[39m\u001B[34m(self, trainer, monitor_candidates)\u001B[39m\n\u001B[32m    384\u001B[39m         warning_cache.warn(m)\n\u001B[32m--> \u001B[39m\u001B[32m385\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_save_monitor_checkpoint\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrainer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmonitor_candidates\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    386\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/kit/graph_hdc/.pixi/envs/default/lib/python3.13/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:705\u001B[39m, in \u001B[36mModelCheckpoint._save_monitor_checkpoint\u001B[39m\u001B[34m(self, trainer, monitor_candidates)\u001B[39m\n\u001B[32m    704\u001B[39m     \u001B[38;5;28;01massert\u001B[39;00m current \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m705\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_update_best_and_save\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcurrent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrainer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmonitor_candidates\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    706\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.verbose:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/kit/graph_hdc/.pixi/envs/default/lib/python3.13/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:757\u001B[39m, in \u001B[36mModelCheckpoint._update_best_and_save\u001B[39m\u001B[34m(self, current, trainer, monitor_candidates)\u001B[39m\n\u001B[32m    753\u001B[39m     rank_zero_info(\n\u001B[32m    754\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mEpoch \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;132;01m:\u001B[39;00m\u001B[33md\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m, global step \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mstep\u001B[38;5;132;01m:\u001B[39;00m\u001B[33md\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m.monitor\u001B[38;5;132;01m!r}\u001B[39;00m\u001B[33m reached \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcurrent\u001B[38;5;132;01m:\u001B[39;00m\u001B[33m0.5f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m\n\u001B[32m    755\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33m (best \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m.best_model_score\u001B[38;5;132;01m:\u001B[39;00m\u001B[33m0.5f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m), saving model to \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfilepath\u001B[38;5;132;01m!r}\u001B[39;00m\u001B[33m as top \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mk\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m\n\u001B[32m    756\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m757\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_save_checkpoint\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrainer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfilepath\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    759\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m del_filepath \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m._should_remove_checkpoint(trainer, del_filepath, filepath):\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/kit/graph_hdc/.pixi/envs/default/lib/python3.13/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:390\u001B[39m, in \u001B[36mModelCheckpoint._save_checkpoint\u001B[39m\u001B[34m(self, trainer, filepath)\u001B[39m\n\u001B[32m    389\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_save_checkpoint\u001B[39m(\u001B[38;5;28mself\u001B[39m, trainer: \u001B[33m\"\u001B[39m\u001B[33mpl.Trainer\u001B[39m\u001B[33m\"\u001B[39m, filepath: \u001B[38;5;28mstr\u001B[39m) -> \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m390\u001B[39m     \u001B[43mtrainer\u001B[49m\u001B[43m.\u001B[49m\u001B[43msave_checkpoint\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43msave_weights_only\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    392\u001B[39m     \u001B[38;5;28mself\u001B[39m._last_global_step_saved = trainer.global_step\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/kit/graph_hdc/.pixi/envs/default/lib/python3.13/site-packages/pytorch_lightning/trainer/trainer.py:1365\u001B[39m, in \u001B[36mTrainer.save_checkpoint\u001B[39m\u001B[34m(self, filepath, weights_only, storage_options)\u001B[39m\n\u001B[32m   1364\u001B[39m checkpoint = \u001B[38;5;28mself\u001B[39m._checkpoint_connector.dump_checkpoint(weights_only)\n\u001B[32m-> \u001B[39m\u001B[32m1365\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mstrategy\u001B[49m\u001B[43m.\u001B[49m\u001B[43msave_checkpoint\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcheckpoint\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfilepath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1366\u001B[39m \u001B[38;5;28mself\u001B[39m.strategy.barrier(\u001B[33m\"\u001B[39m\u001B[33mTrainer.save_checkpoint\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/kit/graph_hdc/.pixi/envs/default/lib/python3.13/site-packages/pytorch_lightning/strategies/strategy.py:490\u001B[39m, in \u001B[36mStrategy.save_checkpoint\u001B[39m\u001B[34m(self, checkpoint, filepath, storage_options)\u001B[39m\n\u001B[32m    489\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.is_global_zero:\n\u001B[32m--> \u001B[39m\u001B[32m490\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mcheckpoint_io\u001B[49m\u001B[43m.\u001B[49m\u001B[43msave_checkpoint\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcheckpoint\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfilepath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/kit/graph_hdc/.pixi/envs/default/lib/python3.13/site-packages/lightning_fabric/plugins/io/torch_io.py:58\u001B[39m, in \u001B[36mTorchCheckpointIO.save_checkpoint\u001B[39m\u001B[34m(self, checkpoint, path, storage_options)\u001B[39m\n\u001B[32m     57\u001B[39m fs.makedirs(os.path.dirname(path), exist_ok=\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[32m---> \u001B[39m\u001B[32m58\u001B[39m \u001B[43m_atomic_save\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcheckpoint\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpath\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/kit/graph_hdc/.pixi/envs/default/lib/python3.13/site-packages/lightning_fabric/utilities/cloud_io.py:90\u001B[39m, in \u001B[36m_atomic_save\u001B[39m\u001B[34m(checkpoint, filepath)\u001B[39m\n\u001B[32m     89\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m fs.transaction, fs.open(urlpath, \u001B[33m\"\u001B[39m\u001B[33mwb\u001B[39m\u001B[33m\"\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[32m---> \u001B[39m\u001B[32m90\u001B[39m     \u001B[43mf\u001B[49m\u001B[43m.\u001B[49m\u001B[43mwrite\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbytesbuffer\u001B[49m\u001B[43m.\u001B[49m\u001B[43mgetvalue\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/kit/graph_hdc/.pixi/envs/default/lib/python3.13/site-packages/fsspec/implementations/local.py:465\u001B[39m, in \u001B[36mLocalFileOpener.write\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m    464\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mwrite\u001B[39m(\u001B[38;5;28mself\u001B[39m, *args, **kwargs):\n\u001B[32m--> \u001B[39m\u001B[32m465\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mf\u001B[49m\u001B[43m.\u001B[49m\u001B[43mwrite\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 424\u001B[39m\n\u001B[32m    406\u001B[39m sampling_cb = SamplingEveryNEpoch(encoder=encoder, n_samples=\u001B[32m1\u001B[39m, every_n_epochs=\u001B[32m10\u001B[39m)\n\u001B[32m    408\u001B[39m trainer = Trainer(\n\u001B[32m    409\u001B[39m     max_epochs=cfg.epochs,\n\u001B[32m    410\u001B[39m     logger=[csv_logger,\n\u001B[32m   (...)\u001B[39m\u001B[32m    421\u001B[39m     \u001B[38;5;66;03m# detect_anomaly=True,\u001B[39;00m\n\u001B[32m    422\u001B[39m )\n\u001B[32m--> \u001B[39m\u001B[32m424\u001B[39m \u001B[43mtrainer\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_dataloaders\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtrain_dataloader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    425\u001B[39m \u001B[43m            \u001B[49m\u001B[43mval_dataloaders\u001B[49m\u001B[43m=\u001B[49m\u001B[43mvalidation_dataloader\u001B[49m\n\u001B[32m    426\u001B[39m \u001B[43m            \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    428\u001B[39m torch.save(model.state_dict(), models_dir / \u001B[33m\"\u001B[39m\u001B[33mfinal_model.pt\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m    430\u001B[39m metrics_path = Path(csv_logger.log_dir) / \u001B[33m\"\u001B[39m\u001B[33mmetrics.csv\u001B[39m\u001B[33m\"\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/kit/graph_hdc/.pixi/envs/default/lib/python3.13/site-packages/pytorch_lightning/trainer/trainer.py:538\u001B[39m, in \u001B[36mTrainer.fit\u001B[39m\u001B[34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001B[39m\n\u001B[32m    536\u001B[39m \u001B[38;5;28mself\u001B[39m.state.status = TrainerStatus.RUNNING\n\u001B[32m    537\u001B[39m \u001B[38;5;28mself\u001B[39m.training = \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m538\u001B[39m \u001B[43mcall\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_call_and_handle_interrupt\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    539\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_fit_impl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_dataloaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_dataloaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdatamodule\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mckpt_path\u001B[49m\n\u001B[32m    540\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/kit/graph_hdc/.pixi/envs/default/lib/python3.13/site-packages/pytorch_lightning/trainer/call.py:64\u001B[39m, in \u001B[36m_call_and_handle_interrupt\u001B[39m\u001B[34m(trainer, trainer_fn, *args, **kwargs)\u001B[39m\n\u001B[32m     62\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(launcher, _SubprocessScriptLauncher):\n\u001B[32m     63\u001B[39m         launcher.kill(_get_sigkill_signal())\n\u001B[32m---> \u001B[39m\u001B[32m64\u001B[39m     \u001B[43mexit\u001B[49m(\u001B[32m1\u001B[39m)\n\u001B[32m     66\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exception:\n\u001B[32m     67\u001B[39m     _interrupt(trainer, exception)\n",
      "\u001B[31mNameError\u001B[39m: name 'exit' is not defined"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-14T14:06:06.733872Z",
     "start_time": "2025-07-14T14:06:03.232858Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import datetime\n",
    "import random\n",
    "import shutil\n",
    "import string\n",
    "import time\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from torch.utils.data import Dataset\n",
    "from torch_geometric.data import Batch\n",
    "from torch_geometric.datasets import ZINC\n",
    "\n",
    "from src.datasets import AddNodeDegree\n",
    "from src.encoding.configs_and_constants import SupportedDataset\n",
    "from src.encoding.graph_encoders import HyperNet\n",
    "from src.encoding.the_types import VSAModel\n",
    "from src.normalizing_flow.models import NeuralSplineLightning\n",
    "\n",
    "model_loaded = NeuralSplineLightning.load_from_checkpoint(\n",
    "    \"/Users/arvandkaveh/Projects/kit/graph_hdc/notebooks/NormFlows/results/real_nvp/2025-07-14_15-56-53_wtvj/models/last.ckpt\")\n",
    "\n",
    "device = get_device()\n",
    "ds = SupportedDataset.ZINC_NODE_DEGREE_COMB\n",
    "ds.default_cfg.vsa = VSAModel.HRR\n",
    "ds.default_cfg.hv_dim = hv_dim\n",
    "ds.default_cfg.device = device\n",
    "ds.default_cfg.seed = cfg.seed\n",
    "ds.default_cfg.edge_feature_configs = {}\n",
    "ds.default_cfg.graph_feature_configs = {}\n",
    "\n",
    "encoder = load_or_create_hypernet(path=global_model_dir, cfg=ds.default_cfg, depth=3)\n",
    "\n",
    "# ---- Sampling example ----\n",
    "n_samples = 1\n",
    "model_loaded.eval()\n",
    "s, l = model_loaded.sample(n_samples)\n",
    "encoder.to(model_loaded.device)\n",
    "# s_decoded = pca_decode(s, pca)\n",
    "# z = s_decoded.view(n_samples, 3, hv_dim)\n",
    "z = s"
   ],
   "id": "42b7f069f054235",
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "MPS backend out of memory (MPS allocated: 36.22 GB, other allocations: 864.00 KB, max allowed: 36.27 GB). Tried to allocate 121.29 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mRuntimeError\u001B[39m                              Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[4]\u001B[39m\u001B[32m, line 21\u001B[39m\n\u001B[32m     18\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01msrc\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mencoding\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mthe_types\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m VSAModel\n\u001B[32m     19\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01msrc\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mnormalizing_flow\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mmodels\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m NeuralSplineLightning\n\u001B[32m---> \u001B[39m\u001B[32m21\u001B[39m model_loaded = \u001B[43mNeuralSplineLightning\u001B[49m\u001B[43m.\u001B[49m\u001B[43mload_from_checkpoint\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     22\u001B[39m \u001B[43m    \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43m/Users/arvandkaveh/Projects/kit/graph_hdc/notebooks/NormFlows/results/real_nvp/2025-07-14_15-56-53_wtvj/models/last.ckpt\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m     24\u001B[39m device = get_device()\n\u001B[32m     25\u001B[39m ds = SupportedDataset.ZINC_NODE_DEGREE_COMB\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/kit/graph_hdc/.pixi/envs/default/lib/python3.13/site-packages/pytorch_lightning/utilities/model_helpers.py:125\u001B[39m, in \u001B[36m_restricted_classmethod_impl.__get__.<locals>.wrapper\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    120\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m instance \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_scripting:\n\u001B[32m    121\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\n\u001B[32m    122\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mThe classmethod `\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mcls\u001B[39m.\u001B[34m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m.method.\u001B[34m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m` cannot be called on an instance.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    123\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33m Please call it on the class type and make sure the return value is used.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    124\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m125\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mcls\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/kit/graph_hdc/.pixi/envs/default/lib/python3.13/site-packages/pytorch_lightning/core/module.py:1582\u001B[39m, in \u001B[36mLightningModule.load_from_checkpoint\u001B[39m\u001B[34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001B[39m\n\u001B[32m   1493\u001B[39m \u001B[38;5;129m@_restricted_classmethod\u001B[39m\n\u001B[32m   1494\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mload_from_checkpoint\u001B[39m(\n\u001B[32m   1495\u001B[39m     \u001B[38;5;28mcls\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m   1500\u001B[39m     **kwargs: Any,\n\u001B[32m   1501\u001B[39m ) -> Self:\n\u001B[32m   1502\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33mr\u001B[39m\u001B[33;03m\"\"\"Primary way of loading a model from a checkpoint. When Lightning saves a checkpoint it stores the arguments\u001B[39;00m\n\u001B[32m   1503\u001B[39m \u001B[33;03m    passed to ``__init__``  in the checkpoint under ``\"hyper_parameters\"``.\u001B[39;00m\n\u001B[32m   1504\u001B[39m \n\u001B[32m   (...)\u001B[39m\u001B[32m   1580\u001B[39m \n\u001B[32m   1581\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1582\u001B[39m     loaded = \u001B[43m_load_from_checkpoint\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1583\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mcls\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m   1584\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcheckpoint_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1585\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmap_location\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1586\u001B[39m \u001B[43m        \u001B[49m\u001B[43mhparams_file\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1587\u001B[39m \u001B[43m        \u001B[49m\u001B[43mstrict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1588\u001B[39m \u001B[43m        \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1589\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1590\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m cast(Self, loaded)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/kit/graph_hdc/.pixi/envs/default/lib/python3.13/site-packages/pytorch_lightning/core/saving.py:63\u001B[39m, in \u001B[36m_load_from_checkpoint\u001B[39m\u001B[34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001B[39m\n\u001B[32m     61\u001B[39m map_location = map_location \u001B[38;5;129;01mor\u001B[39;00m _default_map_location\n\u001B[32m     62\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m pl_legacy_patch():\n\u001B[32m---> \u001B[39m\u001B[32m63\u001B[39m     checkpoint = \u001B[43mpl_load\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcheckpoint_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmap_location\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmap_location\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     65\u001B[39m \u001B[38;5;66;03m# convert legacy checkpoints to the new format\u001B[39;00m\n\u001B[32m     66\u001B[39m checkpoint = _pl_migrate_checkpoint(\n\u001B[32m     67\u001B[39m     checkpoint, checkpoint_path=(checkpoint_path \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(checkpoint_path, (\u001B[38;5;28mstr\u001B[39m, Path)) \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[32m     68\u001B[39m )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/kit/graph_hdc/.pixi/envs/default/lib/python3.13/site-packages/lightning_fabric/utilities/cloud_io.py:60\u001B[39m, in \u001B[36m_load\u001B[39m\u001B[34m(path_or_url, map_location, weights_only)\u001B[39m\n\u001B[32m     58\u001B[39m fs = get_filesystem(path_or_url)\n\u001B[32m     59\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m fs.open(path_or_url, \u001B[33m\"\u001B[39m\u001B[33mrb\u001B[39m\u001B[33m\"\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[32m---> \u001B[39m\u001B[32m60\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     61\u001B[39m \u001B[43m        \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     62\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmap_location\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmap_location\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore[arg-type]\u001B[39;49;00m\n\u001B[32m     63\u001B[39m \u001B[43m        \u001B[49m\u001B[43mweights_only\u001B[49m\u001B[43m=\u001B[49m\u001B[43mweights_only\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     64\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/kit/graph_hdc/.pixi/envs/default/lib/python3.13/site-packages/torch/serialization.py:1471\u001B[39m, in \u001B[36mload\u001B[39m\u001B[34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001B[39m\n\u001B[32m   1469\u001B[39m             \u001B[38;5;28;01mexcept\u001B[39;00m pickle.UnpicklingError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m   1470\u001B[39m                 \u001B[38;5;28;01mraise\u001B[39;00m pickle.UnpicklingError(_get_wo_message(\u001B[38;5;28mstr\u001B[39m(e))) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1471\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_load\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1472\u001B[39m \u001B[43m            \u001B[49m\u001B[43mopened_zipfile\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1473\u001B[39m \u001B[43m            \u001B[49m\u001B[43mmap_location\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1474\u001B[39m \u001B[43m            \u001B[49m\u001B[43mpickle_module\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1475\u001B[39m \u001B[43m            \u001B[49m\u001B[43moverall_storage\u001B[49m\u001B[43m=\u001B[49m\u001B[43moverall_storage\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1476\u001B[39m \u001B[43m            \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mpickle_load_args\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1477\u001B[39m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1478\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m mmap:\n\u001B[32m   1479\u001B[39m     f_name = \u001B[33m\"\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(f, \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;28;01melse\u001B[39;00m \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mf\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m, \u001B[39m\u001B[33m\"\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/kit/graph_hdc/.pixi/envs/default/lib/python3.13/site-packages/torch/serialization.py:1964\u001B[39m, in \u001B[36m_load\u001B[39m\u001B[34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001B[39m\n\u001B[32m   1962\u001B[39m \u001B[38;5;28;01mglobal\u001B[39;00m _serialization_tls\n\u001B[32m   1963\u001B[39m _serialization_tls.map_location = map_location\n\u001B[32m-> \u001B[39m\u001B[32m1964\u001B[39m result = \u001B[43munpickler\u001B[49m\u001B[43m.\u001B[49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1965\u001B[39m _serialization_tls.map_location = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1967\u001B[39m torch._utils._validate_loaded_sparse_tensors()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/kit/graph_hdc/.pixi/envs/default/lib/python3.13/pickle.py:1256\u001B[39m, in \u001B[36m_Unpickler.load\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m   1254\u001B[39m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mEOFError\u001B[39;00m\n\u001B[32m   1255\u001B[39m         \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(key, bytes_types)\n\u001B[32m-> \u001B[39m\u001B[32m1256\u001B[39m         \u001B[43mdispatch\u001B[49m\u001B[43m[\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m[\u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m   1257\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m _Stop \u001B[38;5;28;01mas\u001B[39;00m stopinst:\n\u001B[32m   1258\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m stopinst.value\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/kit/graph_hdc/.pixi/envs/default/lib/python3.13/pickle.py:1297\u001B[39m, in \u001B[36m_Unpickler.load_binpersid\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m   1295\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mload_binpersid\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m   1296\u001B[39m     pid = \u001B[38;5;28mself\u001B[39m.stack.pop()\n\u001B[32m-> \u001B[39m\u001B[32m1297\u001B[39m     \u001B[38;5;28mself\u001B[39m.append(\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mpersistent_load\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpid\u001B[49m\u001B[43m)\u001B[49m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/kit/graph_hdc/.pixi/envs/default/lib/python3.13/site-packages/torch/serialization.py:1928\u001B[39m, in \u001B[36m_load.<locals>.persistent_load\u001B[39m\u001B[34m(saved_id)\u001B[39m\n\u001B[32m   1926\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   1927\u001B[39m     nbytes = numel * torch._utils._element_size(dtype)\n\u001B[32m-> \u001B[39m\u001B[32m1928\u001B[39m     typed_storage = \u001B[43mload_tensor\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1929\u001B[39m \u001B[43m        \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnbytes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_maybe_decode_ascii\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlocation\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1930\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1932\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m typed_storage\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/kit/graph_hdc/.pixi/envs/default/lib/python3.13/site-packages/torch/serialization.py:1900\u001B[39m, in \u001B[36m_load.<locals>.load_tensor\u001B[39m\u001B[34m(dtype, numel, key, location)\u001B[39m\n\u001B[32m   1895\u001B[39m         storage.byteswap(dtype)\n\u001B[32m   1897\u001B[39m \u001B[38;5;66;03m# TODO: Once we decide to break serialization FC, we can\u001B[39;00m\n\u001B[32m   1898\u001B[39m \u001B[38;5;66;03m# stop wrapping with TypedStorage\u001B[39;00m\n\u001B[32m   1899\u001B[39m typed_storage = torch.storage.TypedStorage(\n\u001B[32m-> \u001B[39m\u001B[32m1900\u001B[39m     wrap_storage=\u001B[43mrestore_location\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstorage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlocation\u001B[49m\u001B[43m)\u001B[49m,\n\u001B[32m   1901\u001B[39m     dtype=dtype,\n\u001B[32m   1902\u001B[39m     _internal=\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[32m   1903\u001B[39m )\n\u001B[32m   1905\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m typed_storage._data_ptr() != \u001B[32m0\u001B[39m:\n\u001B[32m   1906\u001B[39m     loaded_storages[key] = typed_storage\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/kit/graph_hdc/.pixi/envs/default/lib/python3.13/site-packages/torch/serialization.py:1813\u001B[39m, in \u001B[36m_get_restore_location.<locals>.restore_location\u001B[39m\u001B[34m(storage, location)\u001B[39m\n\u001B[32m   1811\u001B[39m result = map_location(storage, location)\n\u001B[32m   1812\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m result \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1813\u001B[39m     result = \u001B[43mdefault_restore_location\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstorage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlocation\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1814\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/kit/graph_hdc/.pixi/envs/default/lib/python3.13/site-packages/torch/serialization.py:693\u001B[39m, in \u001B[36mdefault_restore_location\u001B[39m\u001B[34m(storage, location)\u001B[39m\n\u001B[32m    673\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    674\u001B[39m \u001B[33;03mRestores `storage` using a deserializer function registered for the `location`.\u001B[39;00m\n\u001B[32m    675\u001B[39m \n\u001B[32m   (...)\u001B[39m\u001B[32m    690\u001B[39m \u001B[33;03m       all matching ones return `None`.\u001B[39;00m\n\u001B[32m    691\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    692\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m _, _, fn \u001B[38;5;129;01min\u001B[39;00m _package_registry:\n\u001B[32m--> \u001B[39m\u001B[32m693\u001B[39m     result = \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstorage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlocation\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    694\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m result \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    695\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/kit/graph_hdc/.pixi/envs/default/lib/python3.13/site-packages/torch/serialization.py:559\u001B[39m, in \u001B[36m_mps_deserialize\u001B[39m\u001B[34m(obj, location)\u001B[39m\n\u001B[32m    557\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_mps_deserialize\u001B[39m(obj, location):\n\u001B[32m    558\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m location.startswith(\u001B[33m\"\u001B[39m\u001B[33mmps\u001B[39m\u001B[33m\"\u001B[39m):\n\u001B[32m--> \u001B[39m\u001B[32m559\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mobj\u001B[49m\u001B[43m.\u001B[49m\u001B[43mmps\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/kit/graph_hdc/.pixi/envs/default/lib/python3.13/site-packages/torch/storage.py:273\u001B[39m, in \u001B[36m_StorageBase.mps\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    271\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"Return a MPS copy of this storage if it's not already on the MPS.\"\"\"\u001B[39;00m\n\u001B[32m    272\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.device.type != \u001B[33m\"\u001B[39m\u001B[33mmps\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m--> \u001B[39m\u001B[32m273\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43mUntypedStorage\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43msize\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmps\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m.copy_(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[32m    274\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "\u001B[31mRuntimeError\u001B[39m: MPS backend out of memory (MPS allocated: 36.22 GB, other allocations: 864.00 KB, max allowed: 36.27 GB). Tried to allocate 121.29 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure)."
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "import torch\n",
    "from torchhd import HRRTensor\n",
    "\n",
    "node_terms_s, edge_terms_s, graph_embeddings_s = z.unbind(dim=1)\n",
    "\n",
    "# Cast to HRRTensor\n",
    "node_terms_s_hrr = node_terms_s.as_subclass(HRRTensor)\n",
    "edge_terms_s_hrr = edge_terms_s.as_subclass(HRRTensor)\n",
    "graph_embeddings_s_hrr = graph_embeddings_s.as_subclass(HRRTensor)\n",
    "\n",
    "print(\"---SAMPLES---\")\n",
    "for b in range(n_samples):\n",
    "    print(f\"SAMPLE NR: {b}\")\n",
    "    node_counter_dec = encoder.decode_order_zero_counter(node_terms_s_hrr[b])\n",
    "    print(f\"{node_counter_dec[0]=}\")\n",
    "    print(f\"{node_counter_dec[0].total()}\")\n",
    "\n",
    "import torchhd\n",
    "\n",
    "print(\"----RANDOM-----\")\n",
    "random_counter = encoder.decode_order_zero_counter(torchhd.random(1, hv_dim, vsa=\"HRR\")[0])\n",
    "print(f\"{random_counter[0]=}\")\n",
    "print(f\"{random_counter[0].total()=}\")\n"
   ],
   "id": "85affe280e8ba0a1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "print(\"---DATA---\")\n",
    "counter = 1\n",
    "data_ = next(iter(train_dataset))\n",
    "for b in train_dataloader:\n",
    "    a = b.tolist()\n",
    "\n",
    "    print(f\"DATA NR: {counter}\")\n",
    "    counter += 1\n",
    "    # s_decoded = pca_decode(b, pca)\n",
    "    # z = b.view(4, 3, hv_dim\n",
    "    node_terms_s, edge_terms_s, graph_embeddings_s = b.unbind(dim=1)\n",
    "    node_terms_s_hrr = node_terms_s.as_subclass(HRRTensor)\n",
    "    for i in range(batch_size):\n",
    "        encoder.to(node_terms_s_hrr.device)\n",
    "        node_counter_dec = encoder.decode_order_zero_counter(node_terms_s_hrr[i])\n",
    "        print(f\"{node_counter_dec[0]=}\")\n",
    "        print(f\"{node_counter_dec[0].total()}\")\n",
    "        print(f\"{len(node_counter_dec[0])=}\")\n"
   ],
   "id": "afec1a13f41449b5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from src.utils.utils import DataTransformer\n",
    "\n",
    "data = ZINC(root=str(global_dataset_dir), pre_transform=AddNodeDegree(), split=\"train\", subset=True)[0]\n",
    "# data = next(iter(ZINC(root=str(global_dataset_dir), pre_transform=AddNodeDegree(), split=\"train\", subset=True)))\n",
    "print(data.num_nodes)\n",
    "b = Batch.from_data_list([data])\n",
    "\n",
    "device = get_device()\n",
    "ds = SupportedDataset.ZINC_NODE_DEGREE_COMB\n",
    "ds.default_cfg.vsa = VSAModel.HRR\n",
    "ds.default_cfg.hv_dim = 50 * 50\n",
    "ds.default_cfg.device = device\n",
    "ds.default_cfg.seed = cfg.seed\n",
    "ds.default_cfg.edge_feature_configs = {}\n",
    "ds.default_cfg.graph_feature_configs = {}\n",
    "\n",
    "encoder = load_or_create_hypernet(path=global_model_dir, cfg=ds.default_cfg, depth=3)\n",
    "\n",
    "encoded = encoder.forward(b)\n",
    "nodes_encoded = encoder.decode_order_zero_counter(encoded['node_terms'])[0]\n",
    "print(nodes_encoded.total())\n",
    "print(\"data %\", DataTransformer.get_node_counter_from_batch(0, b))\n",
    "print(\"decoded %\", nodes_encoded)"
   ],
   "id": "41bbb34bfdba0c4c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "9120419b3d85871f",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
