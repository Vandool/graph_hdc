{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-15T06:46:34.868529Z",
     "start_time": "2025-07-15T06:46:14.411635Z"
    }
   },
   "source": [
    "import datetime\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import string\n",
    "import time\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchhd\n",
    "import wandb\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import Callback, LearningRateMonitor, ModelCheckpoint\n",
    "from pytorch_lightning.loggers import CSVLogger, WandbLogger\n",
    "from sklearn.decomposition import PCA\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from torch_geometric.data import Batch\n",
    "from torch_geometric.datasets import ZINC\n",
    "\n",
    "from graph_hdc.utils import AbstractEncoder\n",
    "from src.datasets import AddNodeDegree\n",
    "from src.encoding.configs_and_constants import DSHDCConfig, SupportedDataset\n",
    "from src.encoding.graph_encoders import HyperNet\n",
    "from src.encoding.the_types import VSAModel\n",
    "from src.normalizing_flow.config import FlowConfig, get_flow_cli_args\n",
    "from src.normalizing_flow.models import RealNVPLightning\n",
    "\n",
    "\n",
    "def setup_exp(ds_value: str) -> dict:\n",
    "    \"\"\"\n",
    "    Sets up experiment directories based on the current script location.\n",
    "\n",
    "    Args:\n",
    "        ds_value (str): Dataset name to use for global_dataset_dir.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary containing paths to various directories.\n",
    "    \"\"\"\n",
    "    # Resolve script location\n",
    "    script_path = Path(\"/Users/arvandkaveh/Projects/kit/graph_hdc/notebooks/NormFlows/real_nvp.ipynb\")\n",
    "    experiments_path = script_path.parent\n",
    "    script_stem = script_path.stem  # without .py\n",
    "\n",
    "    # Resolve base and project directories\n",
    "    base_dir = experiments_path / \"results\" / script_stem\n",
    "    base_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    project_dir = script_path.parents[2]  # adjust as needed\n",
    "\n",
    "    print(f\"Setting up experiment in {base_dir}\")\n",
    "    now = f\"{datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}_{''.join(random.choices(string.ascii_lowercase, k=4))}\"\n",
    "    exp_dir = base_dir / now\n",
    "    exp_dir.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"Experiment directory created: {exp_dir}\")\n",
    "\n",
    "    dirs = {\n",
    "        \"exp_dir\": exp_dir,\n",
    "        \"models_dir\": exp_dir / \"models\",\n",
    "        \"evals_dir\": exp_dir / \"evaluations\",\n",
    "        \"artefacts_dir\": exp_dir / \"artefacts\",\n",
    "        \"global_model_dir\": project_dir / \"_models\",\n",
    "        \"global_dataset_dir\": project_dir / \"_datasets\" / ds_value,\n",
    "    }\n",
    "\n",
    "    for d in dirs.values():\n",
    "        d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Save a copy of the script\n",
    "    try:\n",
    "        shutil.copy(script_path, exp_dir / script_path.name)\n",
    "        print(f\"Saved a copy of the script to {exp_dir / script_path.name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Failed to save script copy: {e}\")\n",
    "\n",
    "    return dirs\n",
    "\n",
    "\n",
    "def plot_train_val_loss(df, artefacts_dir):\n",
    "    train = df[df[\"train_loss_epoch\"].notna()]\n",
    "    val = df[df[\"val_loss\"].notna()]\n",
    "\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(train[\"epoch\"], train[\"train_loss_epoch\"], label=\"Train Loss\")\n",
    "    plt.plot(val[\"epoch\"], val[\"val_loss\"], label=\"Validation Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Train vs. Validation Loss\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "\n",
    "    artefacts_dir.mkdir(exist_ok=True)\n",
    "    plt.savefig(artefacts_dir / \"train_val_loss.png\")\n",
    "    plt.close()\n",
    "    print(f\"Saved train/val loss plot to {artefacts_dir / 'train_val_loss.png'}\")\n",
    "\n",
    "\n",
    "def pca_encode(x: torch.Tensor, pca: PCA, norm: bool = False) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Encode data using a fitted PCA, with optional normalization.\n",
    "\n",
    "    :param x: Input tensor of shape (..., features).\n",
    "    :type x: torch.Tensor\n",
    "    :param pca: Fitted PCA instance with attributes `mean_` and `std_`.\n",
    "    :type pca: PCA\n",
    "    :param norm: Whether to normalize input by mean and std before PCA.\n",
    "    :type norm: bool\n",
    "    :returns: Tensor of reduced dimensions, same dtype as input.\n",
    "    :rtype: torch.Tensor\n",
    "\n",
    "    The input is flattened over all but the last dimension, optionally normalized,\n",
    "    transformed with the PCA, then returned as a tensor.\n",
    "    \"\"\"\n",
    "    flat = x.view(-1, x.shape[-1]).cpu().numpy()\n",
    "    if norm:\n",
    "        flat = (flat - pca.mean_) / pca.std_\n",
    "    reduced = pca.transform(flat)\n",
    "    return torch.tensor(reduced, dtype=x.dtype)\n",
    "\n",
    "\n",
    "def load_or_fit_pca(\n",
    "    train_dataset: Dataset, encoder: AbstractEncoder, pca_path: Path | None = None, n_components: float = 0.99999, n_fit: int = 20000\n",
    ") -> PCA:\n",
    "    \"\"\"\n",
    "    Load an existing PCA from disk or fit a new one and save it.\n",
    "\n",
    "    :param train_dataset: Dataset for fitting PCA.\n",
    "    :type train_dataset: Dataset\n",
    "    :param encoder: Model or function returning a dict with keys \\\"node_terms\\\", \\\"edge_terms\\\", and \\\"graph_embedding\\\".\n",
    "    :param pca_path: Path to load/save the PCA object.\n",
    "    :type pca_path: Path\n",
    "    :param n_components: Number of components or variance ratio for PCA.\n",
    "    :type n_components: float\n",
    "    :param n_fit: Maximum number of samples to fit PCA on.\n",
    "    :type n_fit: int\n",
    "    :returns: Fitted PCA instance with `mean_` and `std_` attributes.\n",
    "    :rtype: PCA\n",
    "\n",
    "    If a PCA exists at `pca_path`, it is loaded. Otherwise, embeddings\n",
    "    are collected by applying `encoder` to dataset entries until `n_fit`\n",
    "    samples, flattened, and used to fit a new PCA. The mean and std of the\n",
    "    fit data are stored on the PCA for later normalization.\n",
    "    \"\"\"\n",
    "    if pca_path is not None and pca_path.exists():\n",
    "        print(f\"Loading existing PCA from {pca_path}\")\n",
    "        pca = joblib.load(pca_path)\n",
    "        print(f\"Loaded PCA with {pca.n_components_} components\")\n",
    "        return pca\n",
    "\n",
    "    print(\"Fitting PCA on training data...\")\n",
    "    n_fit = min(n_fit, len(train_dataset))\n",
    "    X_fit = []\n",
    "    for i in range(n_fit):\n",
    "        data = train_dataset[i]\n",
    "        batch_data = Batch.from_data_list([data])\n",
    "        res = encoder.forward(data=batch_data)\n",
    "        x = torch.stack(\n",
    "            [res[\"node_terms\"].squeeze(0), res[\"edge_terms\"].squeeze(0), res[\"graph_embedding\"].squeeze(0)], dim=0\n",
    "        )  # [3, D]\n",
    "        X_fit.append(x.cpu().numpy())\n",
    "    X_fit = np.stack(X_fit)\n",
    "    X_fit_flat = X_fit.reshape(-1, X_fit.shape[-1])\n",
    "\n",
    "    # Compute mean and std for normalization\n",
    "    mu = np.mean(X_fit_flat, axis=0)\n",
    "    sigma = np.std(X_fit_flat, axis=0)\n",
    "\n",
    "    # Fit PCA\n",
    "    pca = PCA(n_components=n_components, svd_solver=\"full\")\n",
    "    pca.fit(X_fit_flat)\n",
    "\n",
    "    # Attach normalization stats\n",
    "    pca.mean_ = mu\n",
    "    pca.std_ = sigma\n",
    "\n",
    "    print(f\"PCA reduced dimension: {pca.n_components_} from {X_fit.shape[-1]}\")\n",
    "    joblib.dump(pca, pca_path)\n",
    "    print(f\"Saved new PCA to {pca_path}\")\n",
    "    return pca\n",
    "\n",
    "\n",
    "def load_or_create_hypernet(path: Path, cfg: DSHDCConfig, depth: int) -> HyperNet:\n",
    "    path = path / f\"hypernet_{cfg.vsa.value}_d{cfg.hv_dim}_s{cfg.seed}_dpth{depth}.pt\"\n",
    "    if path.exists():\n",
    "        print(f\"Loading existing HyperNet from {path}\")\n",
    "        encoder = HyperNet(config=cfg, depth=depth)\n",
    "        encoder.load(path)\n",
    "    else:\n",
    "        print(\"Creating new HyperNet instance.\")\n",
    "        encoder = HyperNet(config=cfg, depth=depth)\n",
    "        encoder.populate_codebooks()\n",
    "        encoder.save_to_path(path)\n",
    "        print(f\"Saved new HyperNet to {path}\")\n",
    "    return encoder\n",
    "\n",
    "\n",
    "class EncodedPCADataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, base_dataset, encoder, pca: PCA | None = None, *, use_norm_pca: bool = False):\n",
    "        self.base_dataset = base_dataset\n",
    "        self.encoder = encoder\n",
    "        self.pca = pca\n",
    "        self.use_norm = use_norm_pca  # Whether to normalize the PCA\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.base_dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = self.base_dataset[idx]\n",
    "        batch_data = Batch.from_data_list([data])\n",
    "        res = self.encoder.forward(data=batch_data)\n",
    "        x = torch.stack(\n",
    "            [res[\"node_terms\"].squeeze(0), res[\"edge_terms\"].squeeze(0), res[\"graph_embedding\"].squeeze(0)], dim=0\n",
    "        )\n",
    "        if self.pca is not None:\n",
    "            return pca_encode(x, self.pca, self.use_norm)\n",
    "        return x\n",
    "\n",
    "\n",
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        count = torch.cuda.device_count()\n",
    "        print(f\"CUDA is available. Detected {count} GPU device{'s' if count != 1 else ''}.\")\n",
    "        return torch.device(\"cuda\")\n",
    "    print(\"CUDA is not available.\")\n",
    "    return torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "class TimeLoggingCallback(Callback):\n",
    "    def setup(self, trainer, pl_module, stage=None):\n",
    "        self.start_time = time.time()\n",
    "\n",
    "    def on_train_epoch_end(self, trainer, pl_module):\n",
    "        elapsed = time.time() - self.start_time\n",
    "        trainer.logger.log_metrics({\"elapsed_time_sec\": elapsed}, step=trainer.current_epoch)\n",
    "\n",
    "hv_dim = 6400\n",
    "batch_size = 2\n",
    "cfg = FlowConfig(\n",
    "    project_dir=\"/Users/arvandkaveh/Projects/kit/graph_hdc\",\n",
    "    seed=42,\n",
    "    epochs=50,\n",
    "    batch_size=batch_size,\n",
    "    vsa=VSAModel.HRR,\n",
    "    hv_dim=hv_dim,\n",
    "    dataset=SupportedDataset.ZINC_NODE_DEGREE_COMB,\n",
    "    num_input_channels=3*hv_dim,\n",
    "    num_flows=16,\n",
    "    num_hidden_channels=128,\n",
    "    input_shape=(3, hv_dim),\n",
    "    device=\"cpu\",\n",
    "    lr=0.0001,\n",
    ")\n",
    "\n",
    "print(\"Running experiment\")\n",
    "pprint(cfg.__dict__, indent=2)\n",
    "\n",
    "dirs = setup_exp(cfg.dataset.value)\n",
    "exp_dir = dirs[\"exp_dir\"]\n",
    "models_dir = dirs[\"models_dir\"]\n",
    "evals_dir = dirs[\"evals_dir\"]\n",
    "artefacts_dir = dirs[\"artefacts_dir\"]\n",
    "global_model_dir = dirs[\"global_model_dir\"]\n",
    "global_dataset_dir = dirs[\"global_dataset_dir\"]\n",
    "\n",
    "# W&B Logging — use existing run (from sweep or manual init)\n",
    "# run = wandb.run or wandb.init(project=\"realnvp-hdc\", config=cfg.__dict__, name=f\"run_{cfg.hv_dim}_{cfg.seed}\", reinit=True)\n",
    "# run.tags = [f\"hv_dim={cfg.hv_dim}\", f\"vsa={cfg.vsa.value}\", f\"dataset={cfg.dataset.value}\"]\n",
    "\n",
    "# wandb_logger = WandbLogger(log_model=True, experiment=run)\n",
    "\n",
    "train_data = ZINC(root=str(global_dataset_dir), pre_transform=AddNodeDegree(), split=\"train\", subset=True)[:1]\n",
    "train_dataset = Subset(train_data, indices=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
    "print(f\"Train length = {len(train_dataset)}\")  # → 4\n",
    "print(train_dataset[0])\n",
    "# validation_data = ZINC(root=str(global_dataset_dir), pre_transform=AddNodeDegree(), split=\"val\", subset=True)[:1]\n",
    "validation_dataset = Subset(train_data, indices=[0, 0, 0, 0])\n",
    "print(f\"{len(validation_dataset)=}\")\n",
    "print(validation_dataset[0])\n",
    "\n",
    "device = get_device()\n",
    "ds = cfg.dataset\n",
    "ds.default_cfg.vsa = cfg.vsa\n",
    "ds.default_cfg.hv_dim = cfg.hv_dim\n",
    "ds.default_cfg.device = device\n",
    "ds.default_cfg.seed = cfg.seed\n",
    "ds.default_cfg.edge_feature_configs = {}\n",
    "ds.default_cfg.graph_feature_configs = {}\n",
    "\n",
    "encoder = load_or_create_hypernet(path=global_model_dir, cfg=ds.default_cfg, depth=3)\n",
    "\n",
    "# Print decoded counters of one data point\n",
    "data_batch = Batch.from_data_list(train_data)\n",
    "encoded_data = encoder.forward(data_batch)\n",
    "lvl0_counter = encoder.decode_order_zero_counter(encoded_data['node_terms'])\n",
    "print(f\"Decoded level zero counter = {lvl0_counter[0]}\")\n",
    "print(f\"Decoded level zero counter total = {lvl0_counter[0].total()}\")\n",
    "lvl1_counter = encoder.decode_order_one_counter_explain_away_faster(encoded_data['edge_terms'])\n",
    "print(f\"Decoded level one counter = {lvl1_counter[0]}\")\n",
    "print(f\"Decoded level one counter total = {lvl1_counter[0].total()}\")\n",
    "\n",
    "\n",
    "n_components = 0.99999\n",
    "pca_path = global_model_dir / f\"hypervec_pca_{cfg.vsa.value}_d{cfg.hv_dim}_s{cfg.seed}_c{str(n_components)[2:]}.joblib\"\n",
    "pca = load_or_fit_pca(\n",
    "    train_dataset=ZINC(root=str(global_dataset_dir), pre_transform=AddNodeDegree(), split=\"train\", subset=True),\n",
    "    encoder=encoder,\n",
    "    pca_path=pca_path,\n",
    "    n_components=n_components,\n",
    "    n_fit=20_000,\n",
    ")\n",
    "\n",
    "reduced_dim = int(pca.n_components_)\n",
    "cfg.num_input_channels = 3 * reduced_dim\n",
    "cfg.input_shape = (3, reduced_dim)\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    EncodedPCADataset(train_dataset, encoder, pca, use_norm_pca=False),\n",
    "    batch_size=cfg.batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    pin_memory=torch.cuda.is_available(),\n",
    "    drop_last=True,\n",
    ")\n",
    "validation_dataloader = DataLoader(\n",
    "    EncodedPCADataset(validation_dataset, encoder, pca, use_norm_pca=False),\n",
    "    batch_size=cfg.batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=torch.cuda.is_available(),\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "model = RealNVPLightning(cfg)\n",
    "\n",
    "csv_logger = CSVLogger(save_dir=str(evals_dir), name=\"logs\")\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor=\"val_loss\",\n",
    "    save_top_k=2,\n",
    "    mode=\"min\",\n",
    "    dirpath=str(models_dir),\n",
    "    filename=\"epoch{epoch:02d}-val{val_loss:.2f}\",\n",
    "    save_last=True,\n",
    ")\n",
    "lr_monitor = LearningRateMonitor(logging_interval=\"epoch\")\n",
    "time_logger = TimeLoggingCallback()\n",
    "\n",
    "trainer = Trainer(\n",
    "    max_epochs=cfg.epochs,\n",
    "    logger=[csv_logger,\n",
    "            # wandb_logger\n",
    "            ],\n",
    "    callbacks=[checkpoint_callback, lr_monitor, time_logger],\n",
    "    default_root_dir=str(exp_dir),\n",
    "    accelerator=\"auto\",\n",
    "    log_every_n_steps=20,\n",
    "    enable_progress_bar=True,\n",
    "    detect_anomaly=True,\n",
    ")\n",
    "\n",
    "trainer.fit(model, train_dataloaders=train_dataloader, val_dataloaders=validation_dataloader)\n",
    "\n",
    "torch.save(model.state_dict(), models_dir / \"final_model.pt\")\n",
    "\n",
    "metrics_path = Path(csv_logger.log_dir) / \"metrics.csv\"\n",
    "if metrics_path.exists():\n",
    "    df = pd.read_csv(metrics_path)\n",
    "    df.to_parquet(evals_dir / \"metrics.parquet\")\n",
    "    plot_train_val_loss(df, artefacts_dir)\n",
    "\n",
    "print(\"==== The Experiment is done! ====\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment\n",
      "{ 'activation': <class 'torch.nn.modules.activation.ReLU'>,\n",
      "  'batch_size': 2,\n",
      "  'dataset': <SupportedDataset.ZINC_NODE_DEGREE_COMB: 'ZINC_ND_COMB'>,\n",
      "  'device': 'cpu',\n",
      "  'dropout_probability': 0.0,\n",
      "  'epochs': 50,\n",
      "  'exp_dir': None,\n",
      "  'flow_type': <class 'normflows.flows.neural_spline.wrapper.AutoregressiveRationalQuadraticSpline'>,\n",
      "  'hv_dim': 6400,\n",
      "  'init_identity': True,\n",
      "  'input_shape': (3, 6400),\n",
      "  'lr': 0.0001,\n",
      "  'num_bins': 8,\n",
      "  'num_blocks': 2,\n",
      "  'num_context_channels': None,\n",
      "  'num_flows': 16,\n",
      "  'num_hidden_channels': 128,\n",
      "  'num_input_channels': 19200,\n",
      "  'permute': False,\n",
      "  'project_dir': PosixPath('/Users/arvandkaveh/Projects/kit/graph_hdc'),\n",
      "  'seed': 42,\n",
      "  'tail_bound': 3,\n",
      "  'vsa': <VSAModel.HRR: 'HRR'>,\n",
      "  'weight_decay': 0.0}\n",
      "Setting up experiment in /Users/arvandkaveh/Projects/kit/graph_hdc/notebooks/NormFlows/results/real_nvp\n",
      "Experiment directory created: /Users/arvandkaveh/Projects/kit/graph_hdc/notebooks/NormFlows/results/real_nvp/2025-07-15_08-46-25_mgdr\n",
      "Saved a copy of the script to /Users/arvandkaveh/Projects/kit/graph_hdc/notebooks/NormFlows/results/real_nvp/2025-07-15_08-46-25_mgdr/real_nvp.ipynb\n",
      "Train length = 16\n",
      "Data(x=[29, 2], edge_index=[2, 64], edge_attr=[64], y=[1])\n",
      "len(validation_dataset)=4\n",
      "Data(x=[35, 2], edge_index=[2, 78], edge_attr=[78], y=[1])\n",
      "CUDA is not available.\n",
      "Loading existing HyperNet from /Users/arvandkaveh/Projects/kit/graph_hdc/_models/hypernet_HRR_d6400_s42_dpth3.pt\n",
      "Loading existing PCA from /Users/arvandkaveh/Projects/kit/graph_hdc/_models/hypervec_pca_HRR_d6400_s42_c99999.joblib\n",
      "Loaded PCA with 1454 components\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You have turned on `Trainer(detect_anomaly=True)`. This will significantly slow down compute speed and is recommended only for model debugging.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name | Type            | Params | Mode \n",
      "-------------------------------------------------\n",
      "0 | flow | NormalizingFlow | 36.4 M | train\n",
      "-------------------------------------------------\n",
      "36.4 M    Trainable params\n",
      "0         Non-trainable params\n",
      "36.4 M    Total params\n",
      "145.622   Total estimated model params size (MB)\n",
      "259       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arvandkaveh/Projects/kit/graph_hdc/.pixi/envs/default/lib/python3.13/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arvandkaveh/Projects/kit/graph_hdc/.pixi/envs/default/lib/python3.13/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "/Users/arvandkaveh/Projects/kit/graph_hdc/.pixi/envs/default/lib/python3.13/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (8) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 8/8 [00:05<00:00,  1.38it/s, v_num=0, train_loss_step=7.5e+5] \n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001B[A\n",
      "Validation:   0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:  50%|█████     | 1/2 [00:00<00:00, 36.25it/s]\u001B[A\n",
      "Validation DataLoader 0: 100%|██████████| 2/2 [00:00<00:00, 22.80it/s]\u001B[A\n",
      "Epoch 0: 100%|██████████| 8/8 [00:05<00:00,  1.35it/s, v_num=0, train_loss_step=7.5e+5, val_loss=6.14e+6, lr=0.0001, train_loss_epoch=6.56e+7]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'exit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/kit/graph_hdc/.pixi/envs/default/lib/python3.13/site-packages/pytorch_lightning/trainer/call.py:47\u001B[39m, in \u001B[36m_call_and_handle_interrupt\u001B[39m\u001B[34m(trainer, trainer_fn, *args, **kwargs)\u001B[39m\n\u001B[32m     46\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)\n\u001B[32m---> \u001B[39m\u001B[32m47\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtrainer_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     49\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m _TunerExitException:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/kit/graph_hdc/.pixi/envs/default/lib/python3.13/site-packages/pytorch_lightning/trainer/trainer.py:574\u001B[39m, in \u001B[36mTrainer._fit_impl\u001B[39m\u001B[34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001B[39m\n\u001B[32m    568\u001B[39m ckpt_path = \u001B[38;5;28mself\u001B[39m._checkpoint_connector._select_ckpt_path(\n\u001B[32m    569\u001B[39m     \u001B[38;5;28mself\u001B[39m.state.fn,\n\u001B[32m    570\u001B[39m     ckpt_path,\n\u001B[32m    571\u001B[39m     model_provided=\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[32m    572\u001B[39m     model_connected=\u001B[38;5;28mself\u001B[39m.lightning_module \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[32m    573\u001B[39m )\n\u001B[32m--> \u001B[39m\u001B[32m574\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_run\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mckpt_path\u001B[49m\u001B[43m=\u001B[49m\u001B[43mckpt_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    576\u001B[39m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m.state.stopped\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/kit/graph_hdc/.pixi/envs/default/lib/python3.13/site-packages/pytorch_lightning/trainer/trainer.py:981\u001B[39m, in \u001B[36mTrainer._run\u001B[39m\u001B[34m(self, model, ckpt_path)\u001B[39m\n\u001B[32m    978\u001B[39m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n\u001B[32m    979\u001B[39m \u001B[38;5;66;03m# RUN THE TRAINER\u001B[39;00m\n\u001B[32m    980\u001B[39m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m981\u001B[39m results = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_run_stage\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    983\u001B[39m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n\u001B[32m    984\u001B[39m \u001B[38;5;66;03m# POST-Training CLEAN UP\u001B[39;00m\n\u001B[32m    985\u001B[39m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/kit/graph_hdc/.pixi/envs/default/lib/python3.13/site-packages/pytorch_lightning/trainer/trainer.py:1025\u001B[39m, in \u001B[36mTrainer._run_stage\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m   1024\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m torch.autograd.set_detect_anomaly(\u001B[38;5;28mself\u001B[39m._detect_anomaly):\n\u001B[32m-> \u001B[39m\u001B[32m1025\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mfit_loop\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1026\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/kit/graph_hdc/.pixi/envs/default/lib/python3.13/site-packages/pytorch_lightning/loops/fit_loop.py:206\u001B[39m, in \u001B[36m_FitLoop.run\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    205\u001B[39m \u001B[38;5;28mself\u001B[39m.advance()\n\u001B[32m--> \u001B[39m\u001B[32m206\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mon_advance_end\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    207\u001B[39m \u001B[38;5;28mself\u001B[39m._restarting = \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/kit/graph_hdc/.pixi/envs/default/lib/python3.13/site-packages/pytorch_lightning/loops/fit_loop.py:378\u001B[39m, in \u001B[36m_FitLoop.on_advance_end\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    377\u001B[39m call._call_lightning_module_hook(trainer, \u001B[33m\"\u001B[39m\u001B[33mon_train_epoch_end\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m--> \u001B[39m\u001B[32m378\u001B[39m \u001B[43mcall\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_call_callback_hooks\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrainer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mon_train_epoch_end\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmonitoring_callbacks\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[32m    380\u001B[39m trainer._logger_connector.on_epoch_end()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/kit/graph_hdc/.pixi/envs/default/lib/python3.13/site-packages/pytorch_lightning/trainer/call.py:218\u001B[39m, in \u001B[36m_call_callback_hooks\u001B[39m\u001B[34m(trainer, hook_name, monitoring_callbacks, *args, **kwargs)\u001B[39m\n\u001B[32m    217\u001B[39m         \u001B[38;5;28;01mwith\u001B[39;00m trainer.profiler.profile(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33m[Callback]\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcallback.state_key\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mhook_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m):\n\u001B[32m--> \u001B[39m\u001B[32m218\u001B[39m             \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrainer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrainer\u001B[49m\u001B[43m.\u001B[49m\u001B[43mlightning_module\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    220\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m pl_module:\n\u001B[32m    221\u001B[39m     \u001B[38;5;66;03m# restore current_fx when nested context\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/kit/graph_hdc/.pixi/envs/default/lib/python3.13/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:326\u001B[39m, in \u001B[36mModelCheckpoint.on_train_epoch_end\u001B[39m\u001B[34m(self, trainer, pl_module)\u001B[39m\n\u001B[32m    325\u001B[39m     \u001B[38;5;28mself\u001B[39m._save_topk_checkpoint(trainer, monitor_candidates)\n\u001B[32m--> \u001B[39m\u001B[32m326\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_save_last_checkpoint\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrainer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmonitor_candidates\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/kit/graph_hdc/.pixi/envs/default/lib/python3.13/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:696\u001B[39m, in \u001B[36mModelCheckpoint._save_last_checkpoint\u001B[39m\u001B[34m(self, trainer, monitor_candidates)\u001B[39m\n\u001B[32m    695\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m696\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_save_checkpoint\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrainer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfilepath\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    697\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m previous \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m._should_remove_checkpoint(trainer, previous, filepath):\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/kit/graph_hdc/.pixi/envs/default/lib/python3.13/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:390\u001B[39m, in \u001B[36mModelCheckpoint._save_checkpoint\u001B[39m\u001B[34m(self, trainer, filepath)\u001B[39m\n\u001B[32m    389\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_save_checkpoint\u001B[39m(\u001B[38;5;28mself\u001B[39m, trainer: \u001B[33m\"\u001B[39m\u001B[33mpl.Trainer\u001B[39m\u001B[33m\"\u001B[39m, filepath: \u001B[38;5;28mstr\u001B[39m) -> \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m390\u001B[39m     \u001B[43mtrainer\u001B[49m\u001B[43m.\u001B[49m\u001B[43msave_checkpoint\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43msave_weights_only\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    392\u001B[39m     \u001B[38;5;28mself\u001B[39m._last_global_step_saved = trainer.global_step\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/kit/graph_hdc/.pixi/envs/default/lib/python3.13/site-packages/pytorch_lightning/trainer/trainer.py:1365\u001B[39m, in \u001B[36mTrainer.save_checkpoint\u001B[39m\u001B[34m(self, filepath, weights_only, storage_options)\u001B[39m\n\u001B[32m   1364\u001B[39m checkpoint = \u001B[38;5;28mself\u001B[39m._checkpoint_connector.dump_checkpoint(weights_only)\n\u001B[32m-> \u001B[39m\u001B[32m1365\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mstrategy\u001B[49m\u001B[43m.\u001B[49m\u001B[43msave_checkpoint\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcheckpoint\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfilepath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1366\u001B[39m \u001B[38;5;28mself\u001B[39m.strategy.barrier(\u001B[33m\"\u001B[39m\u001B[33mTrainer.save_checkpoint\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/kit/graph_hdc/.pixi/envs/default/lib/python3.13/site-packages/pytorch_lightning/strategies/strategy.py:490\u001B[39m, in \u001B[36mStrategy.save_checkpoint\u001B[39m\u001B[34m(self, checkpoint, filepath, storage_options)\u001B[39m\n\u001B[32m    489\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.is_global_zero:\n\u001B[32m--> \u001B[39m\u001B[32m490\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mcheckpoint_io\u001B[49m\u001B[43m.\u001B[49m\u001B[43msave_checkpoint\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcheckpoint\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfilepath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/kit/graph_hdc/.pixi/envs/default/lib/python3.13/site-packages/lightning_fabric/plugins/io/torch_io.py:58\u001B[39m, in \u001B[36mTorchCheckpointIO.save_checkpoint\u001B[39m\u001B[34m(self, checkpoint, path, storage_options)\u001B[39m\n\u001B[32m     57\u001B[39m fs.makedirs(os.path.dirname(path), exist_ok=\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[32m---> \u001B[39m\u001B[32m58\u001B[39m \u001B[43m_atomic_save\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcheckpoint\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpath\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/kit/graph_hdc/.pixi/envs/default/lib/python3.13/site-packages/lightning_fabric/utilities/cloud_io.py:90\u001B[39m, in \u001B[36m_atomic_save\u001B[39m\u001B[34m(checkpoint, filepath)\u001B[39m\n\u001B[32m     89\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m fs.transaction, fs.open(urlpath, \u001B[33m\"\u001B[39m\u001B[33mwb\u001B[39m\u001B[33m\"\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[32m---> \u001B[39m\u001B[32m90\u001B[39m     \u001B[43mf\u001B[49m\u001B[43m.\u001B[49m\u001B[43mwrite\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbytesbuffer\u001B[49m\u001B[43m.\u001B[49m\u001B[43mgetvalue\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/kit/graph_hdc/.pixi/envs/default/lib/python3.13/site-packages/fsspec/implementations/local.py:465\u001B[39m, in \u001B[36mLocalFileOpener.write\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m    464\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mwrite\u001B[39m(\u001B[38;5;28mself\u001B[39m, *args, **kwargs):\n\u001B[32m--> \u001B[39m\u001B[32m465\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mf\u001B[49m\u001B[43m.\u001B[49m\u001B[43mwrite\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 354\u001B[39m\n\u001B[32m    339\u001B[39m time_logger = TimeLoggingCallback()\n\u001B[32m    341\u001B[39m trainer = Trainer(\n\u001B[32m    342\u001B[39m     max_epochs=cfg.epochs,\n\u001B[32m    343\u001B[39m     logger=[csv_logger,\n\u001B[32m   (...)\u001B[39m\u001B[32m    351\u001B[39m     detect_anomaly=\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[32m    352\u001B[39m )\n\u001B[32m--> \u001B[39m\u001B[32m354\u001B[39m \u001B[43mtrainer\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_dataloaders\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtrain_dataloader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_dataloaders\u001B[49m\u001B[43m=\u001B[49m\u001B[43mvalidation_dataloader\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    356\u001B[39m torch.save(model.state_dict(), models_dir / \u001B[33m\"\u001B[39m\u001B[33mfinal_model.pt\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m    358\u001B[39m metrics_path = Path(csv_logger.log_dir) / \u001B[33m\"\u001B[39m\u001B[33mmetrics.csv\u001B[39m\u001B[33m\"\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/kit/graph_hdc/.pixi/envs/default/lib/python3.13/site-packages/pytorch_lightning/trainer/trainer.py:538\u001B[39m, in \u001B[36mTrainer.fit\u001B[39m\u001B[34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001B[39m\n\u001B[32m    536\u001B[39m \u001B[38;5;28mself\u001B[39m.state.status = TrainerStatus.RUNNING\n\u001B[32m    537\u001B[39m \u001B[38;5;28mself\u001B[39m.training = \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m538\u001B[39m \u001B[43mcall\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_call_and_handle_interrupt\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    539\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_fit_impl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_dataloaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_dataloaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdatamodule\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mckpt_path\u001B[49m\n\u001B[32m    540\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/kit/graph_hdc/.pixi/envs/default/lib/python3.13/site-packages/pytorch_lightning/trainer/call.py:64\u001B[39m, in \u001B[36m_call_and_handle_interrupt\u001B[39m\u001B[34m(trainer, trainer_fn, *args, **kwargs)\u001B[39m\n\u001B[32m     62\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(launcher, _SubprocessScriptLauncher):\n\u001B[32m     63\u001B[39m         launcher.kill(_get_sigkill_signal())\n\u001B[32m---> \u001B[39m\u001B[32m64\u001B[39m     \u001B[43mexit\u001B[49m(\u001B[32m1\u001B[39m)\n\u001B[32m     66\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exception:\n\u001B[32m     67\u001B[39m     _interrupt(trainer, exception)\n",
      "\u001B[31mNameError\u001B[39m: name 'exit' is not defined"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-14T14:46:11.594649Z",
     "start_time": "2025-07-14T14:46:11.590678Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def pca_decode(x_reduced: torch.Tensor, pca: PCA, denorm: bool = False) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Decode PCA-reduced data, with optional de-normalization.\n",
    "\n",
    "    :param x_reduced: Reduced tensor of shape (..., reduced_features).\n",
    "    :type x_reduced: torch.Tensor\n",
    "    :param pca: Fitted PCA instance with attributes `mean_` and `std_`.\n",
    "    :type pca: PCA\n",
    "    :param denorm: Whether to reverse normalization after inverse PCA.\n",
    "    :type denorm: bool\n",
    "    :returns: Reconstructed tensor in original feature space.\n",
    "    :rtype: torch.Tensor\n",
    "\n",
    "    The reduced tensor is flattened, inverse-transformed by PCA, and then\n",
    "    optionally scaled and shifted back.\n",
    "    \"\"\"\n",
    "    flat = x_reduced.view(-1, x_reduced.shape[-1]).detach().cpu().numpy()\n",
    "    recon = pca.inverse_transform(flat)\n",
    "    if denorm:\n",
    "        recon = recon * pca.std_ + pca.mean_\n",
    "    return torch.tensor(recon, dtype=x_reduced.dtype)\n"
   ],
   "id": "ce9ff598e8f85558",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-14T14:46:13.417297Z",
     "start_time": "2025-07-14T14:46:13.369072Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from src.utils.utils import DataTransformer\n",
    "from graph_hdc import utils\n",
    "\n",
    "# ---- Sampling example ----\n",
    "n_samples = 2\n",
    "s, l = model.sample(n_samples)\n",
    "s_decoded = pca_decode(s, pca)\n",
    "z = s_decoded.view(n_samples, 3, hv_dim)\n"
   ],
   "id": "42b7f069f054235",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-14T14:46:15.964910Z",
     "start_time": "2025-07-14T14:46:15.953632Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "import torch\n",
    "from torchhd import HRRTensor\n",
    "\n",
    "node_terms_s, edge_terms_s, graph_embeddings_s = z.unbind(dim=1)\n",
    "\n",
    "# Cast to HRRTensor\n",
    "node_terms_s_hrr        = node_terms_s.as_subclass(HRRTensor)\n",
    "edge_terms_s_hrr        = edge_terms_s.as_subclass(HRRTensor)\n",
    "graph_embeddings_s_hrr  = graph_embeddings_s.as_subclass(HRRTensor)\n",
    "\n",
    "print(\"---SAMPLES---\")\n",
    "for b in range(n_samples):\n",
    "    print(f\"SAMPLE NR: {b}\")\n",
    "    node_counter_dec = encoder.decode_order_zero_counter(node_terms_s_hrr[b])\n",
    "    print(f\"{node_counter_dec[0]=}\")\n",
    "    print(f\"{node_counter_dec[0].total()}\")\n",
    "\n",
    "import torchhd\n",
    "print(\"----RANDOM-----\")\n",
    "random_counter = encoder.decode_order_zero_counter(torchhd.random(1, 6400, vsa=\"HRR\")[0])\n",
    "print(f\"{random_counter[0]=}\")\n",
    "print(f\"{random_counter[0].total()=}\")\n"
   ],
   "id": "85affe280e8ba0a1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---SAMPLES---\n",
      "SAMPLE NR: 0\n",
      "node_counter_dec[0]=Counter({(16, 1): 419, (15, 3): 315, (7, 0): 281, (0, 2): 218, (1, 1): 211, (22, 0): 202, (5, 2): 198, (5, 0): 192, (4, 2): 185, (22, 5): 183, (7, 4): 174, (19, 0): 172, (19, 2): 168, (11, 3): 165, (1, 3): 162, (9, 2): 162, (24, 4): 160, (2, 0): 157, (27, 1): 156, (14, 2): 153, (21, 4): 153, (8, 5): 152, (4, 5): 148, (18, 2): 148, (25, 0): 142, (27, 4): 134, (8, 0): 125, (12, 0): 121, (14, 1): 116, (6, 1): 113, (17, 2): 111, (23, 4): 110, (16, 0): 107, (3, 1): 102, (8, 1): 101, (6, 3): 97, (24, 0): 97, (3, 5): 93, (1, 2): 91, (25, 5): 91, (18, 4): 86, (24, 5): 86, (18, 0): 84, (15, 1): 82, (27, 2): 82, (26, 5): 80, (26, 1): 77, (17, 0): 68, (27, 0): 66, (0, 5): 61, (19, 3): 57, (26, 3): 56, (13, 2): 54, (14, 5): 53, (2, 5): 50, (20, 4): 49, (10, 3): 48, (3, 3): 46, (3, 4): 46, (18, 3): 46, (10, 4): 41, (4, 4): 40, (14, 0): 39, (10, 2): 38, (15, 5): 38, (26, 2): 36, (17, 5): 35, (17, 1): 32, (13, 4): 31, (0, 0): 30, (20, 5): 27, (17, 4): 25, (4, 3): 24, (13, 0): 24, (9, 0): 22, (9, 3): 21, (1, 4): 20, (6, 4): 18, (10, 0): 15, (11, 0): 12, (15, 0): 12, (23, 3): 11, (9, 4): 7, (8, 4): 5, (21, 1): 4, (13, 1): 2, (0, 3): 1})\n",
      "8272\n",
      "SAMPLE NR: 1\n",
      "node_counter_dec[0]=Counter({(16, 1): 418, (15, 3): 314, (7, 0): 280, (0, 2): 219, (1, 1): 210, (22, 0): 201, (5, 2): 197, (5, 0): 191, (4, 2): 185, (22, 5): 185, (7, 4): 175, (19, 0): 172, (19, 2): 169, (11, 3): 166, (1, 3): 163, (9, 2): 162, (24, 4): 160, (2, 0): 157, (27, 1): 157, (21, 4): 154, (14, 2): 153, (8, 5): 151, (18, 2): 148, (4, 5): 147, (25, 0): 142, (27, 4): 134, (8, 0): 125, (12, 0): 120, (14, 1): 115, (6, 1): 114, (17, 2): 111, (23, 4): 110, (16, 0): 107, (8, 1): 101, (3, 1): 100, (24, 0): 97, (6, 3): 96, (3, 5): 93, (1, 2): 92, (25, 5): 91, (24, 5): 86, (18, 4): 85, (18, 0): 84, (15, 1): 82, (27, 2): 82, (26, 5): 81, (26, 1): 77, (17, 0): 70, (27, 0): 65, (0, 5): 62, (19, 3): 57, (26, 3): 56, (13, 2): 55, (14, 5): 53, (2, 5): 51, (10, 3): 49, (20, 4): 49, (3, 3): 48, (3, 4): 47, (18, 3): 45, (4, 4): 40, (10, 4): 40, (15, 5): 40, (10, 2): 39, (14, 0): 39, (17, 5): 36, (26, 2): 35, (17, 1): 32, (13, 4): 30, (0, 0): 29, (20, 5): 28, (4, 3): 25, (17, 4): 25, (13, 0): 24, (9, 0): 22, (1, 4): 20, (9, 3): 20, (6, 4): 18, (10, 0): 16, (11, 0): 12, (15, 0): 11, (23, 3): 11, (9, 4): 6, (8, 4): 5, (21, 1): 4, (0, 3): 1, (13, 1): 1})\n",
      "8275\n",
      "----RANDOM-----\n",
      "random_counter[0]=Counter()\n",
      "random_counter[0].total()=0\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-14T14:47:14.771031Z",
     "start_time": "2025-07-14T14:47:14.500931Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "print(\"---DATA---\")\n",
    "counter = 1\n",
    "for b in train_dataloader:\n",
    "    print(f\"DATA NR: {counter}\")\n",
    "    counter += 1\n",
    "    s_decoded = pca_decode(b, pca)\n",
    "    z = s_decoded.view(batch_size, 3, hv_dim)\n",
    "    node_terms_s, edge_terms_s, graph_embeddings_s = z.unbind(dim=1)\n",
    "    node_terms_s_hrr        = node_terms_s.as_subclass(HRRTensor)\n",
    "    for i in range(batch_size):\n",
    "        node_counter_dec = encoder.decode_order_zero_counter(node_terms_s_hrr[i])\n",
    "        print(f\"{node_counter_dec[0]=}\")\n",
    "        print(f\"{node_counter_dec[0].total()}\")\n"
   ],
   "id": "afec1a13f41449b5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---DATA---\n",
      "DATA NR: 1\n",
      "node_counter_dec[0]=Counter({(0, 2): 3, (0, 3): 1, (1, 1): 1, (2, 3): 1})\n",
      "6\n",
      "node_counter_dec[0]=Counter({(0, 2): 3, (0, 3): 1, (1, 1): 1, (2, 3): 1})\n",
      "6\n",
      "DATA NR: 2\n",
      "node_counter_dec[0]=Counter({(0, 2): 3, (0, 3): 1, (1, 1): 1, (2, 3): 1})\n",
      "6\n",
      "node_counter_dec[0]=Counter({(0, 2): 3, (0, 3): 1, (1, 1): 1, (2, 3): 1})\n",
      "6\n",
      "DATA NR: 3\n",
      "node_counter_dec[0]=Counter({(0, 2): 3, (0, 3): 1, (1, 1): 1, (2, 3): 1})\n",
      "6\n",
      "node_counter_dec[0]=Counter({(0, 2): 3, (0, 3): 1, (1, 1): 1, (2, 3): 1})\n",
      "6\n",
      "DATA NR: 4\n",
      "node_counter_dec[0]=Counter({(0, 2): 3, (0, 3): 1, (1, 1): 1, (2, 3): 1})\n",
      "6\n",
      "node_counter_dec[0]=Counter({(0, 2): 3, (0, 3): 1, (1, 1): 1, (2, 3): 1})\n",
      "6\n",
      "DATA NR: 5\n",
      "node_counter_dec[0]=Counter({(0, 2): 3, (0, 3): 1, (1, 1): 1, (2, 3): 1})\n",
      "6\n",
      "node_counter_dec[0]=Counter({(0, 2): 3, (0, 3): 1, (1, 1): 1, (2, 3): 1})\n",
      "6\n",
      "DATA NR: 6\n",
      "node_counter_dec[0]=Counter({(0, 2): 3, (0, 3): 1, (1, 1): 1, (2, 3): 1})\n",
      "6\n",
      "node_counter_dec[0]=Counter({(0, 2): 3, (0, 3): 1, (1, 1): 1, (2, 3): 1})\n",
      "6\n",
      "DATA NR: 7\n",
      "node_counter_dec[0]=Counter({(0, 2): 3, (0, 3): 1, (1, 1): 1, (2, 3): 1})\n",
      "6\n",
      "node_counter_dec[0]=Counter({(0, 2): 3, (0, 3): 1, (1, 1): 1, (2, 3): 1})\n",
      "6\n",
      "DATA NR: 8\n",
      "node_counter_dec[0]=Counter({(0, 2): 3, (0, 3): 1, (1, 1): 1, (2, 3): 1})\n",
      "6\n",
      "node_counter_dec[0]=Counter({(0, 2): 3, (0, 3): 1, (1, 1): 1, (2, 3): 1})\n",
      "6\n"
     ]
    }
   ],
   "execution_count": 9
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
