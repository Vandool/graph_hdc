{
 "cells": [
  {
   "metadata": {},
   "cell_type": "raw",
   "source": "",
   "id": "b2a3b983e2cb7128"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-14T13:29:31.762031Z",
     "start_time": "2025-07-14T13:26:40.476508Z"
    }
   },
   "source": [
    "import datetime\n",
    "import random\n",
    "import shutil\n",
    "import string\n",
    "import time\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "from torchhd import HRRTensor\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import pytorch_lightning as pl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import Callback, LearningRateMonitor, ModelCheckpoint\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "from sklearn.decomposition import PCA\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch_geometric.data import Batch\n",
    "from torch_geometric.datasets import ZINC\n",
    "\n",
    "from graph_hdc.utils import AbstractEncoder\n",
    "from src.datasets import AddNodeDegree\n",
    "from src.encoding.configs_and_constants import HDCConfig, SupportedDataset\n",
    "from src.encoding.graph_encoders import HyperNet\n",
    "from src.encoding.the_types import VSAModel\n",
    "from src.normalizing_flow.config import FlowConfig\n",
    "from src.normalizing_flow.models import RealNVPLightning\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "def setup_exp(ds_value: str) -> dict:\n",
    "    \"\"\"\n",
    "    Sets up experiment directories based on the current script location.\n",
    "\n",
    "    Args:\n",
    "        ds_value (str): Dataset name to use for global_dataset_dir.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary containing paths to various directories.\n",
    "    \"\"\"\n",
    "    # Resolve script location\n",
    "    script_path = Path(\"/Users/arvandkaveh/Projects/kit/graph_hdc/notebooks/NormFlows/real_nvp.ipynb\")\n",
    "    experiments_path = script_path.parent\n",
    "    script_stem = script_path.stem  # without .py\n",
    "\n",
    "    # Resolve base and project directories\n",
    "    base_dir = experiments_path / \"results\" / script_stem\n",
    "    base_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    project_dir = script_path.parents[2]  # adjust as needed\n",
    "\n",
    "    print(f\"Setting up experiment in {base_dir}\")\n",
    "    now = f\"{datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}_{''.join(random.choices(string.ascii_lowercase, k=4))}\"\n",
    "    exp_dir = base_dir / now\n",
    "    exp_dir.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"Experiment directory created: {exp_dir}\")\n",
    "\n",
    "    dirs = {\n",
    "        \"exp_dir\": exp_dir,\n",
    "        \"models_dir\": exp_dir / \"models\",\n",
    "        \"evals_dir\": exp_dir / \"evaluations\",\n",
    "        \"artefacts_dir\": exp_dir / \"artefacts\",\n",
    "        \"global_model_dir\": project_dir / \"_models\",\n",
    "        \"global_dataset_dir\": project_dir / \"_datasets\" / ds_value,\n",
    "    }\n",
    "\n",
    "    for d in dirs.values():\n",
    "        d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Save a copy of the script\n",
    "    try:\n",
    "        shutil.copy(script_path, exp_dir / script_path.name)\n",
    "        print(f\"Saved a copy of the script to {exp_dir / script_path.name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Failed to save script copy: {e}\")\n",
    "\n",
    "    return dirs\n",
    "\n",
    "\n",
    "def plot_train_val_loss(df, artefacts_dir):\n",
    "    train = df[df[\"train_loss_epoch\"].notna()]\n",
    "    val = df[df[\"val_loss\"].notna()]\n",
    "\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(train[\"epoch\"], train[\"train_loss_epoch\"], label=\"Train Loss\")\n",
    "    plt.plot(val[\"epoch\"], val[\"val_loss\"], label=\"Validation Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Train vs. Validation Loss\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "\n",
    "    artefacts_dir.mkdir(exist_ok=True)\n",
    "    plt.savefig(artefacts_dir / \"train_val_loss.png\")\n",
    "    plt.close()\n",
    "    print(f\"Saved train/val loss plot to {artefacts_dir / 'train_val_loss.png'}\")\n",
    "\n",
    "\n",
    "def pca_encode(x: torch.Tensor, pca: PCA, norm: bool = False) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Encode data using a fitted PCA, with optional normalization.\n",
    "\n",
    "    :param x: Input tensor of shape (..., features).\n",
    "    :type x: torch.Tensor\n",
    "    :param pca: Fitted PCA instance with attributes `mean_` and `std_`.\n",
    "    :type pca: PCA\n",
    "    :param norm: Whether to normalize input by mean and std before PCA.\n",
    "    :type norm: bool\n",
    "    :returns: Tensor of reduced dimensions, same dtype as input.\n",
    "    :rtype: torch.Tensor\n",
    "\n",
    "    The input is flattened over all but the last dimension, optionally normalized,\n",
    "    transformed with the PCA, then returned as a tensor.\n",
    "    \"\"\"\n",
    "    flat = x.view(-1, x.shape[-1]).cpu().numpy()\n",
    "    if norm:\n",
    "        flat = (flat - pca.mean_) / pca.std_\n",
    "    reduced = pca.transform(flat)\n",
    "    return torch.tensor(reduced, dtype=x.dtype)\n",
    "\n",
    "\n",
    "def load_or_fit_pca(\n",
    "        train_dataset: Dataset, encoder: AbstractEncoder, pca_path: Path | None = None, n_components: float = 0.99999,\n",
    "        n_fit: int = 20000\n",
    ") -> PCA:\n",
    "    \"\"\"\n",
    "    Load an existing PCA from disk or fit a new one and save it.\n",
    "\n",
    "    :param train_dataset: Dataset for fitting PCA.\n",
    "    :type train_dataset: Dataset\n",
    "    :param encoder: Model or function returning a dict with keys \\\"node_terms\\\", \\\"edge_terms\\\", and \\\"graph_embedding\\\".\n",
    "    :param pca_path: Path to load/save the PCA object.\n",
    "    :type pca_path: Path\n",
    "    :param n_components: Number of components or variance ratio for PCA.\n",
    "    :type n_components: float\n",
    "    :param n_fit: Maximum number of samples to fit PCA on.\n",
    "    :type n_fit: int\n",
    "    :returns: Fitted PCA instance with `mean_` and `std_` attributes.\n",
    "    :rtype: PCA\n",
    "\n",
    "    If a PCA exists at `pca_path`, it is loaded. Otherwise, embeddings\n",
    "    are collected by applying `encoder` to dataset entries until `n_fit`\n",
    "    samples, flattened, and used to fit a new PCA. The mean and std of the\n",
    "    fit data are stored on the PCA for later normalization.\n",
    "    \"\"\"\n",
    "    if pca_path is not None and pca_path.exists():\n",
    "        print(f\"Loading existing PCA from {pca_path}\")\n",
    "        pca = joblib.load(pca_path)\n",
    "        print(f\"Loaded PCA with {pca.n_components_} components\")\n",
    "        return pca\n",
    "\n",
    "    print(\"Fitting PCA on training data...\")\n",
    "    n_fit = min(n_fit, len(train_dataset))\n",
    "    X_fit = []\n",
    "    for i in range(n_fit):\n",
    "        data = train_dataset[i]\n",
    "        batch_data = Batch.from_data_list([data])\n",
    "        res = encoder.forward(data=batch_data)\n",
    "        x = torch.stack(\n",
    "            [res[\"node_terms\"].squeeze(0), res[\"edge_terms\"].squeeze(0), res[\"graph_embedding\"].squeeze(0)], dim=0\n",
    "        )  # [3, D]\n",
    "        X_fit.append(x.cpu().numpy())\n",
    "    X_fit = np.stack(X_fit)\n",
    "    X_fit_flat = X_fit.reshape(-1, X_fit.shape[-1])\n",
    "\n",
    "    # Compute mean and std for normalization\n",
    "    mu = np.mean(X_fit_flat, axis=0)\n",
    "    sigma = np.std(X_fit_flat, axis=0)\n",
    "\n",
    "    # Fit PCA\n",
    "    pca = PCA(n_components=n_components, svd_solver=\"full\")\n",
    "    pca.fit(X_fit_flat)\n",
    "\n",
    "    # Attach normalization stats\n",
    "    pca.mean_ = mu\n",
    "    pca.std_ = sigma\n",
    "\n",
    "    print(f\"PCA reduced dimension: {pca.n_components_} from {X_fit.shape[-1]}\")\n",
    "    joblib.dump(pca, pca_path)\n",
    "    print(f\"Saved new PCA to {pca_path}\")\n",
    "    return pca\n",
    "\n",
    "\n",
    "def load_or_create_hypernet(path: Path, cfg: HDCConfig, depth: int) -> HyperNet:\n",
    "    path = path / f\"hypernet_{cfg.vsa.value}_d{cfg.hv_dim}_s{cfg.seed}_dpth{depth}.pt\"\n",
    "    if path.exists():\n",
    "        print(f\"Loading existing HyperNet from {path}\")\n",
    "        encoder = HyperNet(config=cfg, depth=depth)\n",
    "        encoder.load(path)\n",
    "    else:\n",
    "        print(\"Creating new HyperNet instance.\")\n",
    "        encoder = HyperNet(config=cfg, depth=depth)\n",
    "        encoder.populate_codebooks()\n",
    "        encoder.save_to_path(path)\n",
    "        print(f\"Saved new HyperNet to {path}\")\n",
    "    return encoder\n",
    "\n",
    "\n",
    "class EncodedPCADataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, base_dataset, encoder, pca: PCA | None = None, *, use_norm_pca: bool = False):\n",
    "        self.base_dataset = base_dataset\n",
    "        self.encoder = encoder\n",
    "        self.pca = pca\n",
    "        self.use_norm = use_norm_pca  # Whether to normalize the PCA\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.base_dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = self.base_dataset[idx]\n",
    "        batch_data = Batch.from_data_list([data])\n",
    "        res = self.encoder.forward(data=batch_data)\n",
    "        x = torch.stack(\n",
    "            [res[\"node_terms\"].squeeze(0), res[\"edge_terms\"].squeeze(0), res[\"graph_embedding\"].squeeze(0)], dim=0\n",
    "        )\n",
    "        if self.pca is not None:\n",
    "            return pca_encode(x, self.pca, self.use_norm)\n",
    "        return x\n",
    "\n",
    "\n",
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        count = torch.cuda.device_count()\n",
    "        print(f\"CUDA is available. Detected {count} GPU device{'s' if count != 1 else ''}.\")\n",
    "        return torch.device(\"cuda\")\n",
    "    print(\"CUDA is not available.\")\n",
    "    return torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "class TimeLoggingCallback(Callback):\n",
    "    def setup(self, trainer, pl_module, stage=None):\n",
    "        self.start_time = time.time()\n",
    "\n",
    "    def on_train_epoch_end(self, trainer, pl_module):\n",
    "        elapsed = time.time() - self.start_time\n",
    "        trainer.logger.log_metrics({\"elapsed_time_sec\": elapsed}, step=trainer.current_epoch)\n",
    "\n",
    "\n",
    "class DebugMetricsCallback(Callback):\n",
    "    def on_train_epoch_end(self, trainer, pl_module):\n",
    "        print(\"\\n==> callback_metrics:\")\n",
    "        for k, v in trainer.callback_metrics.items():\n",
    "            print(f\"   {k:20s} → {type(v)}\")\n",
    "        print()\n",
    "\n",
    "\n",
    "class SamplingEveryNEpoch(Callback):\n",
    "    def __init__(self, encoder, n_samples: int = 10, every_n_epochs: int = 10):\n",
    "        \"\"\"\n",
    "        :param encoder: your graph‐reconstruction encoder, with `.decode_order_zero_counter()`\n",
    "        :param n_samples: how many samples to draw\n",
    "        :param every_n_epochs: interval at which to run the sampling\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.n_samples = n_samples\n",
    "        self.every_n = every_n_epochs\n",
    "\n",
    "    def on_train_epoch_end(self, trainer, pl_module):\n",
    "        epoch = trainer.current_epoch\n",
    "        if epoch % self.every_n != 0:\n",
    "            return\n",
    "\n",
    "        device = pl_module.device\n",
    "        self.encoder.to(device)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            print(f\"\\n=== Sampling callback at epoch {epoch} ===\")\n",
    "            # ---- Sampling example ----\n",
    "            z, logs = pl_module.sample(self.n_samples)\n",
    "            z = z.to(device)\n",
    "\n",
    "            # if you had a PCA decode step:\n",
    "            # z = pca_decode(z, pca)\n",
    "\n",
    "            # unpack into (batch, 3, D)\n",
    "            node_terms_s, _, _ = z.unbind(dim=1)\n",
    "\n",
    "            # Cast to HRRTensor\n",
    "            node_terms_hrr = node_terms_s.as_subclass(HRRTensor)\n",
    "\n",
    "            for b in range(self.n_samples):\n",
    "                print(f\"-- SAMPLE #{b} --\")\n",
    "                node_counter = self.encoder.decode_order_zero_counter(node_terms_hrr[b])\n",
    "                print(f\"node_counter[0] = {node_counter[0]}\")\n",
    "                print(f\"  total = {node_counter[0].total()}\")\n",
    "        pl_module.train()\n",
    "\n",
    "\n",
    "hv_dim = 6400\n",
    "batch_size = 4\n",
    "cfg = FlowConfig(\n",
    "    project_dir=\"/Users/arvandkaveh/Projects/kit/graph_hdc\",\n",
    "    seed=42,\n",
    "    epochs=20,\n",
    "    batch_size=16,\n",
    "    vsa=VSAModel.HRR,\n",
    "    hv_dim=hv_dim,\n",
    "    dataset=SupportedDataset.ZINC_NODE_DEGREE_COMB,\n",
    "    num_input_channels=3 * hv_dim,\n",
    "    num_flows=12,\n",
    "    num_hidden_channels=128,\n",
    "    input_shape=(3, hv_dim),\n",
    "    device=\"cpu\",\n",
    "    lr=0.00003,\n",
    "    weight_decay=0.0001,\n",
    ")\n",
    "\n",
    "print(\"Running experiment\")\n",
    "pprint(cfg.__dict__, indent=2)\n",
    "\n",
    "dirs = setup_exp(cfg.dataset.value)\n",
    "exp_dir = dirs[\"exp_dir\"]\n",
    "models_dir = dirs[\"models_dir\"]\n",
    "evals_dir = dirs[\"evals_dir\"]\n",
    "artefacts_dir = dirs[\"artefacts_dir\"]\n",
    "global_model_dir = dirs[\"global_model_dir\"]\n",
    "global_dataset_dir = dirs[\"global_dataset_dir\"]\n",
    "\n",
    "# W&B Logging — use existing run (from sweep or manual init)\n",
    "# run = wandb.run or wandb.init(project=\"realnvp-hdc\", config=cfg.__dict__, name=f\"run_{cfg.hv_dim}_{cfg.seed}\", reinit=True)\n",
    "# run.tags = [f\"hv_dim={cfg.hv_dim}\", f\"vsa={cfg.vsa.value}\", f\"dataset={cfg.dataset.value}\"]\n",
    "\n",
    "# wandb_logger = WandbLogger(log_model=True, experiment=run)\n",
    "\n",
    "train_dataset = ZINC(root=str(global_dataset_dir), pre_transform=AddNodeDegree(), split=\"train\", subset=True)[:1]\n",
    "# make a length-4 dataset by selecting index 0 four times\n",
    "train_dataset = Subset(train_dataset, indices=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
    "print(f\"{len(train_dataset)=}\")\n",
    "# validation_dataset = ZINC(root=str(global_dataset_dir), pre_transform=AddNodeDegree(), split=\"val\", subset=True)[:1]\n",
    "# print(f\"{len(validation_dataset)=}\")\n",
    "\n",
    "device = get_device()\n",
    "ds = cfg.dataset\n",
    "ds.default_cfg.vsa = cfg.vsa\n",
    "ds.default_cfg.hv_dim = cfg.hv_dim\n",
    "ds.default_cfg.device = device\n",
    "ds.default_cfg.seed = cfg.seed\n",
    "ds.default_cfg.edge_feature_configs = {}\n",
    "ds.default_cfg.graph_feature_configs = {}\n",
    "\n",
    "encoder = load_or_create_hypernet(path=global_model_dir, cfg=ds.default_cfg, depth=3)\n",
    "\n",
    "n_components = 0.99\n",
    "pca_path = global_model_dir / f\"hypervec_pca_{cfg.vsa.value}_d{cfg.hv_dim}_s{cfg.seed}_c{str(n_components)[2:]}.joblib\"\n",
    "pca = load_or_fit_pca(\n",
    "    train_dataset=ZINC(root=str(global_dataset_dir), pre_transform=AddNodeDegree(), split=\"train\", subset=True),\n",
    "    encoder=encoder,\n",
    "    pca_path=pca_path,\n",
    "    n_components=n_components,\n",
    "    n_fit=20_000,\n",
    ")\n",
    "\n",
    "# reduced_dim = int(pca.n_components_)\n",
    "cfg.num_input_channels = 3 * hv_dim\n",
    "cfg.input_shape = (3, hv_dim)\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    EncodedPCADataset(train_dataset, encoder),\n",
    "    batch_size=cfg.batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    pin_memory=torch.cuda.is_available(),\n",
    "    drop_last=True,\n",
    ")\n",
    "#\n",
    "# validation_dataloader = DataLoader(\n",
    "#     EncodedPCADataset(validation_dataset, encoder),\n",
    "#     batch_size=cfg.batch_size,\n",
    "#     shuffle=False,\n",
    "#     num_workers=0,\n",
    "#     pin_memory=torch.cuda.is_available(),\n",
    "#     drop_last=False,\n",
    "# )\n",
    "\n",
    "model = RealNVPLightning(cfg)\n",
    "\n",
    "csv_logger = CSVLogger(save_dir=str(evals_dir), name=\"logs\")\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor=\"val_loss\",\n",
    "    save_top_k=2,\n",
    "    mode=\"min\",\n",
    "    dirpath=str(models_dir),\n",
    "    filename=\"epoch{epoch:02d}-val{val_loss:.2f}\",\n",
    "    save_last=True,\n",
    ")\n",
    "lr_monitor = LearningRateMonitor(logging_interval=\"epoch\")\n",
    "time_logger = TimeLoggingCallback()\n",
    "# debug_callback = DebugMetricsCallback()\n",
    "sampling_cb = SamplingEveryNEpoch(encoder=encoder, n_samples=10, every_n_epochs=10)\n",
    "\n",
    "trainer = Trainer(\n",
    "    max_epochs=cfg.epochs,\n",
    "    logger=[csv_logger,\n",
    "            # wandb_logger\n",
    "            ],\n",
    "    callbacks=[checkpoint_callback, lr_monitor, time_logger,\n",
    "               # debug_callback,\n",
    "\n",
    "               ],\n",
    "    default_root_dir=str(exp_dir),\n",
    "    accelerator=\"auto\",\n",
    "    log_every_n_steps=20,\n",
    "    enable_progress_bar=True,\n",
    "    detect_anomaly=True,\n",
    ")\n",
    "\n",
    "trainer.fit(model,\n",
    "            train_dataloaders=train_dataloader,\n",
    "            # val_dataloaders=validation_dataloader\n",
    "            )\n",
    "\n",
    "torch.save(model.state_dict(), models_dir / \"final_model.pt\")\n",
    "\n",
    "metrics_path = Path(csv_logger.log_dir) / \"metrics.csv\"\n",
    "if metrics_path.exists():\n",
    "    df = pd.read_csv(metrics_path)\n",
    "    df.to_parquet(evals_dir / \"metrics.parquet\")\n",
    "    plot_train_val_loss(df, artefacts_dir)\n",
    "\n",
    "print(\"==== The Experiment is done! ====\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment\n",
      "{ 'activation': <class 'torch.nn.modules.activation.ReLU'>,\n",
      "  'batch_size': 16,\n",
      "  'dataset': <SupportedDataset.ZINC_NODE_DEGREE_COMB: 'ZINC_ND_COMB'>,\n",
      "  'device': 'cpu',\n",
      "  'dropout_probability': 0.0,\n",
      "  'epochs': 20,\n",
      "  'exp_dir': None,\n",
      "  'flow_type': <class 'normflows.flows.neural_spline.wrapper.AutoregressiveRationalQuadraticSpline'>,\n",
      "  'hv_dim': 6400,\n",
      "  'init_identity': True,\n",
      "  'input_shape': (3, 6400),\n",
      "  'lr': 3e-05,\n",
      "  'num_bins': 8,\n",
      "  'num_blocks': 2,\n",
      "  'num_context_channels': None,\n",
      "  'num_flows': 12,\n",
      "  'num_hidden_channels': 128,\n",
      "  'num_input_channels': 19200,\n",
      "  'permute': False,\n",
      "  'project_dir': PosixPath('/Users/arvandkaveh/Projects/kit/graph_hdc'),\n",
      "  'seed': 42,\n",
      "  'tail_bound': 3,\n",
      "  'vsa': <VSAModel.HRR: 'HRR'>,\n",
      "  'weight_decay': 0.0001}\n",
      "Setting up experiment in /Users/arvandkaveh/Projects/kit/graph_hdc/notebooks/NormFlows/results/real_nvp\n",
      "Experiment directory created: /Users/arvandkaveh/Projects/kit/graph_hdc/notebooks/NormFlows/results/real_nvp/2025-07-14_15-27-09_gieh\n",
      "Saved a copy of the script to /Users/arvandkaveh/Projects/kit/graph_hdc/notebooks/NormFlows/results/real_nvp/2025-07-14_15-27-09_gieh/real_nvp.ipynb\n",
      "len(train_dataset)=16\n",
      "CUDA is not available.\n",
      "Loading existing HyperNet from /Users/arvandkaveh/Projects/kit/graph_hdc/_models/hypernet_HRR_d6400_s42_dpth3.pt\n",
      "Fitting PCA on training data...\n",
      "PCA reduced dimension: 56 from 6400\n",
      "Saved new PCA to /Users/arvandkaveh/Projects/kit/graph_hdc/_models/hypervec_pca_HRR_d6400_s42_c99.joblib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You have turned on `Trainer(detect_anomaly=True)`. This will significantly slow down compute speed and is recommended only for model debugging.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/arvandkaveh/Projects/kit/graph_hdc/.pixi/envs/default/lib/python3.13/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "\n",
      "  | Name | Type            | Params | Mode \n",
      "-------------------------------------------------\n",
      "0 | flow | NormalizingFlow | 118 M  | train\n",
      "-------------------------------------------------\n",
      "118 M     Trainable params\n",
      "0         Non-trainable params\n",
      "118 M     Total params\n",
      "475.300   Total estimated model params size (MB)\n",
      "195       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/Users/arvandkaveh/Projects/kit/graph_hdc/.pixi/envs/default/lib/python3.13/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "/Users/arvandkaveh/Projects/kit/graph_hdc/.pixi/envs/default/lib/python3.13/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 1/1 [00:01<00:00,  0.60it/s, v_num=0, train_loss_step=3.04e+9]\n",
      "=== Sampling callback at epoch 0 ===\n",
      "-- SAMPLE #0 --\n",
      "node_counter[0] = Counter({(19, 0): 3, (0, 2): 2, (4, 1): 2, (5, 2): 2, (20, 3): 2, (21, 1): 2, (21, 2): 2, (24, 4): 2, (2, 0): 1, (2, 2): 1, (4, 4): 1, (4, 5): 1, (5, 3): 1, (5, 4): 1, (5, 5): 1, (6, 1): 1, (6, 3): 1, (7, 0): 1, (7, 4): 1, (7, 5): 1, (9, 1): 1, (9, 2): 1, (9, 3): 1, (10, 0): 1, (11, 0): 1, (11, 5): 1, (12, 4): 1, (14, 0): 1, (14, 2): 1, (14, 4): 1, (17, 0): 1, (17, 3): 1, (18, 4): 1, (18, 5): 1, (20, 0): 1, (20, 1): 1, (20, 4): 1, (21, 0): 1, (22, 2): 1, (23, 0): 1, (23, 1): 1, (23, 3): 1, (23, 4): 1, (24, 0): 1, (24, 5): 1, (25, 1): 1, (25, 4): 1, (26, 1): 1, (26, 3): 1, (27, 4): 1, (27, 5): 1})\n",
      "  total = 60\n",
      "-- SAMPLE #1 --\n",
      "node_counter[0] = Counter({(18, 2): 3, (0, 2): 2, (0, 4): 2, (4, 3): 2, (4, 4): 2, (5, 0): 2, (5, 3): 2, (12, 3): 2, (12, 4): 2, (16, 0): 2, (18, 4): 2, (22, 2): 2, (26, 2): 2, (1, 1): 1, (2, 2): 1, (2, 5): 1, (3, 3): 1, (4, 5): 1, (6, 3): 1, (6, 4): 1, (6, 5): 1, (7, 2): 1, (8, 3): 1, (9, 2): 1, (9, 5): 1, (10, 1): 1, (10, 2): 1, (11, 3): 1, (11, 4): 1, (13, 0): 1, (13, 5): 1, (14, 0): 1, (14, 2): 1, (15, 4): 1, (16, 3): 1, (17, 1): 1, (19, 1): 1, (19, 3): 1, (20, 0): 1, (20, 2): 1, (21, 0): 1, (21, 4): 1, (21, 5): 1, (24, 2): 1, (25, 2): 1, (25, 5): 1, (26, 3): 1, (26, 4): 1, (27, 1): 1, (27, 2): 1, (27, 4): 1})\n",
      "  total = 65\n",
      "-- SAMPLE #2 --\n",
      "node_counter[0] = Counter({(13, 0): 3, (21, 0): 3, (0, 4): 2, (5, 5): 2, (9, 5): 2, (25, 2): 2, (0, 3): 1, (0, 5): 1, (1, 3): 1, (2, 2): 1, (2, 5): 1, (3, 2): 1, (3, 5): 1, (4, 2): 1, (6, 2): 1, (6, 3): 1, (6, 5): 1, (7, 4): 1, (8, 0): 1, (10, 1): 1, (10, 3): 1, (13, 3): 1, (13, 4): 1, (14, 3): 1, (14, 5): 1, (15, 2): 1, (15, 4): 1, (16, 3): 1, (17, 1): 1, (17, 4): 1, (17, 5): 1, (19, 0): 1, (19, 2): 1, (20, 1): 1, (21, 3): 1, (22, 0): 1, (22, 3): 1, (23, 2): 1, (23, 5): 1, (24, 0): 1, (24, 2): 1, (24, 3): 1, (25, 5): 1, (26, 3): 1, (26, 4): 1, (26, 5): 1})\n",
      "  total = 54\n",
      "-- SAMPLE #3 --\n",
      "node_counter[0] = Counter({(0, 2): 2, (1, 0): 2, (1, 4): 2, (3, 0): 2, (5, 3): 2, (9, 5): 2, (10, 1): 2, (13, 0): 2, (13, 4): 2, (16, 2): 2, (19, 1): 2, (0, 3): 1, (2, 3): 1, (2, 4): 1, (4, 1): 1, (4, 3): 1, (4, 4): 1, (6, 0): 1, (6, 2): 1, (6, 4): 1, (7, 0): 1, (7, 1): 1, (7, 2): 1, (8, 0): 1, (8, 1): 1, (8, 4): 1, (9, 2): 1, (10, 2): 1, (11, 5): 1, (12, 4): 1, (13, 1): 1, (13, 2): 1, (14, 0): 1, (14, 3): 1, (15, 4): 1, (16, 1): 1, (16, 4): 1, (16, 5): 1, (17, 1): 1, (17, 2): 1, (18, 1): 1, (18, 3): 1, (19, 4): 1, (22, 3): 1, (23, 2): 1, (24, 2): 1, (24, 5): 1, (25, 0): 1, (25, 4): 1, (26, 5): 1, (27, 0): 1, (27, 1): 1, (27, 3): 1})\n",
      "  total = 64\n",
      "-- SAMPLE #4 --\n",
      "node_counter[0] = Counter({(0, 2): 2, (1, 4): 2, (2, 2): 2, (2, 3): 2, (9, 3): 2, (10, 0): 2, (13, 0): 2, (13, 4): 2, (17, 4): 2, (18, 3): 2, (20, 1): 2, (22, 5): 2, (25, 2): 2, (26, 3): 2, (0, 0): 1, (0, 1): 1, (0, 3): 1, (3, 3): 1, (3, 4): 1, (4, 0): 1, (4, 1): 1, (4, 3): 1, (4, 4): 1, (5, 1): 1, (5, 2): 1, (6, 5): 1, (7, 0): 1, (7, 3): 1, (7, 4): 1, (7, 5): 1, (8, 0): 1, (8, 4): 1, (9, 1): 1, (10, 4): 1, (11, 5): 1, (12, 1): 1, (12, 2): 1, (12, 5): 1, (13, 5): 1, (14, 0): 1, (14, 2): 1, (14, 5): 1, (15, 0): 1, (15, 5): 1, (17, 5): 1, (18, 5): 1, (19, 0): 1, (19, 1): 1, (19, 2): 1, (20, 2): 1, (20, 5): 1, (21, 0): 1, (22, 3): 1, (25, 3): 1, (25, 4): 1, (26, 1): 1, (26, 4): 1, (27, 0): 1, (27, 4): 1, (27, 5): 1})\n",
      "  total = 74\n",
      "-- SAMPLE #5 --\n",
      "node_counter[0] = Counter({(7, 4): 3, (0, 0): 2, (2, 2): 2, (2, 4): 2, (3, 3): 2, (4, 3): 2, (6, 3): 2, (10, 4): 2, (11, 0): 2, (12, 1): 2, (12, 3): 2, (13, 4): 2, (14, 3): 2, (17, 0): 2, (21, 3): 2, (23, 0): 2, (1, 3): 1, (2, 3): 1, (3, 0): 1, (3, 2): 1, (5, 1): 1, (5, 3): 1, (6, 0): 1, (6, 1): 1, (7, 0): 1, (9, 0): 1, (9, 1): 1, (11, 1): 1, (11, 3): 1, (12, 0): 1, (12, 2): 1, (12, 4): 1, (13, 0): 1, (13, 5): 1, (15, 1): 1, (17, 2): 1, (18, 0): 1, (18, 4): 1, (19, 2): 1, (19, 3): 1, (20, 1): 1, (20, 4): 1, (21, 0): 1, (23, 2): 1, (24, 3): 1, (25, 1): 1, (25, 4): 1, (26, 2): 1, (26, 4): 1, (26, 5): 1, (27, 1): 1, (27, 4): 1})\n",
      "  total = 69\n",
      "-- SAMPLE #6 --\n",
      "node_counter[0] = Counter({(27, 1): 3, (1, 0): 2, (6, 1): 2, (10, 2): 2, (12, 1): 2, (16, 0): 2, (21, 4): 2, (25, 1): 2, (26, 0): 2, (0, 0): 1, (2, 1): 1, (2, 5): 1, (3, 0): 1, (3, 3): 1, (4, 1): 1, (4, 4): 1, (5, 0): 1, (5, 3): 1, (5, 5): 1, (6, 0): 1, (6, 4): 1, (7, 1): 1, (8, 1): 1, (8, 3): 1, (8, 5): 1, (9, 2): 1, (9, 4): 1, (11, 1): 1, (11, 4): 1, (11, 5): 1, (12, 5): 1, (13, 0): 1, (13, 5): 1, (14, 4): 1, (15, 3): 1, (16, 4): 1, (16, 5): 1, (17, 1): 1, (17, 4): 1, (18, 0): 1, (19, 2): 1, (19, 4): 1, (20, 1): 1, (20, 2): 1, (20, 4): 1, (21, 1): 1, (21, 2): 1, (22, 4): 1, (23, 0): 1, (23, 2): 1, (23, 4): 1, (23, 5): 1, (25, 4): 1, (26, 4): 1})\n",
      "  total = 64\n",
      "-- SAMPLE #7 --\n",
      "node_counter[0] = Counter({(10, 0): 2, (16, 4): 2, (19, 1): 2, (26, 5): 2, (27, 3): 2, (27, 4): 2, (0, 2): 1, (1, 3): 1, (1, 4): 1, (1, 5): 1, (2, 1): 1, (2, 4): 1, (2, 5): 1, (3, 1): 1, (3, 4): 1, (4, 0): 1, (4, 5): 1, (5, 0): 1, (6, 4): 1, (7, 5): 1, (8, 0): 1, (12, 0): 1, (13, 0): 1, (13, 1): 1, (14, 0): 1, (15, 1): 1, (15, 2): 1, (16, 5): 1, (17, 0): 1, (17, 4): 1, (18, 2): 1, (18, 3): 1, (18, 4): 1, (20, 1): 1, (20, 4): 1, (21, 0): 1, (21, 3): 1, (21, 4): 1, (22, 0): 1, (22, 1): 1, (23, 0): 1, (23, 3): 1, (24, 0): 1, (26, 1): 1, (26, 4): 1, (27, 1): 1, (27, 2): 1})\n",
      "  total = 53\n",
      "-- SAMPLE #8 --\n",
      "node_counter[0] = Counter({(13, 4): 3, (1, 1): 2, (4, 3): 2, (5, 0): 2, (8, 0): 2, (11, 1): 2, (18, 1): 2, (19, 1): 2, (21, 1): 2, (21, 3): 2, (22, 1): 2, (22, 2): 2, (23, 4): 2, (24, 0): 2, (0, 1): 1, (0, 5): 1, (1, 5): 1, (2, 0): 1, (2, 2): 1, (3, 2): 1, (5, 2): 1, (5, 3): 1, (7, 2): 1, (8, 2): 1, (9, 1): 1, (10, 3): 1, (11, 4): 1, (12, 1): 1, (12, 3): 1, (12, 4): 1, (15, 2): 1, (15, 4): 1, (15, 5): 1, (16, 0): 1, (16, 1): 1, (18, 4): 1, (18, 5): 1, (19, 3): 1, (19, 4): 1, (20, 3): 1, (21, 5): 1, (22, 0): 1, (24, 3): 1, (25, 2): 1, (26, 2): 1})\n",
      "  total = 60\n",
      "-- SAMPLE #9 --\n",
      "node_counter[0] = Counter({(1, 1): 2, (2, 1): 2, (4, 1): 2, (5, 3): 2, (5, 4): 2, (7, 4): 2, (13, 2): 2, (14, 0): 2, (16, 0): 2, (16, 5): 2, (22, 0): 2, (23, 1): 2, (0, 2): 1, (1, 0): 1, (1, 2): 1, (1, 3): 1, (1, 5): 1, (2, 2): 1, (3, 4): 1, (3, 5): 1, (4, 2): 1, (4, 5): 1, (7, 5): 1, (8, 1): 1, (8, 4): 1, (8, 5): 1, (9, 2): 1, (9, 5): 1, (14, 1): 1, (14, 2): 1, (14, 5): 1, (15, 3): 1, (17, 2): 1, (18, 0): 1, (18, 5): 1, (19, 0): 1, (19, 5): 1, (20, 1): 1, (20, 5): 1, (21, 2): 1, (21, 5): 1, (22, 1): 1, (22, 3): 1, (22, 4): 1, (23, 3): 1, (24, 4): 1, (24, 5): 1, (25, 4): 1, (26, 5): 1, (27, 2): 1})\n",
      "  total = 62\n",
      "Epoch 0: 100%|██████████| 1/1 [00:06<00:00,  0.16it/s, v_num=0, train_loss_step=3.04e+9, lr=3e-5, train_loss_epoch=3.04e+9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arvandkaveh/Projects/kit/graph_hdc/.pixi/envs/default/lib/python3.13/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:384: `ModelCheckpoint(monitor='val_loss')` could not find the monitored key in the returned metrics: ['lr-Adam', 'train_loss', 'train_loss_step', 'lr', 'train_loss_epoch', 'epoch', 'step']. HINT: Did you call `log('val_loss', value)` in the `LightningModule`?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 1/1 [00:00<00:00,  1.26it/s, v_num=0, train_loss_step=1.52e+9, lr=3e-5, train_loss_epoch=1.52e+9]\n",
      "=== Sampling callback at epoch 10 ===\n",
      "-- SAMPLE #0 --\n",
      "node_counter[0] = Counter({(0, 0): 3, (6, 0): 3, (18, 5): 3, (1, 4): 2, (2, 0): 2, (2, 4): 2, (3, 5): 2, (5, 1): 2, (7, 2): 2, (8, 0): 2, (10, 4): 2, (14, 1): 2, (17, 1): 2, (22, 3): 2, (24, 2): 2, (25, 5): 2, (0, 5): 1, (2, 2): 1, (3, 4): 1, (4, 0): 1, (5, 4): 1, (6, 4): 1, (6, 5): 1, (7, 3): 1, (7, 5): 1, (8, 4): 1, (9, 4): 1, (10, 2): 1, (10, 5): 1, (12, 2): 1, (13, 1): 1, (14, 2): 1, (15, 0): 1, (15, 4): 1, (15, 5): 1, (17, 4): 1, (18, 1): 1, (18, 3): 1, (19, 3): 1, (19, 5): 1, (20, 0): 1, (20, 2): 1, (21, 0): 1, (21, 2): 1, (23, 1): 1, (23, 3): 1, (23, 4): 1, (24, 3): 1, (24, 4): 1, (24, 5): 1, (25, 3): 1, (26, 2): 1, (27, 1): 1, (27, 2): 1})\n",
      "  total = 73\n",
      "-- SAMPLE #1 --\n",
      "node_counter[0] = Counter({(8, 4): 3, (15, 5): 3, (0, 0): 2, (10, 1): 2, (27, 4): 2, (1, 0): 1, (2, 1): 1, (2, 3): 1, (2, 5): 1, (3, 2): 1, (5, 0): 1, (6, 0): 1, (6, 1): 1, (6, 3): 1, (7, 2): 1, (7, 4): 1, (8, 5): 1, (9, 0): 1, (10, 3): 1, (10, 4): 1, (11, 0): 1, (11, 2): 1, (12, 1): 1, (12, 2): 1, (12, 5): 1, (13, 0): 1, (14, 2): 1, (14, 5): 1, (15, 2): 1, (16, 1): 1, (16, 2): 1, (18, 0): 1, (18, 4): 1, (18, 5): 1, (19, 1): 1, (20, 0): 1, (23, 5): 1, (24, 0): 1, (26, 0): 1, (26, 5): 1})\n",
      "  total = 47\n",
      "-- SAMPLE #2 --\n",
      "node_counter[0] = Counter({(26, 4): 4, (19, 1): 3, (0, 0): 2, (3, 1): 2, (3, 2): 2, (4, 3): 2, (9, 5): 2, (12, 0): 2, (13, 0): 2, (19, 4): 2, (23, 0): 2, (26, 2): 2, (2, 2): 1, (2, 5): 1, (3, 4): 1, (3, 5): 1, (5, 1): 1, (6, 0): 1, (6, 2): 1, (6, 4): 1, (6, 5): 1, (7, 5): 1, (8, 0): 1, (8, 1): 1, (10, 0): 1, (10, 1): 1, (11, 0): 1, (11, 4): 1, (11, 5): 1, (13, 4): 1, (14, 3): 1, (15, 0): 1, (17, 1): 1, (17, 5): 1, (19, 2): 1, (19, 5): 1, (20, 3): 1, (21, 2): 1, (22, 3): 1, (24, 1): 1, (24, 2): 1, (25, 3): 1, (26, 3): 1, (27, 1): 1, (27, 4): 1})\n",
      "  total = 60\n",
      "-- SAMPLE #3 --\n",
      "node_counter[0] = Counter({(19, 4): 3, (4, 1): 2, (10, 4): 2, (20, 5): 2, (26, 2): 2, (27, 1): 2, (1, 0): 1, (1, 5): 1, (2, 1): 1, (2, 5): 1, (3, 0): 1, (3, 1): 1, (4, 4): 1, (5, 1): 1, (5, 4): 1, (6, 3): 1, (6, 5): 1, (8, 3): 1, (9, 0): 1, (9, 1): 1, (10, 1): 1, (10, 3): 1, (12, 0): 1, (13, 0): 1, (13, 1): 1, (13, 4): 1, (15, 1): 1, (15, 4): 1, (15, 5): 1, (16, 2): 1, (17, 1): 1, (18, 0): 1, (18, 1): 1, (18, 3): 1, (18, 4): 1, (19, 1): 1, (20, 4): 1, (22, 1): 1, (24, 3): 1, (24, 4): 1, (25, 2): 1, (26, 0): 1, (26, 3): 1})\n",
      "  total = 50\n",
      "-- SAMPLE #4 --\n",
      "node_counter[0] = Counter({(0, 4): 2, (1, 1): 2, (2, 5): 2, (4, 5): 2, (6, 4): 2, (8, 2): 2, (12, 0): 2, (18, 3): 2, (19, 1): 2, (24, 5): 2, (0, 0): 1, (0, 5): 1, (1, 3): 1, (1, 5): 1, (3, 1): 1, (4, 0): 1, (4, 1): 1, (4, 4): 1, (5, 2): 1, (6, 3): 1, (7, 2): 1, (8, 4): 1, (8, 5): 1, (9, 1): 1, (9, 3): 1, (10, 3): 1, (11, 0): 1, (11, 5): 1, (12, 5): 1, (13, 4): 1, (13, 5): 1, (14, 0): 1, (14, 3): 1, (15, 1): 1, (15, 4): 1, (15, 5): 1, (16, 0): 1, (16, 2): 1, (16, 5): 1, (17, 2): 1, (17, 5): 1, (18, 1): 1, (18, 5): 1, (19, 3): 1, (20, 2): 1, (20, 3): 1, (22, 1): 1, (22, 3): 1, (23, 2): 1, (24, 2): 1, (24, 3): 1, (25, 1): 1, (25, 2): 1, (25, 5): 1, (26, 0): 1, (26, 1): 1, (26, 2): 1})\n",
      "  total = 67\n",
      "-- SAMPLE #5 --\n",
      "node_counter[0] = Counter({(23, 3): 3, (0, 1): 2, (2, 0): 2, (4, 4): 2, (5, 1): 2, (9, 1): 2, (11, 2): 2, (16, 1): 2, (17, 0): 2, (18, 4): 2, (21, 3): 2, (22, 5): 2, (23, 5): 2, (25, 3): 2, (26, 3): 2, (27, 2): 2, (0, 3): 1, (2, 3): 1, (3, 0): 1, (4, 0): 1, (4, 1): 1, (4, 5): 1, (6, 4): 1, (7, 3): 1, (7, 4): 1, (8, 0): 1, (8, 1): 1, (8, 2): 1, (8, 4): 1, (9, 0): 1, (9, 3): 1, (9, 4): 1, (10, 4): 1, (12, 4): 1, (12, 5): 1, (13, 5): 1, (15, 3): 1, (15, 4): 1, (15, 5): 1, (16, 0): 1, (16, 2): 1, (18, 3): 1, (19, 2): 1, (19, 4): 1, (19, 5): 1, (21, 1): 1, (21, 2): 1, (23, 0): 1, (23, 4): 1, (24, 1): 1, (25, 0): 1, (25, 5): 1, (26, 0): 1})\n",
      "  total = 70\n",
      "-- SAMPLE #6 --\n",
      "node_counter[0] = Counter({(2, 2): 3, (5, 5): 3, (19, 4): 3, (1, 1): 2, (4, 5): 2, (5, 2): 2, (6, 0): 2, (18, 5): 2, (19, 0): 2, (21, 0): 2, (26, 3): 2, (0, 4): 1, (0, 5): 1, (1, 0): 1, (1, 3): 1, (3, 5): 1, (4, 1): 1, (6, 1): 1, (6, 2): 1, (6, 3): 1, (6, 4): 1, (6, 5): 1, (7, 0): 1, (7, 1): 1, (8, 4): 1, (9, 2): 1, (10, 2): 1, (11, 0): 1, (11, 1): 1, (11, 4): 1, (11, 5): 1, (12, 2): 1, (14, 0): 1, (14, 1): 1, (14, 3): 1, (16, 3): 1, (17, 3): 1, (19, 1): 1, (19, 5): 1, (20, 4): 1, (22, 0): 1, (22, 1): 1, (22, 3): 1, (22, 4): 1, (23, 4): 1, (24, 2): 1, (25, 2): 1, (26, 2): 1, (26, 4): 1, (26, 5): 1})\n",
      "  total = 64\n",
      "-- SAMPLE #7 --\n",
      "node_counter[0] = Counter({(14, 4): 4, (15, 3): 3, (20, 2): 3, (3, 3): 2, (4, 1): 2, (15, 1): 2, (15, 5): 2, (22, 2): 2, (25, 0): 2, (25, 3): 2, (25, 4): 2, (26, 0): 2, (27, 5): 2, (0, 2): 1, (0, 3): 1, (1, 0): 1, (1, 1): 1, (2, 4): 1, (2, 5): 1, (3, 1): 1, (3, 4): 1, (3, 5): 1, (4, 2): 1, (5, 1): 1, (5, 2): 1, (6, 5): 1, (10, 0): 1, (10, 3): 1, (10, 5): 1, (11, 3): 1, (12, 2): 1, (13, 0): 1, (13, 1): 1, (15, 0): 1, (16, 4): 1, (17, 0): 1, (17, 4): 1, (17, 5): 1, (18, 1): 1, (18, 4): 1, (20, 3): 1, (20, 4): 1, (20, 5): 1, (21, 2): 1, (22, 1): 1, (23, 4): 1, (24, 5): 1, (25, 2): 1, (27, 2): 1})\n",
      "  total = 66\n",
      "-- SAMPLE #8 --\n",
      "node_counter[0] = Counter({(7, 5): 2, (10, 3): 2, (12, 5): 2, (13, 1): 2, (13, 4): 2, (20, 1): 2, (20, 3): 2, (24, 1): 2, (24, 3): 2, (25, 1): 2, (25, 4): 2, (27, 0): 2, (0, 2): 1, (1, 1): 1, (3, 2): 1, (4, 0): 1, (4, 1): 1, (4, 4): 1, (4, 5): 1, (6, 1): 1, (6, 3): 1, (6, 5): 1, (7, 1): 1, (7, 2): 1, (7, 4): 1, (8, 1): 1, (8, 2): 1, (8, 5): 1, (10, 0): 1, (10, 1): 1, (10, 4): 1, (11, 0): 1, (11, 3): 1, (11, 4): 1, (11, 5): 1, (12, 0): 1, (12, 3): 1, (12, 4): 1, (13, 0): 1, (13, 3): 1, (14, 4): 1, (15, 1): 1, (15, 3): 1, (15, 5): 1, (16, 0): 1, (16, 5): 1, (17, 1): 1, (19, 0): 1, (19, 3): 1, (20, 0): 1, (20, 2): 1, (20, 4): 1, (23, 0): 1, (23, 1): 1, (23, 5): 1, (26, 0): 1, (27, 3): 1, (27, 4): 1})\n",
      "  total = 70\n",
      "-- SAMPLE #9 --\n",
      "node_counter[0] = Counter({(20, 5): 3, (3, 2): 2, (5, 3): 2, (11, 0): 2, (16, 1): 2, (24, 0): 2, (24, 4): 2, (25, 3): 2, (27, 3): 2, (1, 3): 1, (1, 5): 1, (2, 0): 1, (5, 2): 1, (6, 2): 1, (6, 3): 1, (6, 5): 1, (7, 3): 1, (8, 4): 1, (9, 3): 1, (9, 4): 1, (10, 2): 1, (10, 3): 1, (10, 4): 1, (12, 0): 1, (12, 1): 1, (12, 2): 1, (12, 3): 1, (13, 1): 1, (14, 0): 1, (14, 2): 1, (14, 3): 1, (14, 4): 1, (14, 5): 1, (16, 5): 1, (17, 0): 1, (17, 2): 1, (17, 3): 1, (18, 2): 1, (20, 0): 1, (20, 1): 1, (20, 2): 1, (21, 2): 1, (21, 3): 1, (22, 2): 1, (23, 1): 1, (23, 3): 1, (24, 5): 1, (26, 2): 1})\n",
      "  total = 58\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  1.08it/s, v_num=0, train_loss_step=1.52e+9, lr=3e-5, train_loss_epoch=1.52e+9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 1/1 [00:02<00:00,  0.40it/s, v_num=0, train_loss_step=1.52e+9, lr=3e-5, train_loss_epoch=1.52e+9]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'val_loss'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyError\u001B[39m                                  Traceback (most recent call last)",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/kit/graph_hdc/.pixi/envs/default/lib/python3.13/site-packages/pandas/core/indexes/base.py:3812\u001B[39m, in \u001B[36mIndex.get_loc\u001B[39m\u001B[34m(self, key)\u001B[39m\n\u001B[32m   3811\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m3812\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_engine\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcasted_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   3813\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "\u001B[36mFile \u001B[39m\u001B[32mpandas/_libs/index.pyx:167\u001B[39m, in \u001B[36mpandas._libs.index.IndexEngine.get_loc\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mpandas/_libs/index.pyx:196\u001B[39m, in \u001B[36mpandas._libs.index.IndexEngine.get_loc\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001B[39m, in \u001B[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001B[39m, in \u001B[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[31mKeyError\u001B[39m: 'val_loss'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[31mKeyError\u001B[39m                                  Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 421\u001B[39m\n\u001B[32m    419\u001B[39m     df = pd.read_csv(metrics_path)\n\u001B[32m    420\u001B[39m     df.to_parquet(evals_dir / \u001B[33m\"\u001B[39m\u001B[33mmetrics.parquet\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m--> \u001B[39m\u001B[32m421\u001B[39m     \u001B[43mplot_train_val_loss\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43martefacts_dir\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    423\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33m==== The Experiment is done! ====\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 83\u001B[39m, in \u001B[36mplot_train_val_loss\u001B[39m\u001B[34m(df, artefacts_dir)\u001B[39m\n\u001B[32m     81\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mplot_train_val_loss\u001B[39m(df, artefacts_dir):\n\u001B[32m     82\u001B[39m     train = df[df[\u001B[33m\"\u001B[39m\u001B[33mtrain_loss_epoch\u001B[39m\u001B[33m\"\u001B[39m].notna()]\n\u001B[32m---> \u001B[39m\u001B[32m83\u001B[39m     val = df[\u001B[43mdf\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mval_loss\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m.notna()]\n\u001B[32m     85\u001B[39m     plt.figure(figsize=(\u001B[32m8\u001B[39m, \u001B[32m5\u001B[39m))\n\u001B[32m     86\u001B[39m     plt.plot(train[\u001B[33m\"\u001B[39m\u001B[33mepoch\u001B[39m\u001B[33m\"\u001B[39m], train[\u001B[33m\"\u001B[39m\u001B[33mtrain_loss_epoch\u001B[39m\u001B[33m\"\u001B[39m], label=\u001B[33m\"\u001B[39m\u001B[33mTrain Loss\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/kit/graph_hdc/.pixi/envs/default/lib/python3.13/site-packages/pandas/core/frame.py:4107\u001B[39m, in \u001B[36mDataFrame.__getitem__\u001B[39m\u001B[34m(self, key)\u001B[39m\n\u001B[32m   4105\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.columns.nlevels > \u001B[32m1\u001B[39m:\n\u001B[32m   4106\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._getitem_multilevel(key)\n\u001B[32m-> \u001B[39m\u001B[32m4107\u001B[39m indexer = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mcolumns\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   4108\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[32m   4109\u001B[39m     indexer = [indexer]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/kit/graph_hdc/.pixi/envs/default/lib/python3.13/site-packages/pandas/core/indexes/base.py:3819\u001B[39m, in \u001B[36mIndex.get_loc\u001B[39m\u001B[34m(self, key)\u001B[39m\n\u001B[32m   3814\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(casted_key, \u001B[38;5;28mslice\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m (\n\u001B[32m   3815\u001B[39m         \u001B[38;5;28misinstance\u001B[39m(casted_key, abc.Iterable)\n\u001B[32m   3816\u001B[39m         \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28many\u001B[39m(\u001B[38;5;28misinstance\u001B[39m(x, \u001B[38;5;28mslice\u001B[39m) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m casted_key)\n\u001B[32m   3817\u001B[39m     ):\n\u001B[32m   3818\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m InvalidIndexError(key)\n\u001B[32m-> \u001B[39m\u001B[32m3819\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01merr\u001B[39;00m\n\u001B[32m   3820\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[32m   3821\u001B[39m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[32m   3822\u001B[39m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[32m   3823\u001B[39m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[32m   3824\u001B[39m     \u001B[38;5;28mself\u001B[39m._check_indexing_error(key)\n",
      "\u001B[31mKeyError\u001B[39m: 'val_loss'"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-14T11:13:09.367090Z",
     "start_time": "2025-07-14T09:05:23.383952Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def pca_decode(x_reduced: torch.Tensor, pca: PCA, denorm: bool = False) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Decode PCA-reduced data, with optional de-normalization.\n",
    "\n",
    "    :param x_reduced: Reduced tensor of shape (..., reduced_features).\n",
    "    :type x_reduced: torch.Tensor\n",
    "    :param pca: Fitted PCA instance with attributes `mean_` and `std_`.\n",
    "    :type pca: PCA\n",
    "    :param denorm: Whether to reverse normalization after inverse PCA.\n",
    "    :type denorm: bool\n",
    "    :returns: Reconstructed tensor in original feature space.\n",
    "    :rtype: torch.Tensor\n",
    "\n",
    "    The reduced tensor is flattened, inverse-transformed by PCA, and then\n",
    "    optionally scaled and shifted back.\n",
    "    \"\"\"\n",
    "    flat = x_reduced.view(-1, x_reduced.shape[-1]).detach().cpu().numpy()\n",
    "    recon = pca.inverse_transform(flat)\n",
    "    if denorm:\n",
    "        recon = recon * pca.std_ + pca.mean_\n",
    "    return torch.tensor(recon, dtype=x_reduced.dtype)\n"
   ],
   "id": "ce9ff598e8f85558",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-14T13:30:29.975720Z",
     "start_time": "2025-07-14T13:30:28.249289Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "model_loaded = RealNVPLightning.load_from_checkpoint(\"/Users/arvandkaveh/Projects/kit/graph_hdc/notebooks/NormFlows/results/real_nvp/2025-07-14_15-27-09_gieh/models/last.ckpt\")\n",
    "\n",
    "# ---- Sampling example ----\n",
    "n_samples = 10\n",
    "model_loaded.eval()\n",
    "s, l = model_loaded.sample(n_samples)\n",
    "encoder.to(model_loaded.device)\n",
    "# s_decoded = pca_decode(s, pca)\n",
    "# z = s_decoded.view(n_samples, 3, hv_dim)\n",
    "z = s"
   ],
   "id": "42b7f069f054235",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-14T13:30:32.219093Z",
     "start_time": "2025-07-14T13:30:31.924300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "import torch\n",
    "from torchhd import HRRTensor\n",
    "\n",
    "node_terms_s, edge_terms_s, graph_embeddings_s = z.unbind(dim=1)\n",
    "\n",
    "# Cast to HRRTensor\n",
    "node_terms_s_hrr = node_terms_s.as_subclass(HRRTensor)\n",
    "edge_terms_s_hrr = edge_terms_s.as_subclass(HRRTensor)\n",
    "graph_embeddings_s_hrr = graph_embeddings_s.as_subclass(HRRTensor)\n",
    "\n",
    "print(\"---SAMPLES---\")\n",
    "for b in range(n_samples):\n",
    "    print(f\"SAMPLE NR: {b}\")\n",
    "    node_counter_dec = encoder.decode_order_zero_counter(node_terms_s_hrr[b])\n",
    "    print(f\"{node_counter_dec[0]=}\")\n",
    "    print(f\"{node_counter_dec[0].total()}\")\n",
    "\n",
    "import torchhd\n",
    "\n",
    "print(\"----RANDOM-----\")\n",
    "random_counter = encoder.decode_order_zero_counter(torchhd.random(1, 6400, vsa=\"HRR\")[0])\n",
    "print(f\"{random_counter[0]=}\")\n",
    "print(f\"{random_counter[0].total()=}\")\n"
   ],
   "id": "85affe280e8ba0a1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---SAMPLES---\n",
      "SAMPLE NR: 0\n",
      "node_counter_dec[0]=Counter({(1, 3): 2, (4, 2): 2, (6, 4): 2, (9, 5): 2, (14, 1): 2, (17, 0): 2, (17, 4): 2, (19, 1): 2, (24, 5): 2, (25, 2): 2, (0, 0): 1, (0, 2): 1, (0, 4): 1, (0, 5): 1, (2, 2): 1, (5, 0): 1, (6, 0): 1, (6, 1): 1, (7, 2): 1, (7, 3): 1, (8, 1): 1, (9, 0): 1, (9, 4): 1, (10, 2): 1, (11, 0): 1, (11, 3): 1, (12, 0): 1, (12, 3): 1, (13, 1): 1, (14, 5): 1, (15, 3): 1, (16, 5): 1, (17, 2): 1, (19, 0): 1, (20, 2): 1, (21, 0): 1, (22, 1): 1, (22, 3): 1, (22, 5): 1, (23, 0): 1, (24, 3): 1, (25, 0): 1, (25, 4): 1, (26, 5): 1, (27, 2): 1, (27, 5): 1})\n",
      "56\n",
      "SAMPLE NR: 1\n",
      "node_counter_dec[0]=Counter({(7, 2): 3, (12, 5): 3, (23, 4): 3, (1, 0): 2, (2, 2): 2, (3, 4): 2, (4, 0): 2, (4, 1): 2, (8, 2): 2, (11, 3): 2, (12, 3): 2, (13, 4): 2, (13, 5): 2, (14, 1): 2, (17, 4): 2, (25, 1): 2, (25, 5): 2, (26, 5): 2, (0, 0): 1, (0, 1): 1, (1, 2): 1, (2, 4): 1, (2, 5): 1, (3, 2): 1, (4, 4): 1, (4, 5): 1, (5, 0): 1, (6, 3): 1, (7, 3): 1, (7, 5): 1, (8, 0): 1, (8, 1): 1, (8, 3): 1, (10, 2): 1, (10, 3): 1, (12, 0): 1, (12, 1): 1, (19, 0): 1, (19, 5): 1, (20, 0): 1, (20, 2): 1, (20, 5): 1, (22, 0): 1, (22, 3): 1, (24, 0): 1, (24, 1): 1})\n",
      "67\n",
      "SAMPLE NR: 2\n",
      "node_counter_dec[0]=Counter({(4, 2): 3, (23, 2): 3, (11, 3): 2, (15, 2): 2, (17, 5): 2, (23, 3): 2, (23, 5): 2, (0, 2): 1, (0, 3): 1, (0, 5): 1, (1, 0): 1, (1, 1): 1, (1, 5): 1, (2, 1): 1, (3, 4): 1, (3, 5): 1, (4, 0): 1, (4, 3): 1, (4, 4): 1, (4, 5): 1, (5, 0): 1, (5, 3): 1, (6, 2): 1, (6, 5): 1, (7, 2): 1, (7, 5): 1, (8, 0): 1, (8, 2): 1, (8, 3): 1, (9, 2): 1, (9, 3): 1, (9, 5): 1, (11, 4): 1, (12, 4): 1, (12, 5): 1, (13, 0): 1, (13, 4): 1, (14, 1): 1, (14, 2): 1, (16, 1): 1, (16, 3): 1, (17, 1): 1, (17, 2): 1, (18, 0): 1, (19, 2): 1, (20, 3): 1, (24, 5): 1, (25, 5): 1, (26, 0): 1, (26, 2): 1, (27, 5): 1})\n",
      "60\n",
      "SAMPLE NR: 3\n",
      "node_counter_dec[0]=Counter({(16, 4): 3, (22, 2): 3, (4, 3): 2, (5, 0): 2, (9, 1): 2, (13, 0): 2, (25, 5): 2, (27, 2): 2, (27, 3): 2, (0, 4): 1, (0, 5): 1, (1, 1): 1, (1, 2): 1, (1, 4): 1, (2, 5): 1, (3, 0): 1, (3, 4): 1, (5, 1): 1, (5, 3): 1, (5, 5): 1, (6, 0): 1, (6, 1): 1, (6, 2): 1, (6, 5): 1, (7, 0): 1, (7, 1): 1, (7, 2): 1, (7, 3): 1, (7, 4): 1, (8, 0): 1, (8, 2): 1, (8, 5): 1, (9, 4): 1, (10, 1): 1, (10, 3): 1, (10, 4): 1, (11, 2): 1, (11, 4): 1, (12, 4): 1, (13, 1): 1, (13, 2): 1, (14, 0): 1, (15, 3): 1, (15, 5): 1, (17, 0): 1, (17, 5): 1, (18, 3): 1, (19, 3): 1, (19, 5): 1, (20, 0): 1, (20, 1): 1, (20, 2): 1, (20, 4): 1, (21, 3): 1, (21, 5): 1, (22, 4): 1, (23, 1): 1, (23, 3): 1, (23, 4): 1, (24, 0): 1, (24, 1): 1, (24, 4): 1, (25, 3): 1, (26, 3): 1})\n",
      "75\n",
      "SAMPLE NR: 4\n",
      "node_counter_dec[0]=Counter({(7, 5): 2, (8, 3): 2, (9, 0): 2, (11, 3): 2, (13, 4): 2, (19, 5): 2, (26, 5): 2, (1, 2): 1, (1, 4): 1, (2, 1): 1, (3, 1): 1, (3, 4): 1, (4, 1): 1, (4, 2): 1, (4, 3): 1, (5, 0): 1, (6, 2): 1, (7, 1): 1, (7, 3): 1, (9, 1): 1, (10, 5): 1, (11, 0): 1, (11, 1): 1, (12, 4): 1, (13, 1): 1, (14, 1): 1, (17, 1): 1, (17, 2): 1, (17, 5): 1, (18, 1): 1, (18, 2): 1, (22, 1): 1, (22, 5): 1, (23, 4): 1, (24, 5): 1, (26, 0): 1, (26, 3): 1, (27, 0): 1, (27, 3): 1})\n",
      "46\n",
      "SAMPLE NR: 5\n",
      "node_counter_dec[0]=Counter({(25, 1): 3, (5, 5): 2, (8, 1): 2, (10, 1): 2, (14, 4): 2, (16, 3): 2, (18, 5): 2, (19, 0): 2, (22, 0): 2, (23, 2): 2, (24, 0): 2, (26, 2): 2, (0, 0): 1, (0, 4): 1, (1, 5): 1, (2, 3): 1, (2, 5): 1, (3, 2): 1, (4, 0): 1, (4, 3): 1, (4, 4): 1, (7, 1): 1, (7, 2): 1, (7, 3): 1, (7, 4): 1, (8, 0): 1, (8, 3): 1, (8, 5): 1, (9, 2): 1, (9, 3): 1, (9, 5): 1, (11, 2): 1, (11, 3): 1, (11, 4): 1, (12, 2): 1, (12, 3): 1, (12, 5): 1, (14, 2): 1, (15, 4): 1, (16, 1): 1, (16, 4): 1, (18, 3): 1, (19, 1): 1, (19, 2): 1, (19, 4): 1, (22, 2): 1, (22, 4): 1, (23, 3): 1, (23, 5): 1, (24, 1): 1, (24, 2): 1, (25, 0): 1, (25, 5): 1})\n",
      "66\n",
      "SAMPLE NR: 6\n",
      "node_counter_dec[0]=Counter({(3, 2): 3, (0, 4): 2, (2, 2): 2, (4, 3): 2, (14, 2): 2, (14, 5): 2, (20, 2): 2, (20, 4): 2, (22, 3): 2, (22, 4): 2, (23, 3): 2, (23, 4): 2, (24, 1): 2, (27, 5): 2, (1, 2): 1, (1, 4): 1, (2, 0): 1, (2, 5): 1, (3, 0): 1, (4, 0): 1, (4, 2): 1, (5, 5): 1, (6, 3): 1, (7, 3): 1, (7, 4): 1, (7, 5): 1, (8, 0): 1, (8, 1): 1, (8, 3): 1, (8, 5): 1, (9, 1): 1, (9, 3): 1, (10, 1): 1, (11, 4): 1, (12, 0): 1, (12, 2): 1, (12, 4): 1, (13, 1): 1, (14, 1): 1, (18, 1): 1, (18, 2): 1, (18, 3): 1, (18, 4): 1, (19, 2): 1, (19, 4): 1, (20, 1): 1, (21, 1): 1, (21, 5): 1, (22, 0): 1, (24, 4): 1, (25, 0): 1, (26, 0): 1})\n",
      "67\n",
      "SAMPLE NR: 7\n",
      "node_counter_dec[0]=Counter({(11, 1): 3, (3, 4): 2, (4, 3): 2, (5, 4): 2, (7, 0): 2, (12, 5): 2, (16, 1): 2, (17, 1): 2, (17, 2): 2, (18, 4): 2, (20, 0): 2, (25, 0): 2, (26, 1): 2, (26, 5): 2, (0, 0): 1, (0, 3): 1, (0, 4): 1, (1, 2): 1, (1, 4): 1, (1, 5): 1, (2, 0): 1, (3, 1): 1, (3, 2): 1, (4, 4): 1, (6, 2): 1, (7, 1): 1, (8, 0): 1, (9, 0): 1, (9, 2): 1, (10, 1): 1, (10, 5): 1, (11, 0): 1, (11, 2): 1, (12, 2): 1, (14, 1): 1, (15, 3): 1, (15, 5): 1, (19, 4): 1, (20, 1): 1, (21, 3): 1, (22, 0): 1, (22, 4): 1, (23, 2): 1, (24, 2): 1, (24, 5): 1, (25, 2): 1, (27, 2): 1, (27, 4): 1, (27, 5): 1})\n",
      "64\n",
      "SAMPLE NR: 8\n",
      "node_counter_dec[0]=Counter({(21, 3): 3, (0, 0): 2, (2, 1): 2, (9, 2): 2, (13, 1): 2, (16, 1): 2, (16, 5): 2, (23, 3): 2, (0, 4): 1, (1, 3): 1, (4, 5): 1, (6, 3): 1, (7, 2): 1, (11, 0): 1, (11, 1): 1, (13, 0): 1, (14, 2): 1, (14, 4): 1, (14, 5): 1, (15, 3): 1, (17, 2): 1, (17, 3): 1, (18, 2): 1, (19, 1): 1, (19, 3): 1, (19, 5): 1, (20, 1): 1, (20, 2): 1, (21, 5): 1, (22, 2): 1, (22, 3): 1, (23, 0): 1, (23, 4): 1, (24, 2): 1, (25, 1): 1, (25, 2): 1, (25, 4): 1, (26, 0): 1, (27, 0): 1})\n",
      "48\n",
      "SAMPLE NR: 9\n",
      "node_counter_dec[0]=Counter({(2, 5): 3, (27, 0): 3, (1, 2): 2, (3, 1): 2, (4, 2): 2, (6, 3): 2, (14, 0): 2, (14, 3): 2, (15, 0): 2, (16, 3): 2, (18, 1): 2, (21, 3): 2, (0, 1): 1, (0, 5): 1, (1, 3): 1, (2, 0): 1, (3, 3): 1, (3, 5): 1, (4, 1): 1, (5, 4): 1, (6, 2): 1, (6, 4): 1, (7, 0): 1, (7, 4): 1, (9, 2): 1, (9, 5): 1, (11, 1): 1, (11, 2): 1, (11, 4): 1, (13, 0): 1, (13, 3): 1, (13, 5): 1, (15, 3): 1, (16, 1): 1, (16, 4): 1, (17, 0): 1, (18, 3): 1, (19, 2): 1, (19, 5): 1, (21, 0): 1, (21, 5): 1, (22, 1): 1, (22, 4): 1, (24, 0): 1, (24, 2): 1, (24, 4): 1, (25, 3): 1, (25, 4): 1, (26, 3): 1, (27, 2): 1, (27, 3): 1, (27, 4): 1})\n",
      "66\n",
      "----RANDOM-----\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Tensor for argument #1 'mat1' is on CPU, but expected it to be on GPU (while checking arguments for mm)",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mRuntimeError\u001B[39m                              Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[3]\u001B[39m\u001B[32m, line 21\u001B[39m\n\u001B[32m     18\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorchhd\u001B[39;00m\n\u001B[32m     20\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33m----RANDOM-----\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m---> \u001B[39m\u001B[32m21\u001B[39m random_counter = \u001B[43mencoder\u001B[49m\u001B[43m.\u001B[49m\u001B[43mdecode_order_zero_counter\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtorchhd\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrandom\u001B[49m\u001B[43m(\u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m6400\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvsa\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mHRR\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m[\u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     22\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mrandom_counter[\u001B[32m0\u001B[39m]\u001B[38;5;132;01m=}\u001B[39;00m\u001B[33m\"\u001B[39m)\n\u001B[32m     23\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mrandom_counter[\u001B[32m0\u001B[39m].total()\u001B[38;5;132;01m=}\u001B[39;00m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/kit/graph_hdc/src/encoding/graph_encoders.py:566\u001B[39m, in \u001B[36mHyperNet.decode_order_zero_counter\u001B[39m\u001B[34m(self, embedding)\u001B[39m\n\u001B[32m    565\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mdecode_order_zero_counter\u001B[39m(\u001B[38;5;28mself\u001B[39m, embedding: torch.Tensor) -> \u001B[38;5;28mdict\u001B[39m[\u001B[38;5;28mint\u001B[39m, Counter]:\n\u001B[32m--> \u001B[39m\u001B[32m566\u001B[39m     dot_products_rounded = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mdecode_order_zero\u001B[49m\u001B[43m(\u001B[49m\u001B[43membedding\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    568\u001B[39m     \u001B[38;5;66;03m# Counts (feature1, feature2, ...) : #Occurrences\u001B[39;00m\n\u001B[32m    569\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.convert_to_counter(similarities=dot_products_rounded, indexer=\u001B[38;5;28mself\u001B[39m.nodes_indexer)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/kit/graph_hdc/src/encoding/graph_encoders.py:554\u001B[39m, in \u001B[36mHyperNet.decode_order_zero\u001B[39m\u001B[34m(self, embedding)\u001B[39m\n\u001B[32m    551\u001B[39m \u001B[38;5;28mself\u001B[39m._populate_nodes_indexer()\n\u001B[32m    553\u001B[39m \u001B[38;5;66;03m# Compute the dot product between the embedding and each node hypervector representation.\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m554\u001B[39m d = \u001B[43mtorchhd\u001B[49m\u001B[43m.\u001B[49m\u001B[43mdot\u001B[49m\u001B[43m(\u001B[49m\u001B[43membedding\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mnodes_codebook\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    555\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.vsa \u001B[38;5;129;01min\u001B[39;00m {VSAModel.FHRR, VSAModel.MAP}:\n\u001B[32m    556\u001B[39m     \u001B[38;5;66;03m# For FHRR and MAP VSA models, the dot product scales with the dimensionality.\u001B[39;00m\n\u001B[32m    557\u001B[39m     \u001B[38;5;66;03m# Normalize by dividing by the hypervector dimension to approximate the original counts.\u001B[39;00m\n\u001B[32m    558\u001B[39m     d = d / \u001B[38;5;28mself\u001B[39m.hv_dim\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/kit/graph_hdc/.pixi/envs/default/lib/python3.13/site-packages/torchhd/functional.py:989\u001B[39m, in \u001B[36mdot_similarity\u001B[39m\u001B[34m(input, others, **kwargs)\u001B[39m\n\u001B[32m    987\u001B[39m \u001B[38;5;28minput\u001B[39m = ensure_vsa_tensor(\u001B[38;5;28minput\u001B[39m)\n\u001B[32m    988\u001B[39m others = ensure_vsa_tensor(others)\n\u001B[32m--> \u001B[39m\u001B[32m989\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43minput\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mdot_similarity\u001B[49m\u001B[43m(\u001B[49m\u001B[43mothers\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/kit/graph_hdc/.pixi/envs/default/lib/python3.13/site-packages/torchhd/tensors/hrr.py:392\u001B[39m, in \u001B[36mHRRTensor.dot_similarity\u001B[39m\u001B[34m(self, others)\u001B[39m\n\u001B[32m    389\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m others.dim() >= \u001B[32m2\u001B[39m:\n\u001B[32m    390\u001B[39m     others = others.transpose(-\u001B[32m2\u001B[39m, -\u001B[32m1\u001B[39m)\n\u001B[32m--> \u001B[39m\u001B[32m392\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43mmatmul\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mothers\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/kit/graph_hdc/.pixi/envs/default/lib/python3.13/site-packages/torch/_tensor.py:1648\u001B[39m, in \u001B[36mTensor.__torch_function__\u001B[39m\u001B[34m(cls, func, types, args, kwargs)\u001B[39m\n\u001B[32m   1645\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mNotImplemented\u001B[39m\n\u001B[32m   1647\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m _C.DisableTorchFunctionSubclass():\n\u001B[32m-> \u001B[39m\u001B[32m1648\u001B[39m     ret = \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1649\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m func \u001B[38;5;129;01min\u001B[39;00m get_default_nowrap_functions():\n\u001B[32m   1650\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m ret\n",
      "\u001B[31mRuntimeError\u001B[39m: Tensor for argument #1 'mat1' is on CPU, but expected it to be on GPU (while checking arguments for mm)"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-14T13:33:30.832912Z",
     "start_time": "2025-07-14T13:33:30.348683Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "print(\"---DATA---\")\n",
    "counter = 1\n",
    "for b in train_dataloader:\n",
    "    print(f\"DATA NR: {counter}\")\n",
    "    counter += 1\n",
    "    # s_decoded = pca_decode(b, pca)\n",
    "    z = b.view(16, 3, hv_dim)\n",
    "    node_terms_s, edge_terms_s, graph_embeddings_s = z.unbind(dim=1)\n",
    "    node_terms_s_hrr = node_terms_s.as_subclass(HRRTensor)\n",
    "    for i in range(4):\n",
    "        encoder.to(node_terms_s_hrr.device)\n",
    "        node_counter_dec = encoder.decode_order_zero_counter(node_terms_s_hrr[i])\n",
    "        print(f\"{node_counter_dec[0]=}\")\n",
    "        print(f\"{node_counter_dec[0].total()}\")\n"
   ],
   "id": "afec1a13f41449b5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---DATA---\n",
      "DATA NR: 1\n",
      "node_counter_dec[0]=Counter({(0, 2): 13, (0, 3): 6, (1, 1): 3, (2, 3): 3, (0, 1): 2, (1, 2): 1, (5, 4): 1})\n",
      "29\n",
      "node_counter_dec[0]=Counter({(0, 2): 13, (0, 3): 6, (1, 1): 3, (2, 3): 3, (0, 1): 2, (1, 2): 1, (5, 4): 1})\n",
      "29\n",
      "node_counter_dec[0]=Counter({(0, 2): 13, (0, 3): 6, (1, 1): 3, (2, 3): 3, (0, 1): 2, (1, 2): 1, (5, 4): 1})\n",
      "29\n",
      "node_counter_dec[0]=Counter({(0, 2): 13, (0, 3): 6, (1, 1): 3, (2, 3): 3, (0, 1): 2, (1, 2): 1, (5, 4): 1})\n",
      "29\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model_loaded = RealNVPLightning.load_from_checkpoint(\n",
    "    \"/Users/arvandkaveh/Projects/kit/graph_hdc/notebooks/NormFlows/results/real_nvp/2025-07-12_10-33-51_wews/models/epochepoch=229-valval_loss=-14874.93.ckpt\")\n"
   ],
   "id": "41bbb34bfdba0c4c",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
