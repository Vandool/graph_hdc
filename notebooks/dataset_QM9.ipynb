{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T10:56:15.890397Z",
     "start_time": "2025-07-08T10:55:39.629251Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from src.utils.utils import DATASET_TEST_PATH\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.datasets import QM9\n",
    "\n",
    "\n",
    "dataset = QM9(root=DATASET_TEST_PATH,)\n",
    "loader =DataLoader(dataset, batch_size=3, shuffle=False)\n",
    "n = 1\n",
    "for batch in loader:\n",
    "    if n > 0:\n",
    "        n -= 1\n",
    "    else:\n",
    "        break\n",
    "    # batch.x: [N_total, num_features]\n",
    "    # batch.batch: [N_total] where batch[i]=g means node i belongs to graph g (0 ≤ g < batch_size)\n",
    "    print(batch.x.shape, batch.batch.shape)\n",
    "    # e.g. torch.Size([35, 11]) torch.Size([35])\n",
    "print(len(dataset))\n",
    "print(dataset[0])\n",
    "d = dataset[0]\n",
    "d2 = dataset[4]\n"
   ],
   "id": "a99103d22f130415",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://data.pyg.org/datasets/qm9_v3.zip\n",
      "Extracting /Users/arvandkaveh/Projects/kit/graph_hdc/src/artifacts/datasets/raw/qm9_v3.zip\n",
      "Processing...\n",
      "Using a pre-processed version of the dataset. Please install 'rdkit' to alternatively process the raw data.\n",
      "Done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12, 11]) torch.Size([12])\n",
      "130831\n",
      "Data(x=[5, 11], edge_index=[2, 8], edge_attr=[8, 4], y=[1, 19], pos=[5, 3], idx=[1], name='gdb_1', z=[5])\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T10:56:42.675667Z",
     "start_time": "2025-07-08T10:56:16.029536Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Utility to gather unique values per feature index\n",
    "def gather_unique_values(dataset, attr_name, feature_dim):\n",
    "    uniques = defaultdict(set)\n",
    "    for data in dataset:\n",
    "        feat = getattr(data, attr_name)\n",
    "        # Handle 1D or 2D feature arrays\n",
    "        if feat is None:\n",
    "            continue\n",
    "        feat = feat.detach()\n",
    "        if feat.dim() == 2:\n",
    "            for i in range(feat.size(1)):\n",
    "                uniques[i].update(feat[:, i].unique().tolist())\n",
    "        elif feat.dim() == 1 and feature_dim is None:\n",
    "            uniques[0].update(feat.unique().tolist())\n",
    "        else:\n",
    "            # treat entire tensor as one feature (e.g., for y)\n",
    "            uniques[0].update(feat.view(-1).unique().tolist())\n",
    "    return uniques\n",
    "\n",
    "# Node features: data.x has shape [total_nodes, 11]\n",
    "node_uniques = gather_unique_values(dataset, 'x', feature_dim=dataset.num_node_features)\n",
    "print(\"Node feature categories per index:\")\n",
    "for idx, vals in sorted(node_uniques.items()):\n",
    "    print(f\"  - Feature {idx}: {len(vals)} distinct values → {sorted(vals)}\")\n",
    "\n",
    "# Edge features: data.edge_attr has shape [total_edges, 4]\n",
    "edge_uniques = gather_unique_values(dataset, 'edge_attr', feature_dim=dataset.num_edge_features)\n",
    "print(\"\\nEdge feature categories per index:\")\n",
    "for idx, vals in sorted(edge_uniques.items()):\n",
    "    print(f\"  - Feature {idx}: {len(vals)} distinct values → {sorted(vals)}\")\n",
    "\n",
    "# Graph‐level targets: data.y has shape [1, 19]\n",
    "# Here we treat each of the 19 targets as one \"feature column\":\n",
    "graph_uniques = defaultdict(set)\n",
    "for data in dataset:\n",
    "    y = data.y.squeeze()  # shape [19]\n",
    "    for i, val in enumerate(y.tolist()):\n",
    "        graph_uniques[i].add(val)\n",
    "print(\"\\nGraph‐level target categories per index:\")\n",
    "for idx, vals in sorted(graph_uniques.items()):\n",
    "    print(f\"  - Target {idx}: {len(vals)} distinct values\")  # continuous, so this will be size = num_graphs\n",
    "\n",
    "# Additionally, checking atomic numbers (data.z) and hybridization categories:\n",
    "z_uniques = gather_unique_values(dataset, 'z', feature_dim=None)\n",
    "print(\"\\nAtomic number categories:\", sorted(z_uniques[0]))"
   ],
   "id": "ee0d16b275b79995",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node feature categories per index:\n",
      "  - Feature 0: 2 distinct values → [0.0, 1.0]\n",
      "  - Feature 1: 2 distinct values → [0.0, 1.0]\n",
      "  - Feature 2: 2 distinct values → [0.0, 1.0]\n",
      "  - Feature 3: 2 distinct values → [0.0, 1.0]\n",
      "  - Feature 4: 2 distinct values → [0.0, 1.0]\n",
      "  - Feature 5: 5 distinct values → [1.0, 6.0, 7.0, 8.0, 9.0]\n",
      "  - Feature 6: 1 distinct values → [0.0]\n",
      "  - Feature 7: 1 distinct values → [0.0]\n",
      "  - Feature 8: 1 distinct values → [0.0]\n",
      "  - Feature 9: 1 distinct values → [0.0]\n",
      "  - Feature 10: 5 distinct values → [0.0, 1.0, 2.0, 3.0, 4.0]\n",
      "\n",
      "Edge feature categories per index:\n",
      "  - Feature 0: 2 distinct values → [0.0, 1.0]\n",
      "  - Feature 1: 2 distinct values → [0.0, 1.0]\n",
      "  - Feature 2: 2 distinct values → [0.0, 1.0]\n",
      "  - Feature 3: 1 distinct values → [0.0]\n",
      "\n",
      "Graph‐level target categories per index:\n",
      "  - Target 0: 49556 distinct values\n",
      "  - Target 1: 5431 distinct values\n",
      "  - Target 2: 1815 distinct values\n",
      "  - Target 3: 2415 distinct values\n",
      "  - Target 4: 2658 distinct values\n",
      "  - Target 5: 129432 distinct values\n",
      "  - Target 6: 72452 distinct values\n",
      "  - Target 7: 96986 distinct values\n",
      "  - Target 8: 97269 distinct values\n",
      "  - Target 9: 97221 distinct values\n",
      "  - Target 10: 97075 distinct values\n",
      "  - Target 11: 20072 distinct values\n",
      "  - Target 12: 124295 distinct values\n",
      "  - Target 13: 124623 distinct values\n",
      "  - Target 14: 124581 distinct values\n",
      "  - Target 15: 123825 distinct values\n",
      "  - Target 16: 106851 distinct values\n",
      "  - Target 17: 87890 distinct values\n",
      "  - Target 18: 76155 distinct values\n",
      "\n",
      "Atomic number categories: [1, 6, 7, 8, 9]\n"
     ]
    }
   ],
   "execution_count": 2
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
