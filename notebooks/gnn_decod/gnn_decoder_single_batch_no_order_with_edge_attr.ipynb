{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T13:50:20.726008Z",
     "start_time": "2025-07-08T13:50:17.357024Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "import math\n",
    "\n",
    "\"\"\"\n",
    "Conditional Graph Neural Network Implementation for Graph Link Prediction\n",
    "\n",
    "This module implements a conditional graph neural network architecture based on the message passing\n",
    "paradigm, specifically designed for graph link prediction tasks. The implementation uses PyTorch\n",
    "Geometric and PyTorch Lightning frameworks.\n",
    "\n",
    "The key components of this implementation are:\n",
    "\n",
    "1. FilmConditionalLinear: A conditional linear layer using Feature-wise Linear Modulation (FiLM)\n",
    "   that allows neural network behavior to be conditioned on external inputs.\n",
    "\n",
    "2. ConditionalGraphAttention: A graph attention layer that extends PyTorch Geometric's MessagePassing\n",
    "   class, incorporating attention mechanisms and conditional processing via FiLM.\n",
    "\n",
    "3. ConditionalGIN: A Graph Isomorphism Network that uses the conditional graph attention mechanism\n",
    "   for message passing and is trained to predict whether edges should exist in the graph.\n",
    "\n",
    "The module demonstrates how to:\n",
    "- Create conditional neural network layers with FiLM\n",
    "- Implement custom message passing mechanisms with attention\n",
    "- Apply graph neural networks to link prediction tasks\n",
    "- Generate and visualize mock graph data for testing\n",
    "\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import MessagePassing\n",
    "\n",
    "\n",
    "class FilmConditionalLinear(nn.Module):\n",
    "    \"\"\"\n",
    "    This is a conditional variant of the default ``Linear`` layer using the FiLM conditioning mechanism.\n",
    "\n",
    "    As a conditional layer, this layer requires 2 different input tensors. The first is the actual input\n",
    "    tensor to be transformed into the output tensor and the second is the condition vector that should\n",
    "    modify the behavior of the linear layer. The implementation follows the Feature-wise Linear Modulation\n",
    "    (FiLM) approach, which applies an affine transformation (scale and shift) to the output of a linear\n",
    "    layer based on the conditioning vector.\n",
    "\n",
    "    :param in_features: Number of input features\n",
    "    :param out_features: Number of output features\n",
    "    :param condition_features: Number of features in the conditioning vector\n",
    "    :param film_units: List of hidden unit sizes for the FiLM network\n",
    "    :param film_use_norm: Whether to use batch normalization in the FiLM network\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_features: int,\n",
    "                 out_features: int,\n",
    "                 condition_features: int,\n",
    "                 film_units: list[int] = [128, ],\n",
    "                 film_use_norm: bool = False,\n",
    "                 **kwargs,\n",
    "                 ):\n",
    "        \"\"\"\n",
    "        Initialize the FiLM conditional linear layer.\n",
    "\n",
    "        :param in_features: Number of input features\n",
    "        :param out_features: Number of output features\n",
    "        :param condition_features: Number of features in the conditioning vector\n",
    "        :param film_units: List of hidden unit sizes for the FiLM network\n",
    "        :param film_use_norm: Whether to use batch normalization in the FiLM network\n",
    "        :param kwargs: Additional keyword arguments to pass to the parent class\n",
    "        \"\"\"\n",
    "        nn.Module.__init__(self, **kwargs)\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.condition_features = condition_features\n",
    "        self.film_units = film_units\n",
    "        self.film_use_norm = film_use_norm\n",
    "        # The final activation we actually want to be Tanh because the output values should\n",
    "        # be in the range of [-1, 1], both for the bias as well as the multiplicative factor.\n",
    "        # TODO: Make this configurable.\n",
    "        self.lay_final_activation = nn.Tanh()\n",
    "\n",
    "        ## -- Main Linear Layer --\n",
    "        # Ultimately, the FiLM layer is just a variation of a linear layer where the output\n",
    "        # is additionally modified by the activation. So what we define here is the core\n",
    "        # linear layer itself.\n",
    "        self.lay_linear = nn.Linear(\n",
    "            in_features=in_features,\n",
    "            out_features=out_features,\n",
    "        )\n",
    "        self.dim = out_features\n",
    "\n",
    "        ## -- FiLM Layers --\n",
    "        # These are the layers that will be used to create the FiLM activation modifier tensors.\n",
    "        # They take as the input the condition vector and transform that into the additive and\n",
    "        # multiplicative modifiers which than perform the affine transformation on the output\n",
    "        # of the actual linear layer.\n",
    "        # This can even be a multi-layer perceptron by itself, depending on how difficult the\n",
    "        # condition function is to learn.\n",
    "        self.film_layers = nn.ModuleList()\n",
    "        prev_features = condition_features\n",
    "        for num_features in film_units:\n",
    "            if self.film_use_norm:\n",
    "                lay = nn.Sequential(\n",
    "                    nn.Linear(\n",
    "                        in_features=prev_features,\n",
    "                        out_features=num_features\n",
    "                    ),\n",
    "                    # CHANGED: BatchNorm1d -> LayerNorm\n",
    "                    # nn.BatchNorm1d(num_features),\n",
    "                    nn.LayerNorm(num_features),\n",
    "                    nn.ReLU(),\n",
    "                )\n",
    "            else:\n",
    "                lay = nn.Sequential(\n",
    "                    nn.Linear(\n",
    "                        in_features=prev_features,\n",
    "                        out_features=num_features\n",
    "                    ),\n",
    "                    nn.ReLU(),\n",
    "                )\n",
    "\n",
    "            self.film_layers.append(lay)\n",
    "            prev_features = num_features\n",
    "\n",
    "        # Finally, at the end of this MLP we need the final layer to be one that outputs a\n",
    "        # vector of the size that is twice the size of the output of the core linear layer.\n",
    "        # From this output we need to derive the additive and the multiplicative modifier\n",
    "        # and we do this by using the first half of the output as the multiplicative\n",
    "        # modifier and the second half as the additive modifier.\n",
    "        self.film_layers.append(nn.Linear(\n",
    "            in_features=prev_features,\n",
    "            out_features=self.dim * 2,\n",
    "        ))\n",
    "\n",
    "    def forward(self,\n",
    "                input: torch.Tensor,\n",
    "                condition: torch.Tensor\n",
    "                ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass of the FiLM conditional linear layer.\n",
    "\n",
    "        The forward method applies the core linear transformation to the input tensor,\n",
    "        then modifies the result based on the condition tensor through a FiLM (Feature-wise\n",
    "        Linear Modulation) mechanism, which performs an affine transformation with parameters\n",
    "        derived from the condition.\n",
    "\n",
    "        :param input: Input tensor of shape (batch_size, in_features)\n",
    "        :param condition: Condition tensor of shape (batch_size, condition_features)\n",
    "\n",
    "        :returns: Output tensor of shape (batch_size, out_features)\n",
    "        \"\"\"\n",
    "\n",
    "        ## -- getting the modifier from the condition --\n",
    "        # We need the film layers to create the activation modifier tensor.\n",
    "        # This actually may or may not be a multi layer perceptron.\n",
    "        modifier = condition\n",
    "        for lay in self.film_layers:\n",
    "            modifier = lay(modifier)\n",
    "\n",
    "        # Reduced the factor 2 -> 0.5\n",
    "        # The predictions jump from 0 to 1 and 1 to 0 within one single training loop, that indicates numerical instability\n",
    "        # and possibly high activation values\n",
    "        modifier = 0.5 * self.lay_final_activation(modifier)\n",
    "\n",
    "        # -- getting the output from the linear layer --\n",
    "        output = self.lay_linear(input)\n",
    "\n",
    "        # -- applying the modifier to the output --\n",
    "        # And then finally we split the modifier vector into the two equally sized distinct vectors where one of them\n",
    "        # is the multiplicative modification and the other is the additive modification to the output activation.\n",
    "        factor = modifier[:, :self.dim]\n",
    "        bias = modifier[:, self.dim:]\n",
    "        output = (factor * output) + bias\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "class ConditionalGraphAttention(MessagePassing):\n",
    "    \"\"\"\n",
    "    A conditional graph attention layer that extends PyTorch Geometric's MessagePassing base class.\n",
    "\n",
    "    This layer implements a message passing mechanism where attention coefficients are computed\n",
    "    for each edge based on the features of the connected nodes and edge attributes, modified by\n",
    "    a condition vector. The attention mechanism helps the network focus on the most relevant\n",
    "    parts of the graph structure for the given task and condition.\n",
    "\n",
    "    :param in_dim: Dimension of input node features\n",
    "    :param out_dim: Dimension of output node features\n",
    "    :param edge_dim: Dimension of edge features\n",
    "    :param cond_dim: Dimension of the condition vector\n",
    "    :param hidden_dim: Dimension of hidden layers\n",
    "    :param eps: Epsilon value for residual connections\n",
    "    :param film_units: List of hidden unit sizes for the FiLM networks\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_dim: int,\n",
    "                 out_dim: int,\n",
    "                 cond_dim: int,\n",
    "                 edge_dim: int = 0,\n",
    "                 hidden_dim: int = 64,\n",
    "                 eps: float = 0.1,\n",
    "                 film_units: list[int] = [],\n",
    "                 **kwargs):\n",
    "        \"\"\"\n",
    "        Initialize the conditional graph attention layer.\n",
    "\n",
    "        :param in_dim: Dimension of input node features\n",
    "        :param out_dim: Dimension of output node features\n",
    "        :param edge_dim: Dimension of edge features\n",
    "        :param cond_dim: Dimension of the condition vector\n",
    "        :param hidden_dim: Dimension of hidden layers\n",
    "        :param eps: Epsilon value for residual connections\n",
    "        :param film_units: List of hidden unit sizes for the FiLM networks\n",
    "        :param kwargs: Additional keyword arguments to pass to the parent class\n",
    "        \"\"\"\n",
    "        kwargs.setdefault('aggr', 'add')\n",
    "        MessagePassing.__init__(self, **kwargs)\n",
    "        self.in_dim = in_dim\n",
    "        self.out_dim = out_dim\n",
    "        self.edge_dim = edge_dim\n",
    "        self.cond_dim = cond_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.eps = eps\n",
    "        self.film_units = film_units\n",
    "\n",
    "        self._attention_logits = None\n",
    "        self._attention = None\n",
    "\n",
    "        ## -- Initial Embedding Layer --\n",
    "        self.message_dim = (in_dim * 2 + edge_dim)\n",
    "        self.lay_message_lin_1 = FilmConditionalLinear(\n",
    "            in_features=self.message_dim,\n",
    "            out_features=self.hidden_dim,\n",
    "            condition_features=self.cond_dim,\n",
    "            film_units=self.film_units,\n",
    "        )\n",
    "        # CHANGE: replaced BatchNorm1d with LayerNorm\n",
    "        self.lay_message_bn = nn.LayerNorm(self.hidden_dim)\n",
    "        self.lay_message_act = nn.LeakyReLU()\n",
    "        self.lay_message_lin_2 = FilmConditionalLinear(\n",
    "            in_features=self.hidden_dim,\n",
    "            out_features=self.hidden_dim,\n",
    "            condition_features=self.cond_dim,\n",
    "            film_units=self.film_units,\n",
    "        )\n",
    "\n",
    "        # -- Attention Layer --\n",
    "        # This layer will produce the attention coefficients which will then be used in the\n",
    "        # attention-weighted message accumulation step.\n",
    "        self.lay_attention_lin_1 = FilmConditionalLinear(\n",
    "            in_features=self.message_dim,\n",
    "            out_features=self.hidden_dim,\n",
    "            condition_features=self.cond_dim,\n",
    "            film_units=self.film_units,\n",
    "        )\n",
    "        # CHANGE: replaced BatchNorm1d with LayerNorm\n",
    "        self.lay_attention_bn = nn.LayerNorm(self.hidden_dim)\n",
    "        self.lay_attention_act = nn.LeakyReLU()\n",
    "        self.lay_attention_lin_2 = FilmConditionalLinear(\n",
    "            in_features=self.hidden_dim,\n",
    "            out_features=1,  # attention logits\n",
    "            condition_features=self.cond_dim,\n",
    "            film_units=self.film_units,\n",
    "        )\n",
    "\n",
    "        # -- Final Transform Layer --\n",
    "        # In the end we add an additional transformation on the attention weighted aggregation\n",
    "        # of the message to determine the update to the node features.\n",
    "        self.lay_transform_lin_1 = FilmConditionalLinear(\n",
    "            in_features=self.hidden_dim + self.in_dim,\n",
    "            out_features=self.hidden_dim,\n",
    "            condition_features=self.cond_dim,\n",
    "            film_units=self.film_units,\n",
    "        )\n",
    "        self.lay_transform_bn = nn.BatchNorm1d(self.hidden_dim)\n",
    "        self.lay_transform_act = nn.LeakyReLU()\n",
    "        self.lay_transform_lin_2 = FilmConditionalLinear(\n",
    "            in_features=self.hidden_dim,\n",
    "            out_features=self.out_dim,\n",
    "            condition_features=self.cond_dim,\n",
    "            film_units=self.film_units,\n",
    "        )\n",
    "\n",
    "    def message(self,\n",
    "                x_i, x_j,\n",
    "                condition_i, condition_j,\n",
    "                edge_attr,\n",
    "                edge_weights,\n",
    "                ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Compute the message for each edge in the message passing step.\n",
    "\n",
    "        This method is called for each edge during the propagation step of message passing.\n",
    "        It computes attention coefficients based on the features of connected nodes and the edge,\n",
    "        then uses these coefficients to weight the message being passed.\n",
    "\n",
    "        :param x_i: Features of the target node\n",
    "        :param x_j: Features of the source node\n",
    "        :param condition_i: Condition vector for the target node\n",
    "        :param condition_j: Condition vector for the source node\n",
    "        :param edge_attr: Edge attributes\n",
    "        :param edge_weights: Optional edge weights to further modulate the messages\n",
    "\n",
    "        :returns: The weighted message to be passed along the edge\n",
    "        \"\"\"\n",
    "\n",
    "        # message = torch.cat([x_i, x_j, edge_attr], dim=-1)\n",
    "        feats = [x_i, x_j]\n",
    "        if edge_attr is not None:\n",
    "            feats.append(edge_attr)\n",
    "        message = torch.cat(feats, dim=-1)\n",
    "\n",
    "        attention_logits = self.lay_attention_lin_1(message, condition_i)\n",
    "        attention_logits = self.lay_attention_bn(attention_logits)\n",
    "        attention_logits = self.lay_attention_act(attention_logits)\n",
    "        attention_logits = self.lay_attention_lin_2(attention_logits, condition_i)\n",
    "        self._attention_logits = attention_logits\n",
    "        self._attention = F.sigmoid(self._attention_logits)\n",
    "\n",
    "        message_transformed = self.lay_message_lin_1(message, condition_i)\n",
    "        message_transformed = self.lay_message_bn(message_transformed)\n",
    "        message_transformed = self.lay_message_act(message_transformed)\n",
    "        message_transformed = self.lay_message_lin_2(message_transformed, condition_i)\n",
    "\n",
    "        result = self._attention * message_transformed\n",
    "\n",
    "        if edge_weights is not None:\n",
    "            if edge_weights.dim() == 1:\n",
    "                edge_weights = torch.unsqueeze(edge_weights, dim=-1)\n",
    "\n",
    "            result *= edge_weights\n",
    "\n",
    "        return result\n",
    "\n",
    "    def forward(self,\n",
    "                x: torch.Tensor,\n",
    "                condition: torch.Tensor,\n",
    "                edge_index: torch.Tensor,\n",
    "                edge_attr: torch.Tensor | None = None,\n",
    "                edge_weights: torch.Tensor = None,\n",
    "                **kwargs) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Forward pass of the conditional graph attention layer.\n",
    "\n",
    "        This method implements the full message passing operation, including propagation of messages\n",
    "        along edges and aggregation of these messages at each node. The final node embeddings are\n",
    "        computed by transforming the aggregated messages together with the original node features.\n",
    "\n",
    "        :param x: Input node features\n",
    "        :param condition: Condition vector for all nodes\n",
    "        :param edge_attr: Edge attributes\n",
    "        :param edge_index: Graph connectivity\n",
    "        :param edge_weights: Optional edge weights\n",
    "        :param kwargs: Additional keyword arguments\n",
    "\n",
    "        :returns: A tuple containing the updated node embeddings and attention logits\n",
    "        \"\"\"\n",
    "\n",
    "        self._attention = None\n",
    "        self._attention_logits = None\n",
    "\n",
    "        # node_embedding: (B * V, out)\n",
    "        node_embedding = self.propagate(\n",
    "            edge_index,\n",
    "            x=x,\n",
    "            condition=condition,\n",
    "            edge_attr=edge_attr,\n",
    "            # edge_weights=edge_weights,\n",
    "        )\n",
    "\n",
    "        # node_embedding = self.lay_act(node_embedding)\n",
    "        x = self.lay_transform_lin_1(\n",
    "            torch.cat([node_embedding, x], axis=1),\n",
    "            condition\n",
    "        )\n",
    "        x = self.lay_transform_bn(x)\n",
    "        x = self.lay_transform_act(x)\n",
    "        x = self.lay_transform_lin_2(x, condition)\n",
    "\n",
    "        # Residual connection to make the gradient flow more stable.\n",
    "        #node_embedding += self.eps * x\n",
    "        node_embedding = x\n",
    "\n",
    "        return node_embedding, self._attention_logits\n",
    "\n",
    "\n",
    "class ConditionalGIN(pl.LightningModule):\n",
    "    \"\"\"\n",
    "    A conditional Graph Isomorphism Network (GIN) implemented using PyTorch Lightning.\n",
    "\n",
    "    This model performs message passing on graph structured data conditioned on an external\n",
    "    vector. It uses the conditional graph attention mechanism to propagate information through\n",
    "    the graph. The model is designed for link prediction tasks, predicting whether edges should\n",
    "    exist in the graph based on the learned node representations and the condition vector.\n",
    "\n",
    "    :param input_dim: Dimension of input node features\n",
    "    :param edge_dim: Dimension of edge features\n",
    "    :param condition_dim: Dimension of the condition vector\n",
    "    :param cond_units: List of hidden unit sizes for the condition embedding network\n",
    "    :param conv_units: List of hidden unit sizes for the graph convolution layers\n",
    "    :param film_units: List of hidden unit sizes for the FiLM networks in the graph attention layers\n",
    "    :param link_units: List of hidden unit sizes for the link prediction network\n",
    "    :param learning_rate: Learning rate for the optimizer\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 input_dim: int,\n",
    "                 condition_dim: int,\n",
    "                 edge_dim: int = 0,\n",
    "                 cond_units: list[int] = [256, 128],\n",
    "                 conv_units: list[int] = [64, 64, 64],\n",
    "                 film_units: list[int] = [128, ],\n",
    "                 link_units: list[int] = [256, 64, 1],\n",
    "                 learning_rate: float = 0.0001,\n",
    "                 max_nodes_per_graph: int = 37,   # CHANGE: pass in your max nodes\n",
    "                 node_id_emb_dim: int = 32,       # CHANGE: separate dim constant\n",
    "                 edge_emb_dim: int = 16,\n",
    "                 ):\n",
    "        \"\"\"\n",
    "        Initialize the conditional GIN model.\n",
    "\n",
    "        :param input_dim: Dimension of input node features\n",
    "        :param edge_dim: Dimension of edge features\n",
    "        :param condition_dim: Dimension of the condition vector\n",
    "        :param cond_units: List of hidden unit sizes for the condition embedding network\n",
    "        :param conv_units: List of hidden unit sizes for the graph convolution layers\n",
    "        :param film_units: List of hidden unit sizes for the FiLM networks in the graph attention layers\n",
    "        :param link_units: List of hidden unit sizes for the link prediction network\n",
    "        :param learning_rate: Learning rate for the optimizer\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        # ─── CHANGE: add per-node categorical embeddings ───────────────────────\n",
    "        self.atom_emb   = nn.Embedding(num_embeddings=28, embedding_dim=64)    # CHANGE\n",
    "        self.degree_emb = nn.Embedding(num_embeddings=6,  embedding_dim=16)     # CHANGE\n",
    "        # self.node_id_emb = nn.Embedding(num_embeddings=max_nodes_per_graph,  embedding_dim=node_id_emb_dim)     # CHANGE\n",
    "        self.input_proj = nn.Linear(64 + 16\n",
    "                                    # + node_id_emb_dim\n",
    "                                    , input_dim)                  # CHANGE\n",
    "        # ──────────────────────────────────────────────────────────────────────\n",
    "        self.edge_emb = nn.Embedding(num_embeddings=3, embedding_dim=edge_emb_dim)\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.condition_dim = condition_dim\n",
    "        self.conv_units = conv_units\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        ## == LAYER DEFINITIONS ==\n",
    "\n",
    "        ## -- Condition Layers --\n",
    "\n",
    "        # These will be the layers (the mlp) which will be used to create an overall lower-dimensional\n",
    "        # embedding representation of the (very high-dimensional) condition vector. It is then this\n",
    "        # embedding that will be used in the individual FiLM conditioning layers.\n",
    "        self.cond_layers = nn.ModuleList()\n",
    "        prev_units = condition_dim\n",
    "        for units in cond_units:\n",
    "            self.cond_layers.append(\n",
    "                nn.Linear(prev_units, units),\n",
    "            )\n",
    "            prev_units = units\n",
    "\n",
    "        self.cond_embedding_dim = prev_units\n",
    "\n",
    "        ## -- Graph Convolutional Layers --\n",
    "\n",
    "        # These will be the actual convolutional layers that will be used as the message passing\n",
    "        # operations on the given graph.\n",
    "        self.conv_layers = nn.ModuleList()\n",
    "        prev_units = input_dim\n",
    "        for units in conv_units:\n",
    "            lay = ConditionalGraphAttention(\n",
    "                in_dim=prev_units,\n",
    "                out_dim=units,\n",
    "                edge_dim=edge_emb_dim,\n",
    "                cond_dim=self.cond_embedding_dim,\n",
    "                film_units=film_units,\n",
    "            )\n",
    "            self.conv_layers.append(lay)\n",
    "            prev_units = units\n",
    "\n",
    "        # -- Edge Prediction Layers --\n",
    "\n",
    "        # Finally, after the message passing and so on, we need to have some kind of network which\n",
    "        # takes the messages (edge dimension) as an input and produces the binary classification\n",
    "        # of whether that edge should exist or not.\n",
    "\n",
    "        self.link_layers = nn.ModuleList()\n",
    "        prev_units = self.conv_units[-1] * 2\n",
    "        for i, units in enumerate(link_units):\n",
    "            if i == len(link_units) - 1:\n",
    "                # The last layer should not have the batch norm and activation.\n",
    "                self.link_layers.append(\n",
    "                    nn.Linear(prev_units, units),\n",
    "                )\n",
    "            else:\n",
    "                self.link_layers.append(nn.Sequential(\n",
    "                    nn.Linear(prev_units, units),\n",
    "                    # CHANGED: BatchNorm -> LayerNorm\n",
    "                    nn.LayerNorm(units),\n",
    "                    nn.ReLU(),\n",
    "                ))\n",
    "            prev_units = units\n",
    "\n",
    "        # For the binary classification task we obviously want a sigmoid activation at the end\n",
    "        self.lay_link_act = nn.Sigmoid()\n",
    "\n",
    "        # ─── CHANGE: initialize final bias to match dataset’s positive rate ───\n",
    "        #    assume you know `p = (#positives)/(#edges)` up front\n",
    "        p = 288 / 1344  # <– replace with your actual base‐rate\n",
    "        final_lin = self.link_layers[-1]\n",
    "        nn.init.zeros_(final_lin.weight)               # CHANGE: zero‐init final weights\n",
    "        final_lin.bias.data.fill_(-math.log((1-p)/p))  # CHANGE: set bias = logit(p)\n",
    "\n",
    "    def forward(self, data: Data):\n",
    "        \"\"\"\n",
    "        Forward pass of the conditional GIN model.\n",
    "\n",
    "        This method processes the input graph data through the condition embedding network,\n",
    "        the graph convolutional layers, and finally the link prediction network to predict\n",
    "        edge existence probabilities.\n",
    "\n",
    "        :param data: PyTorch Geometric Data object containing the graph\n",
    "\n",
    "        :returns: Dictionary containing the edge prediction probabilities\n",
    "        \"\"\"\n",
    "\n",
    "        ## -- embedding the condition --\n",
    "        cond: torch.Tensor = data.cond\n",
    "        for lay in self.cond_layers:\n",
    "            cond = lay(cond)\n",
    "\n",
    "        if not hasattr(data, 'edge_weights'):\n",
    "            data.edge_weights = None\n",
    "\n",
    "        # ─── CHANGE: build node features from categorical IDs ───────────────\n",
    "        atom_ids   = data.x[:, 0].long()      # assume in [0..27]\n",
    "        degree_ids = data.x[:, 1].long()      # assume in [0..5]\n",
    "        # use the row-index in data.x as the unique node ID\n",
    "        node_idx_global = torch.arange(data.x.size(0), device=data.x.device)\n",
    "        # data.batch tells which graph each node belongs to, and data.ptr holds cumulative counts\n",
    "        local_idx = node_idx_global - data.ptr[data.batch]   # now runs 0…(N_g−1) per graph\n",
    "        # e_id      = self.node_id_emb(local_idx)\n",
    "        e_atom     = self.atom_emb(atom_ids)\n",
    "        e_degree   = self.degree_emb(degree_ids)\n",
    "        node_embedding = self.input_proj(torch.cat([e_atom, e_degree,\n",
    "                                                    # e_id\n",
    "                                                    ], dim=-1))\n",
    "        # ──────────────────────────────────────────────────────────────────────\n",
    "        # ─── CHANGED: embed the categorical edge attributes ─────────────────\n",
    "        # data.edge_attr is assumed shape [num_edges] with values in {0,1,2}\n",
    "        e_edge = self.edge_emb(data.edge_attr.long())\n",
    "        # ──────────────────────────────────────────────────────────────────────\n",
    "\n",
    "\n",
    "        ## -- message passing --\n",
    "        # CHANGE: Use the learned embedding\n",
    "        # node_embedding = data.x\n",
    "        for lay_conv in self.conv_layers:\n",
    "            node_embedding, _ = lay_conv(\n",
    "                x=node_embedding,\n",
    "                condition=cond,\n",
    "                edge_attr=e_edge,\n",
    "                edge_index=data.edge_index,\n",
    "                # edge_weights=data.edge_weights,\n",
    "            )\n",
    "\n",
    "        ## -- link prediction --\n",
    "        node_embedding_i = node_embedding[data.edge_index[0]]\n",
    "        node_embedding_j = node_embedding[data.edge_index[1]]\n",
    "        edge_embedding = torch.cat(\n",
    "            [node_embedding_i + node_embedding_j, torch.abs(node_embedding_i - node_embedding_j)], dim=-1)\n",
    "\n",
    "        for lay_link in self.link_layers:\n",
    "            edge_embedding = lay_link(edge_embedding)\n",
    "\n",
    "        # Sigmoid activation to get the final edge prediction probabilities.\n",
    "        edge_prediction = self.lay_link_act(edge_embedding)\n",
    "\n",
    "        return {\n",
    "            'edge_prediction': edge_prediction,\n",
    "        }\n",
    "\n",
    "    def training_step(self, batch: Data, batch_idx):\n",
    "        \"\"\"\n",
    "        Perform a single training step.\n",
    "\n",
    "        This method is called by PyTorch Lightning during training. It computes the forward pass\n",
    "        and calculates the binary cross-entropy loss between the predicted edge probabilities\n",
    "        and the target edge labels.\n",
    "\n",
    "        :param batch: PyTorch Geometric Data object containing a batch of graphs\n",
    "        :param batch_idx: Index of the current batch\n",
    "\n",
    "        :returns: Loss value for the current training step\n",
    "        \"\"\"\n",
    "\n",
    "        batch.edge_y = batch.edge_y.float()\n",
    "\n",
    "        result: dict = self(batch)\n",
    "        edge_prediction = result['edge_prediction']\n",
    "\n",
    "        edge_target = batch.edge_y.view(-1, 1)\n",
    "        loss = F.binary_cross_entropy(\n",
    "            edge_prediction,\n",
    "            edge_target,\n",
    "            reduction='mean',\n",
    "        )\n",
    "\n",
    "        self.log('loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \"\"\"\n",
    "        Configure optimizers for the model.\n",
    "\n",
    "        This method is called by PyTorch Lightning to set up the optimizer\n",
    "        for training the model.\n",
    "\n",
    "        :returns: The configured optimizer\n",
    "        \"\"\"\n",
    "        # CHANGE: added weight decay\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.learning_rate, weight_decay=1e-4)\n"
   ],
   "id": "64a8e50ee445d63b",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T13:50:21.918950Z",
     "start_time": "2025-07-08T13:50:20.840971Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from src.datasets import AddNodeDegree\n",
    "from torch_geometric.datasets import ZINC\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "batch_size = 2\n",
    "dataset = ZINC(root=\"/Users/arvandkaveh/Projects/kit/graph_hdc/datasets/test/zinc_subset_with_degree\",\n",
    "               pre_transform=AddNodeDegree())[:2]\n",
    "\n",
    "# Take the first graph for visualization and model testing\n",
    "sample_data = dataset[1]\n",
    "\n",
    "print(f\"Sample graph info:\")\n",
    "print(f\"Number of nodes: {sample_data.x.size(0)}\")\n",
    "print(f\"Number of edges: {sample_data.edge_index.size(1)}\")\n",
    "print(f\"Node feature dimension: {sample_data.x.size(1)}\")\n",
    "# print(f\"Edge feature dimension: {sample_data.edge_attr.size(1)}\")\n",
    "# print(f\"Condition dimension: {sample_data.cond.size(1)}\")\n"
   ],
   "id": "a331cd204ef808f5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample graph info:\n",
      "Number of nodes: 18\n",
      "Number of edges: 36\n",
      "Node feature dimension: 2\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T13:50:21.940686Z",
     "start_time": "2025-07-08T13:50:21.929067Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "## Reconstruct\n",
    "# Original\n",
    "existing_edges = list(zip(sample_data.edge_index[0].tolist(), sample_data.edge_index[1].tolist()))\n",
    "x = sample_data.x\n",
    "x_list = list(map(tuple, x.tolist()))\n",
    "existing_edges_tuples = {(x_list[u], x_list[v]) for u, v in existing_edges}\n",
    "\n",
    "assert len(existing_edges_tuples) < len(existing_edges)\n",
    "# Sorted\n",
    "\n",
    "## First sort by the **secondary key** (column 1)\n",
    "idx1 = torch.argsort(x[:, 1], stable=True)\n",
    "\n",
    "## Then sort the result by the **primary key** (column 0)\n",
    "x1 = x[idx1]\n",
    "idx2 = torch.argsort(x1[:, 0], stable=True)\n",
    "\n",
    "## Final sort index\n",
    "sort_idx = idx1[idx2]\n",
    "\n",
    "sort_idx_l = sort_idx.tolist()\n",
    "for idx in sort_idx_l:\n",
    "    print(x[idx])\n",
    "\n",
    "y = []\n",
    "initial_edge_guess = []\n",
    "num_nodes = sample_data.x.size(0)\n",
    "uniques = set()\n",
    "for i in range(num_nodes):\n",
    "    for j in range(i + 1, num_nodes):\n",
    "        if (x_list[i], x_list[j]) in existing_edges_tuples:\n",
    "            if (i, j) in existing_edges:\n",
    "                print(\"---Edge exists\")\n",
    "                print(i, j)\n",
    "                print(x_list[i], x_list[j])\n",
    "                # Edge exists\n",
    "                if (i, j) not in initial_edge_guess:\n",
    "                    initial_edge_guess.append((i, j))\n",
    "                    y.append(1)\n",
    "                    uniques.add(i)\n",
    "                    uniques.add(j)\n",
    "\n",
    "                    initial_edge_guess.append((j, i))\n",
    "                    y.append(1)\n",
    "            else:\n",
    "                # Edge does not exist\n",
    "                if (i, j) not in initial_edge_guess:\n",
    "                    initial_edge_guess.append((i, j))\n",
    "                    y.append(0)\n",
    "                    initial_edge_guess.append((j, i))\n",
    "                    y.append(0)\n",
    "\n",
    "print(uniques)\n",
    "print(initial_edge_guess)\n",
    "\n",
    "sample_data.edge_y = torch.tensor(y).float()\n",
    "sample_data.sort_idx = sort_idx_l\n",
    "\n",
    "edge_index_init_tensor = torch.tensor(list(zip(*initial_edge_guess)), dtype=torch.long)\n",
    "sample_data.edge_index_old = sample_data.edge_index\n",
    "sample_data.edge_index = edge_index_init_tensor\n",
    "\n",
    "print(f\"Sample graph info:\")\n",
    "print(f\"Number of nodes: {sample_data.x.size(0)}\")\n",
    "print(f\"Number of edges: {sample_data.edge_index.size(1)}\")\n",
    "print(f\"Node feature dimension: {sample_data.x.size(1)}\")\n",
    "# print(f\"Edge feature dimension: {sample_data.edge_attr.size(1)}\")\n",
    "# print(f\"Condition dimension: {sample_data.cond.size(1)}\")\n",
    "print(f\"edge_y: {sample_data.edge_y}\")\n"
   ],
   "id": "b9929f336f01a725",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1.])\n",
      "tensor([0., 1.])\n",
      "tensor([0., 1.])\n",
      "tensor([0., 2.])\n",
      "tensor([0., 2.])\n",
      "tensor([0., 2.])\n",
      "tensor([0., 2.])\n",
      "tensor([0., 2.])\n",
      "tensor([0., 2.])\n",
      "tensor([0., 2.])\n",
      "tensor([0., 3.])\n",
      "tensor([0., 3.])\n",
      "tensor([0., 3.])\n",
      "tensor([1., 1.])\n",
      "tensor([1., 1.])\n",
      "tensor([1., 2.])\n",
      "tensor([2., 3.])\n",
      "tensor([4., 3.])\n",
      "---Edge exists\n",
      "0 1\n",
      "(0.0, 1.0) (1.0, 2.0)\n",
      "---Edge exists\n",
      "1 2\n",
      "(1.0, 2.0) (0.0, 2.0)\n",
      "---Edge exists\n",
      "2 3\n",
      "(0.0, 2.0) (0.0, 2.0)\n",
      "---Edge exists\n",
      "3 4\n",
      "(0.0, 2.0) (4.0, 3.0)\n",
      "---Edge exists\n",
      "4 5\n",
      "(4.0, 3.0) (0.0, 1.0)\n",
      "---Edge exists\n",
      "4 6\n",
      "(4.0, 3.0) (0.0, 3.0)\n",
      "---Edge exists\n",
      "6 7\n",
      "(0.0, 3.0) (1.0, 1.0)\n",
      "---Edge exists\n",
      "6 8\n",
      "(0.0, 3.0) (2.0, 3.0)\n",
      "---Edge exists\n",
      "8 9\n",
      "(2.0, 3.0) (0.0, 1.0)\n",
      "---Edge exists\n",
      "8 10\n",
      "(2.0, 3.0) (0.0, 2.0)\n",
      "---Edge exists\n",
      "10 11\n",
      "(0.0, 2.0) (0.0, 3.0)\n",
      "---Edge exists\n",
      "11 12\n",
      "(0.0, 3.0) (0.0, 2.0)\n",
      "---Edge exists\n",
      "11 17\n",
      "(0.0, 3.0) (0.0, 2.0)\n",
      "---Edge exists\n",
      "12 13\n",
      "(0.0, 2.0) (0.0, 2.0)\n",
      "---Edge exists\n",
      "13 14\n",
      "(0.0, 2.0) (0.0, 3.0)\n",
      "---Edge exists\n",
      "14 15\n",
      "(0.0, 3.0) (1.0, 1.0)\n",
      "---Edge exists\n",
      "14 16\n",
      "(0.0, 3.0) (0.0, 2.0)\n",
      "---Edge exists\n",
      "16 17\n",
      "(0.0, 2.0) (0.0, 2.0)\n",
      "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17}\n",
      "[(0, 1), (1, 0), (0, 4), (4, 0), (0, 8), (8, 0), (1, 2), (2, 1), (1, 3), (3, 1), (1, 5), (5, 1), (1, 9), (9, 1), (1, 10), (10, 1), (1, 12), (12, 1), (1, 13), (13, 1), (1, 16), (16, 1), (1, 17), (17, 1), (2, 3), (3, 2), (2, 4), (4, 2), (2, 6), (6, 2), (2, 8), (8, 2), (2, 10), (10, 2), (2, 11), (11, 2), (2, 12), (12, 2), (2, 13), (13, 2), (2, 14), (14, 2), (2, 16), (16, 2), (2, 17), (17, 2), (3, 4), (4, 3), (3, 6), (6, 3), (3, 8), (8, 3), (3, 10), (10, 3), (3, 11), (11, 3), (3, 12), (12, 3), (3, 13), (13, 3), (3, 14), (14, 3), (3, 16), (16, 3), (3, 17), (17, 3), (4, 5), (5, 4), (4, 6), (6, 4), (4, 9), (9, 4), (4, 10), (10, 4), (4, 11), (11, 4), (4, 12), (12, 4), (4, 13), (13, 4), (4, 14), (14, 4), (4, 16), (16, 4), (4, 17), (17, 4), (5, 8), (8, 5), (6, 7), (7, 6), (6, 8), (8, 6), (6, 10), (10, 6), (6, 12), (12, 6), (6, 13), (13, 6), (6, 15), (15, 6), (6, 16), (16, 6), (6, 17), (17, 6), (7, 11), (11, 7), (7, 14), (14, 7), (8, 9), (9, 8), (8, 10), (10, 8), (8, 11), (11, 8), (8, 12), (12, 8), (8, 13), (13, 8), (8, 14), (14, 8), (8, 16), (16, 8), (8, 17), (17, 8), (10, 11), (11, 10), (10, 12), (12, 10), (10, 13), (13, 10), (10, 14), (14, 10), (10, 16), (16, 10), (10, 17), (17, 10), (11, 12), (12, 11), (11, 13), (13, 11), (11, 15), (15, 11), (11, 16), (16, 11), (11, 17), (17, 11), (12, 13), (13, 12), (12, 14), (14, 12), (12, 16), (16, 12), (12, 17), (17, 12), (13, 14), (14, 13), (13, 16), (16, 13), (13, 17), (17, 13), (14, 15), (15, 14), (14, 16), (16, 14), (14, 17), (17, 14), (16, 17), (17, 16)]\n",
      "Sample graph info:\n",
      "Number of nodes: 18\n",
      "Number of edges: 168\n",
      "Node feature dimension: 2\n",
      "edge_y: tensor([1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 0., 0., 1., 1.])\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T13:50:21.955313Z",
     "start_time": "2025-07-08T13:50:21.952356Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch_geometric.data import Batch\n",
    "\n",
    "# Create a batch of the same graph to overfit\n",
    "batch_size = 1\n",
    "batch_list = []\n",
    "for _ in range(batch_size):\n",
    "    batch_list.append(sample_data)\n",
    "batch = Batch.from_data_list(batch_list)\n",
    "print(batch.edge_index.shape)\n",
    "print(batch.edge_y.shape)\n",
    "\n",
    "\n",
    "# res = hypernet.forward(data=batch)\n",
    "# x = torch.stack([res[\"node_terms\"], res[\"edge_terms\"], res[\"graph_embedding\"]], dim=1)"
   ],
   "id": "5b245e5f90e0b71",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 168])\n",
      "torch.Size([168])\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T13:50:26.601306Z",
     "start_time": "2025-07-08T13:50:21.965927Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from src.encoding.the_types import VSAModel\n",
    "from src.encoding.configs_and_constants import SupportedDataset\n",
    "import torch\n",
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "vsa = \"HRR\"\n",
    "hv_dim = 96 * 96\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "seed = 42\n",
    "\n",
    "ds = SupportedDataset.ZINC_NODE_DEGREE_COMB\n",
    "ds.default_cfg.vsa = VSAModel(vsa)\n",
    "ds.default_cfg.hv_dim = hv_dim\n",
    "ds.default_cfg.device = device\n",
    "ds.default_cfg.seed = seed\n",
    "# Disable edge and graph features\n",
    "ds.default_cfg.edge_feature_configs = {}\n",
    "ds.default_cfg.graph_feature_configs = {}\n",
    "\n",
    "from src.encoding.graph_encoders import HyperNet\n",
    "\n",
    "hypernet = HyperNet(config=ds.default_cfg, depth=3)\n",
    "hypernet.populate_codebooks()\n",
    "\n",
    "encoded = hypernet.forward(batch)\n",
    "cond = encoded[\"graph_embedding\"].squeeze()\n",
    "\n",
    "num_nodes = sample_data.num_nodes\n",
    "cond_c = cond.unsqueeze(0).expand(num_nodes, -1)\n",
    "sample_data.cond = cond_c  # shape: [num_nodes, 64]\n",
    "\n",
    "# Create a batch of the same graph to overfit\n",
    "batch_size = 16\n",
    "batch_list = []\n",
    "for _ in range(batch_size):\n",
    "    batch_list.append(sample_data)\n",
    "batch = Batch.from_data_list(batch_list)\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "3b25b7e30cdfbda5",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T13:50:26.705624Z",
     "start_time": "2025-07-08T13:50:26.619708Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Visualize the graph with edge targets as colors\n",
    "plt.figure(figsize=(8, 6))\n",
    "G_vis = nx.Graph()\n",
    "for i in range(sample_data.x.size(0)):\n",
    "    G_vis.add_node(i)\n",
    "\n",
    "edge_colors = []\n",
    "for i in range(sample_data.edge_index.size(1)):\n",
    "    src = sample_data.edge_index[0, i].item()\n",
    "    dst = sample_data.edge_index[1, i].item()\n",
    "    target = sample_data.edge_y[i].item()\n",
    "    if target > 0.5:\n",
    "        G_vis.add_edge(src, dst)\n",
    "        edge_colors.append('black')\n",
    "    # edge_colors.append('black' if target > 0.5 else 'white')\n",
    "\n",
    "print(f\"{sample_data.edge_index_old.size(1)=}\")\n",
    "\n",
    "pos = nx.spring_layout(G_vis, seed=42)\n",
    "nx.draw(G_vis, pos, with_labels=True, node_color='skyblue',\n",
    "        node_size=500, edge_color=edge_colors, width=2, alpha=0.7)\n",
    "plt.title(\"Sample Graph with Edge Targets (green=1, red=0)\")\n",
    "plt.savefig(\"sample_graph_pre_training.png\")\n",
    "plt.close()\n"
   ],
   "id": "86a8c886995dd9ed",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_data.edge_index_old.size(1)=36\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T13:50:27.091797Z",
     "start_time": "2025-07-08T13:50:26.717255Z"
    }
   },
   "cell_type": "code",
   "source": [
    "node_feature_dim = 2\n",
    "edge_feature_dim = 1\n",
    "condition_dim = hv_dim # 6400\n",
    "# Initialize the GIN model\n",
    "model = ConditionalGIN(\n",
    "    input_dim=node_feature_dim,\n",
    "    edge_dim=edge_feature_dim,\n",
    "    condition_dim=condition_dim,\n",
    "    cond_units=[1024, 512, 256],  # Simplified for testing\n",
    "    conv_units=[128, 128, 64],  # Simplified for testing\n",
    "    film_units=[256, 128],  # Simplified for testing\n",
    "    link_units=[128, 64, 1]\n",
    ")\n",
    "\n",
    "batch_size_training = 8\n",
    "\n",
    "\n",
    "loader = DataLoader(\n",
    "    dataset=[sample_data for _ in range(batch_size_training)],\n",
    "    batch_size=batch_size_training, shuffle=False)\n",
    "batch = next(iter(loader))\n",
    "data_cond = sample_data.cond\n",
    "print(data_cond.shape)  # -> [num_nodes, 64]\n",
    "batch_cond = batch.cond\n",
    "print(batch_cond.shape)  # -> [num_nodes_in_batch, 64]\n",
    "batch_edge_y = sample_data.edge_y\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "# Prepare to record losses\n",
    "train_losses = []\n",
    "for i in range(200):\n",
    "    print(f\"\\n=== Iteration {i + 1} ===\")\n",
    "\n",
    "    # 1) Evaluation passos\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        result = model(batch)\n",
    "        edge_pred = result['edge_prediction']\n",
    "    print(\"  [Eval] pred shape:\", edge_pred.shape)\n",
    "    print(\"  [Eval] first 20 preds:\", edge_pred[:20].cpu().numpy().flatten())\n",
    "    print(\"  [Eval] sum pred:\", edge_pred.sum().item())\n",
    "    print(\"  [Eval] first 20 targets:\", sample_data.edge_y[:20].cpu().numpy().flatten())\n",
    "    print(\"  [Eval] sum y:\", sample_data.edge_y.sum().item() * 8)\n",
    "\n",
    "    # 2) Training step\n",
    "    model.train()\n",
    "    batch = next(iter(loader))\n",
    "    optimizer.zero_grad()\n",
    "    loss = model.training_step(batch, 0)\n",
    "    train_losses.append(loss.item())\n",
    "    loss.backward()\n",
    "    # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "    optimizer.step()\n",
    "    print(\"  [Train] loss:\", loss.item())\n",
    "\n",
    "# After loop, plot losses\n",
    "plt.figure()\n",
    "plt.plot(train_losses)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss over Iterations')\n",
    "plt.show()\n",
    "\n",
    "## Plot the decoded graph\n",
    "# 1) Run a forward pass and build a global mask\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    result    = model(batch)\n",
    "    edge_pred = result['edge_prediction'].view(-1)\n",
    "    mask_all  = edge_pred > 0.5               # BoolTensor[N]\n",
    "\n",
    "# 2) Split the batch back into individual Data objects\n",
    "data_list   = batch.to_data_list()\n",
    "sample_graph = data_list[0]                  # pick the first graph in your batch\n",
    "\n",
    "# 3) Now mask _that_ graph's edges\n",
    "num_edges0  = sample_graph.edge_index.size(1)\n",
    "mask0       = mask_all[:num_edges0]          # only the edges of graph 0\n",
    "sample_graph.edge_index = sample_graph.edge_index[:, mask0]\n",
    "sample_graph.edge_y     = sample_graph.edge_y[mask0]\n",
    "\n",
    "# Visualize the graph with edge targets as colors\n",
    "plt.figure(figsize=(8, 6))\n",
    "G_vis = nx.Graph()\n",
    "for i in range(sample_graph.x.size(0)):\n",
    "    G_vis.add_node(i)\n",
    "\n",
    "edge_colors = []\n",
    "for i in range(sample_graph.edge_index.size(1)):\n",
    "    src = sample_graph.edge_index[0, i].item()\n",
    "    dst = sample_graph.edge_index[1, i].item()\n",
    "    target = sample_graph.edge_y[i].item()\n",
    "    if target > 0.5:\n",
    "        G_vis.add_edge(src, dst)\n",
    "        edge_colors.append('black')\n",
    "    # edge_colors.append('black' if target > 0.5 else 'white')\n",
    "\n",
    "print(f\"{sample_graph.edge_index_old.size(1)=}\")\n",
    "\n",
    "pos = nx.spring_layout(G_vis, seed=42)\n",
    "nx.draw(G_vis, pos, with_labels=True, node_color='skyblue',\n",
    "        node_size=500, edge_color=edge_colors, width=2, alpha=0.7)\n",
    "plt.title(\"Sample Graph with Edge Targets (green=1, red=0)\")\n",
    "plt.savefig(\"sample_graph_after_training.png\")\n",
    "plt.close()"
   ],
   "id": "4b544e2663e2fc34",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 9216])\n",
      "torch.Size([144, 9216])\n",
      "\n",
      "=== Iteration 1 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arvandkaveh/Projects/kit/graph_hdc/.pixi/envs/default/lib/python3.13/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 1. Expected size 1344 but got size 288 for tensor number 2 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mRuntimeError\u001B[39m                              Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[7]\u001B[39m\u001B[32m, line 38\u001B[39m\n\u001B[32m     36\u001B[39m model.eval()\n\u001B[32m     37\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m torch.no_grad():\n\u001B[32m---> \u001B[39m\u001B[32m38\u001B[39m     result = \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     39\u001B[39m     edge_pred = result[\u001B[33m'\u001B[39m\u001B[33medge_prediction\u001B[39m\u001B[33m'\u001B[39m]\n\u001B[32m     40\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33m  [Eval] pred shape:\u001B[39m\u001B[33m\"\u001B[39m, edge_pred.shape)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/kit/graph_hdc/.pixi/envs/default/lib/python3.13/site-packages/torch/nn/modules/module.py:1739\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1737\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1738\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1739\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/kit/graph_hdc/.pixi/envs/default/lib/python3.13/site-packages/torch/nn/modules/module.py:1750\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1745\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1746\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1747\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1748\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1749\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1750\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1752\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1753\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 564\u001B[39m, in \u001B[36mConditionalGIN.forward\u001B[39m\u001B[34m(self, data)\u001B[39m\n\u001B[32m    557\u001B[39m \u001B[38;5;66;03m# ──────────────────────────────────────────────────────────────────────\u001B[39;00m\n\u001B[32m    558\u001B[39m \n\u001B[32m    559\u001B[39m \n\u001B[32m    560\u001B[39m \u001B[38;5;66;03m## -- message passing --\u001B[39;00m\n\u001B[32m    561\u001B[39m \u001B[38;5;66;03m# CHANGE: Use the learned embedding\u001B[39;00m\n\u001B[32m    562\u001B[39m \u001B[38;5;66;03m# node_embedding = data.x\u001B[39;00m\n\u001B[32m    563\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m lay_conv \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m.conv_layers:\n\u001B[32m--> \u001B[39m\u001B[32m564\u001B[39m     node_embedding, _ = \u001B[43mlay_conv\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    565\u001B[39m \u001B[43m        \u001B[49m\u001B[43mx\u001B[49m\u001B[43m=\u001B[49m\u001B[43mnode_embedding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    566\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcondition\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcond\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    567\u001B[39m \u001B[43m        \u001B[49m\u001B[43medge_attr\u001B[49m\u001B[43m=\u001B[49m\u001B[43me_edge\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    568\u001B[39m \u001B[43m        \u001B[49m\u001B[43medge_index\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m.\u001B[49m\u001B[43medge_index\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    569\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# edge_weights=data.edge_weights,\u001B[39;49;00m\n\u001B[32m    570\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    572\u001B[39m \u001B[38;5;66;03m## -- link prediction --\u001B[39;00m\n\u001B[32m    573\u001B[39m node_embedding_i = node_embedding[data.edge_index[\u001B[32m0\u001B[39m]]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/kit/graph_hdc/.pixi/envs/default/lib/python3.13/site-packages/torch/nn/modules/module.py:1739\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1737\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1738\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1739\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/kit/graph_hdc/.pixi/envs/default/lib/python3.13/site-packages/torch/nn/modules/module.py:1750\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1745\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1746\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1747\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1748\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1749\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1750\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1752\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1753\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 366\u001B[39m, in \u001B[36mConditionalGraphAttention.forward\u001B[39m\u001B[34m(self, x, condition, edge_index, edge_attr, edge_weights, **kwargs)\u001B[39m\n\u001B[32m    363\u001B[39m \u001B[38;5;28mself\u001B[39m._attention_logits = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    365\u001B[39m \u001B[38;5;66;03m# node_embedding: (B * V, out)\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m366\u001B[39m node_embedding = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mpropagate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    367\u001B[39m \u001B[43m    \u001B[49m\u001B[43medge_index\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    368\u001B[39m \u001B[43m    \u001B[49m\u001B[43mx\u001B[49m\u001B[43m=\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    369\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcondition\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcondition\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    370\u001B[39m \u001B[43m    \u001B[49m\u001B[43medge_attr\u001B[49m\u001B[43m=\u001B[49m\u001B[43medge_attr\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    371\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# edge_weights=edge_weights,\u001B[39;49;00m\n\u001B[32m    372\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    374\u001B[39m \u001B[38;5;66;03m# node_embedding = self.lay_act(node_embedding)\u001B[39;00m\n\u001B[32m    375\u001B[39m x = \u001B[38;5;28mself\u001B[39m.lay_transform_lin_1(\n\u001B[32m    376\u001B[39m     torch.cat([node_embedding, x], axis=\u001B[32m1\u001B[39m),\n\u001B[32m    377\u001B[39m     condition\n\u001B[32m    378\u001B[39m )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/kit/graph_hdc/.pixi/envs/default/lib/python3.13/site-packages/torch_geometric/nn/conv/message_passing.py:523\u001B[39m, in \u001B[36mMessagePassing.propagate\u001B[39m\u001B[34m(self, edge_index, size, **kwargs)\u001B[39m\n\u001B[32m    521\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m res \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    522\u001B[39m         msg_kwargs = res[\u001B[32m0\u001B[39m] \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(res, \u001B[38;5;28mtuple\u001B[39m) \u001B[38;5;28;01melse\u001B[39;00m res\n\u001B[32m--> \u001B[39m\u001B[32m523\u001B[39m out = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mmessage\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mmsg_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    524\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m hook \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m._message_forward_hooks.values():\n\u001B[32m    525\u001B[39m     res = hook(\u001B[38;5;28mself\u001B[39m, (msg_kwargs, ), out)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 314\u001B[39m, in \u001B[36mConditionalGraphAttention.message\u001B[39m\u001B[34m(self, x_i, x_j, condition_i, condition_j, edge_attr, edge_weights)\u001B[39m\n\u001B[32m    312\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m edge_attr \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    313\u001B[39m     feats.append(edge_attr)\n\u001B[32m--> \u001B[39m\u001B[32m314\u001B[39m message = \u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcat\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfeats\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdim\u001B[49m\u001B[43m=\u001B[49m\u001B[43m-\u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m    316\u001B[39m attention_logits = \u001B[38;5;28mself\u001B[39m.lay_attention_lin_1(message, condition_i)\n\u001B[32m    317\u001B[39m attention_logits = \u001B[38;5;28mself\u001B[39m.lay_attention_bn(attention_logits)\n",
      "\u001B[31mRuntimeError\u001B[39m: Sizes of tensors must match except in dimension 1. Expected size 1344 but got size 288 for tensor number 2 in the list."
     ]
    }
   ],
   "execution_count": 7
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
