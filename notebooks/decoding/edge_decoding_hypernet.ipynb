{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "cc9045ed6fae4063",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-07T07:43:27.468131Z",
     "start_time": "2025-10-07T07:29:08.881178Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from collections import Counter\n",
    "import itertools\n",
    "\n",
    "from torch_geometric.data import Batch\n",
    "import torch\n",
    "import torchhd\n",
    "\n",
    "from src.datasets.qm9_smiles_generation import QM9Smiles\n",
    "from src.encoding.configs_and_constants import QM9_SMILES_HRR_1600_CONFIG\n",
    "from src.encoding.graph_encoders import load_or_create_hypernet\n",
    "from src.utils.utils import DataTransformer, GLOBAL_MODEL_PATH, TupleIndexer, pick_device\n",
    "\n",
    "ds = QM9Smiles(split=\"test\")\n",
    "\n",
    "\n",
    "data = ds[64]\n",
    "\n",
    "nx_g = DataTransformer.pyg_to_nx(data)\n",
    "mol, _ = DataTransformer.nx_to_mol_v2(nx_g, dataset=\"qm9\")\n",
    "\n",
    "display(mol)\n",
    "print(mol.GetNumAtoms())\n",
    "print(mol.GetNumBonds())\n",
    "print(nx_g.number_of_nodes())\n",
    "print(nx_g.number_of_edges())\n",
    "print(data.x)\n",
    "print(data.edge_index)\n",
    "\n",
    "device = pick_device()\n",
    "\n",
    "node_tuples = [tuple(i) for i in data.x.tolist()]\n",
    "edge_tuples = [tuple(e) for e in data.edge_index.t().cpu().tolist()]\n",
    "\n",
    "ds_config = QM9_SMILES_HRR_1600_CONFIG\n",
    "encoder = load_or_create_hypernet(GLOBAL_MODEL_PATH, cfg=ds_config)\n",
    "node_cb = encoder.nodes_codebook\n",
    "node_cb = node_cb.to(torch.float64).as_subclass(torchhd.HRRTensor)\n",
    "print(node_cb.shape)\n",
    "node_idxer: TupleIndexer = encoder.nodes_indexer\n",
    "\n",
    "\n",
    "# Manually compute the edge terms\n",
    "edget_terms_manual = None\n",
    "edges = []\n",
    "for a, b in edge_tuples:\n",
    "    idx_a = node_idxer.get_idx(node_tuples[a])\n",
    "    idx_b = node_idxer.get_idx(node_tuples[b])\n",
    "    hd_a = node_cb[idx_a]\n",
    "    hd_b = node_cb[idx_b]\n",
    "\n",
    "    # bind\n",
    "    edges.append(hd_a.bind(hd_b))\n",
    "\n",
    "t = torch.stack(edges)\n",
    "print(t.shape)\n",
    "edget_terms_manual = torchhd.multibundle(t)\n",
    "print(edget_terms_manual.shape)\n",
    "\n",
    "edget_terms_m_copy = edget_terms_manual.clone()\n",
    "# Now just reverse to see if you get 0\n",
    "for a, b in edge_tuples:\n",
    "    idx_a = node_idxer.get_idx(node_tuples[a])\n",
    "    idx_b = node_idxer.get_idx(node_tuples[b])\n",
    "    hd_a = node_cb[idx_a]\n",
    "    hd_b = node_cb[idx_b]\n",
    "\n",
    "    # bind\n",
    "    edget_terms_m_copy -= hd_a.bind(hd_b)\n",
    "\n",
    "zero_hd = torchhd.empty(1, 1600, \"HRR\")\n",
    "sum_elements = edget_terms_m_copy.abs().sum().item()\n",
    "print(sum_elements)\n",
    "# prints 2.470420440658927e-05 <-- why not zero?\n",
    "# with dtype floa64 -> 4.542902902140598e-14 almost zero\n",
    "\n",
    "# Compare the manually created one with the hypernet\n",
    "\n",
    "batch = Batch.from_data_list([data])\n",
    "edge_terms = encoder.forward(batch)[\"edge_terms\"]\n",
    "\n",
    "eps = 1e-6\n",
    "ok_mask = (edge_terms - edget_terms_manual).abs() <= eps         # bool tensor\n",
    "all_ok = ok_mask.all() # << GOOD\n",
    "print(all_ok.item())\n",
    "\n",
    "\n",
    "## Now let's fucking decode the edges\n",
    "node_counter = DataTransformer.get_node_counter_from_batch(0, batch)\n",
    "num_edges = sum([(e_idx+1) * n for (_, e_idx, _, _), n in node_counter.items()])\n",
    "\n",
    "n_count = node_counter.total()\n",
    "e_count = num_edges\n",
    "print(n_count)\n",
    "print(e_count)\n",
    "\n",
    "node_idxs = node_idxer.get_idxs(node_tuples)\n",
    "idx_tensor = torch.tensor(node_idxs, dtype=torch.long, device=device)\n",
    "cb = node_cb[idx_tensor]\n",
    "print(cb.shape)\n",
    "\n",
    "working_node_counter = node_counter.copy()\n",
    "residuals = {k:(k[1]+1) * n * 2 for k, n in node_counter.items()} # how much each node can spend on edges\n",
    "edges_left = [(node_tuples[a], node_tuples[b]) for a, b in edge_tuples]\n",
    "working_edge_terms = edget_terms_manual.clone().as_subclass(torchhd.HRRTensor)\n",
    "working_node_tuples = node_tuples.copy()\n",
    "result = Counter()\n",
    "print(f\"ITERATIONS: {e_count}\")\n",
    "tuple_to_idx = {t: i for i, t in enumerate(working_node_counter.keys())}\n",
    "result_edge_index = []\n",
    "black_list = set()\n",
    "for i in range(e_count // 2):\n",
    "    edges = []\n",
    "    all_edges = list(itertools.product(working_node_counter.keys(), working_node_counter.keys()))\n",
    "    for a, b in all_edges:\n",
    "        # if a == b: continue\n",
    "        idx_a = node_idxer.get_idx(a)\n",
    "        idx_b = node_idxer.get_idx(b)\n",
    "        hd_a = node_cb[idx_a]\n",
    "        hd_b = node_cb[idx_b]\n",
    "\n",
    "        # bind\n",
    "        edges.append(hd_a.bind(hd_b))\n",
    "\n",
    "    t = torch.stack(edges).as_subclass(torchhd.HRRTensor)\n",
    "    sims = torchhd.cos(working_edge_terms, t)\n",
    "    idx = torch.argmax(sims)\n",
    "    eps = 1e-9\n",
    "    max_idxs = (sims >= sims.max() - eps).nonzero(as_tuple=True)[0]\n",
    "    a_found, b_found = None, None\n",
    "    for idx in max_idxs:\n",
    "        if idx in black_list:\n",
    "            continue\n",
    "        a_found, b_found = all_edges[idx]\n",
    "        if residuals[a_found] <= 0:\n",
    "            continue\n",
    "        if residuals[b_found] <= 0:\n",
    "            continue\n",
    "        if (a_found, b_found) not in edges_left:\n",
    "            print(\"ALARM\")\n",
    "        break\n",
    "\n",
    "    if not a_found or not b_found:\n",
    "        print(\"Failed to decode\")\n",
    "        break\n",
    "    edges_left.remove((a_found, b_found))\n",
    "    edges_left.remove((b_found, a_found))\n",
    "    hd_a_found = node_cb[node_idxer.get_idx(a_found)]\n",
    "    hd_b_found = node_cb[node_idxer.get_idx(b_found)]\n",
    "    working_edge_terms -= hd_a_found.bind(hd_b_found)\n",
    "    working_edge_terms -= hd_b_found.bind(hd_a_found)\n",
    "    result[(a_found, b_found)] += 1\n",
    "    result[(b_found, a_found)] += 1\n",
    "\n",
    "    residuals[a_found] -= 2\n",
    "    residuals[b_found] -= 2\n",
    "\n",
    "    result_edge_index.append((a_found, b_found))\n",
    "    result_edge_index.append((b_found, a_found))\n",
    "    print(f\"Edge {i} done\")\n",
    "    print(f\"Sim max: {sims.max().item()}\")\n",
    "\n",
    "\n",
    "print(result.total())\n",
    "print(result)\n",
    "print(result_edge_index)\n",
    "print(\"ENCODED\")\n",
    "e_c = Counter(result_edge_index)\n",
    "print(sorted(e_c.items(), key=lambda x: x[1], reverse=True))\n",
    "print(\"ACTUAL\")\n",
    "a_c = Counter([(node_tuples[a], node_tuples[b]) for a, b in edge_tuples])\n",
    "print(sorted(a_c.items(), key=lambda x: x[1], reverse=True))\n",
    "\n",
    "\n",
    "encoded_nodes = []\n",
    "encoded_edge_indexes = []\n",
    "node_indexes = {}\n",
    "idx = 0\n",
    "residuals_left = []\n",
    "actual_edges = [(node_tuples[a], node_tuples[b]) for a, b in edge_tuples]\n",
    "for i, (a, b) in enumerate(result_edge_index):\n",
    "    if i % 2 == 1:\n",
    "        continue\n",
    "    i_a, i_b = -1, -1\n",
    "    for i, (n, r) in enumerate(zip(encoded_nodes, residuals_left)):\n",
    "        if n == a and r >= 0:\n",
    "            i_a = i\n",
    "        if n == b and r >= 0:\n",
    "            i_b = i\n",
    "    if (i_a, i_b) not in encoded_edge_indexes:\n",
    "        if i_a == -1:\n",
    "            encoded_nodes.append(a)\n",
    "            residuals_left.append(a[1] + 1)\n",
    "            i_a = idx\n",
    "            idx += 1\n",
    "        if i_b == -1:\n",
    "            encoded_nodes.append(b)\n",
    "            residuals_left.append(b[1] + 1)\n",
    "            i_b = idx\n",
    "            idx += 1\n",
    "    else:\n",
    "\n",
    "    encoded_edge_indexes.append((i_a, i_b))\n",
    "    encoded_edge_indexes.append((i_b, i_a))\n",
    "    residuals_left[i_a] -= 1\n",
    "    residuals_left[i_b] -= 1\n"
   ],
   "id": "1cbcceda0511e258",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<rdkit.Chem.rdchem.Mol at 0x7f2d5b2818c0>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "tensor([[2., 0., 0., 0.],\n",
      "        [0., 2., 0., 0.],\n",
      "        [0., 1., 0., 2.],\n",
      "        [0., 2., 0., 1.],\n",
      "        [2., 0., 0., 1.],\n",
      "        [0., 1., 0., 2.],\n",
      "        [2., 1., 0., 0.],\n",
      "        [0., 1., 0., 2.],\n",
      "        [2., 1., 0., 0.]])\n",
      "tensor([[0, 1, 1, 2, 2, 3, 3, 4, 3, 5, 5, 6, 6, 7, 7, 8, 8, 1],\n",
      "        [1, 0, 2, 1, 3, 2, 4, 3, 5, 3, 6, 5, 7, 6, 8, 7, 1, 8]])\n",
      "Loading existing HyperNet from /home/akaveh/Projects/kit/graph_hdc/_models/hypernet_QM9SmilesHRR1600_HRR_dim1600_s42_depth3_ecb0.pt\n",
      "torch.Size([300, 1600])\n",
      "torch.Size([18, 1600])\n",
      "torch.Size([1600])\n",
      "4.542902902140598e-14\n",
      "True\n",
      "9\n",
      "18\n",
      "torch.Size([9, 1600])\n",
      "ITERATIONS: 18\n",
      "Edge 0 done\n",
      "Sim max: 0.7490727842160757\n",
      "Edge 1 done\n",
      "Sim max: 0.6095282557366755\n",
      "Edge 2 done\n",
      "Sim max: 0.6593857140683818\n",
      "Edge 3 done\n",
      "Sim max: 0.4507840139272349\n",
      "Edge 4 done\n",
      "Sim max: 0.4730925234213882\n",
      "Edge 5 done\n",
      "Sim max: 0.4939945456993436\n",
      "Edge 6 done\n",
      "Sim max: 0.5817664880936574\n",
      "Edge 7 done\n",
      "Sim max: 0.6848822814531254\n",
      "Edge 8 done\n",
      "Sim max: 1.0\n",
      "18\n",
      "Counter({((0, 1, 0, 2), (2, 1, 0, 0)): 3, ((2, 1, 0, 0), (0, 1, 0, 2)): 3, ((0, 1, 0, 2), (0, 2, 0, 1)): 2, ((0, 2, 0, 1), (0, 1, 0, 2)): 2, ((2, 0, 0, 0), (0, 2, 0, 0)): 1, ((0, 2, 0, 0), (2, 0, 0, 0)): 1, ((0, 2, 0, 0), (0, 1, 0, 2)): 1, ((0, 1, 0, 2), (0, 2, 0, 0)): 1, ((0, 2, 0, 1), (2, 0, 0, 1)): 1, ((2, 0, 0, 1), (0, 2, 0, 1)): 1, ((0, 2, 0, 0), (2, 1, 0, 0)): 1, ((2, 1, 0, 0), (0, 2, 0, 0)): 1})\n",
      "[((0, 1, 0, 2), (2, 1, 0, 0)), ((2, 1, 0, 0), (0, 1, 0, 2)), ((0, 1, 0, 2), (2, 1, 0, 0)), ((2, 1, 0, 0), (0, 1, 0, 2)), ((0, 1, 0, 2), (0, 2, 0, 1)), ((0, 2, 0, 1), (0, 1, 0, 2)), ((2, 0, 0, 0), (0, 2, 0, 0)), ((0, 2, 0, 0), (2, 0, 0, 0)), ((0, 1, 0, 2), (2, 1, 0, 0)), ((2, 1, 0, 0), (0, 1, 0, 2)), ((0, 2, 0, 0), (0, 1, 0, 2)), ((0, 1, 0, 2), (0, 2, 0, 0)), ((0, 1, 0, 2), (0, 2, 0, 1)), ((0, 2, 0, 1), (0, 1, 0, 2)), ((0, 2, 0, 1), (2, 0, 0, 1)), ((2, 0, 0, 1), (0, 2, 0, 1)), ((0, 2, 0, 0), (2, 1, 0, 0)), ((2, 1, 0, 0), (0, 2, 0, 0))]\n",
      "ENCODED\n",
      "[(((0, 1, 0, 2), (2, 1, 0, 0)), 3), (((2, 1, 0, 0), (0, 1, 0, 2)), 3), (((0, 1, 0, 2), (0, 2, 0, 1)), 2), (((0, 2, 0, 1), (0, 1, 0, 2)), 2), (((2, 0, 0, 0), (0, 2, 0, 0)), 1), (((0, 2, 0, 0), (2, 0, 0, 0)), 1), (((0, 2, 0, 0), (0, 1, 0, 2)), 1), (((0, 1, 0, 2), (0, 2, 0, 0)), 1), (((0, 2, 0, 1), (2, 0, 0, 1)), 1), (((2, 0, 0, 1), (0, 2, 0, 1)), 1), (((0, 2, 0, 0), (2, 1, 0, 0)), 1), (((2, 1, 0, 0), (0, 2, 0, 0)), 1)]\n",
      "ACTUAL\n",
      "[(((0.0, 1.0, 0.0, 2.0), (2.0, 1.0, 0.0, 0.0)), 3), (((2.0, 1.0, 0.0, 0.0), (0.0, 1.0, 0.0, 2.0)), 3), (((0.0, 1.0, 0.0, 2.0), (0.0, 2.0, 0.0, 1.0)), 2), (((0.0, 2.0, 0.0, 1.0), (0.0, 1.0, 0.0, 2.0)), 2), (((2.0, 0.0, 0.0, 0.0), (0.0, 2.0, 0.0, 0.0)), 1), (((0.0, 2.0, 0.0, 0.0), (2.0, 0.0, 0.0, 0.0)), 1), (((0.0, 2.0, 0.0, 0.0), (0.0, 1.0, 0.0, 2.0)), 1), (((0.0, 1.0, 0.0, 2.0), (0.0, 2.0, 0.0, 0.0)), 1), (((0.0, 2.0, 0.0, 1.0), (2.0, 0.0, 0.0, 1.0)), 1), (((2.0, 0.0, 0.0, 1.0), (0.0, 2.0, 0.0, 1.0)), 1), (((2.0, 1.0, 0.0, 0.0), (0.0, 2.0, 0.0, 0.0)), 1), (((0.0, 2.0, 0.0, 0.0), (2.0, 1.0, 0.0, 0.0)), 1)]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 195\u001B[39m\n\u001B[32m    193\u001B[39m     i_a = idx\n\u001B[32m    194\u001B[39m     idx += \u001B[32m1\u001B[39m\n\u001B[32m--> \u001B[39m\u001B[32m195\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[43mi_b\u001B[49m == -\u001B[32m1\u001B[39m:\n\u001B[32m    196\u001B[39m     encoded_nodes.append(b)\n\u001B[32m    197\u001B[39m     residuals_left.append(b[\u001B[32m1\u001B[39m] + \u001B[32m1\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/pycharm-2025.2.3/plugins/python-ce/helpers/pydev/_pydevd_bundle/pydevd_frame.py:888\u001B[39m, in \u001B[36mPyDBFrame.trace_dispatch\u001B[39m\u001B[34m(self, frame, event, arg)\u001B[39m\n\u001B[32m    885\u001B[39m             stop = \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[32m    887\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m plugin_stop:\n\u001B[32m--> \u001B[39m\u001B[32m888\u001B[39m     stopped_on_plugin = \u001B[43mplugin_manager\u001B[49m\u001B[43m.\u001B[49m\u001B[43mstop\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmain_debugger\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop_info\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstep_cmd\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    889\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m stop:\n\u001B[32m    890\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m is_line:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/pycharm-2025.2.3/plugins/python-ce/helpers/jupyter_debug/pydev_jupyter_plugin.py:185\u001B[39m, in \u001B[36mstop\u001B[39m\u001B[34m(plugin, pydb, frame, event, args, stop_info, arg, step_cmd)\u001B[39m\n\u001B[32m    183\u001B[39m     frame = suspend_jupyter(main_debugger, thread, frame, step_cmd)\n\u001B[32m    184\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m frame:\n\u001B[32m--> \u001B[39m\u001B[32m185\u001B[39m         \u001B[43mmain_debugger\u001B[49m\u001B[43m.\u001B[49m\u001B[43mdo_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    186\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[32m    187\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/pycharm-2025.2.3/plugins/python-ce/helpers/pydev/pydevd.py:1196\u001B[39m, in \u001B[36mPyDB.do_wait_suspend\u001B[39m\u001B[34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[39m\n\u001B[32m   1193\u001B[39m         from_this_thread.append(frame_id)\n\u001B[32m   1195\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m._threads_suspended_single_notification.notify_thread_suspended(thread_id, stop_reason):\n\u001B[32m-> \u001B[39m\u001B[32m1196\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_do_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msuspend_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrom_this_thread\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/pycharm-2025.2.3/plugins/python-ce/helpers/pydev/pydevd.py:1211\u001B[39m, in \u001B[36mPyDB._do_wait_suspend\u001B[39m\u001B[34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[39m\n\u001B[32m   1208\u001B[39m             \u001B[38;5;28mself\u001B[39m._call_mpl_hook()\n\u001B[32m   1210\u001B[39m         \u001B[38;5;28mself\u001B[39m.process_internal_commands()\n\u001B[32m-> \u001B[39m\u001B[32m1211\u001B[39m         time.sleep(\u001B[32m0.01\u001B[39m)\n\u001B[32m   1213\u001B[39m \u001B[38;5;28mself\u001B[39m.cancel_async_evaluation(get_current_thread_id(thread), \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mid\u001B[39m(frame)))\n\u001B[32m   1215\u001B[39m \u001B[38;5;66;03m# process any stepping instructions\u001B[39;00m\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
